{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bfd4bb",
   "metadata": {},
   "source": "# **Tutorial 4** - Building AI Agents: From Conversations to Career Matching\n\nWelcome to the world of intelligent AI agents! After getting on the leaderboard with Tutorial 3's quick submissions, it's time to build something actually good.\n\n**Prerequisites**: You should have completed Tutorials 1-3, which covered setup, API basics, and your first submission.\n\n## What You'll Learn\n\nAfter completing this tutorial, you'll understand:\n- **Multi-agent system architecture** using the Strands framework\n- **Structured information extraction** from unstructured conversations  \n- **Intelligent matching algorithms** that go beyond simple keyword matching\n- **Best practices** for building efficient and cost-effective AI solutions\n\n## The AI Agent Advantage\n\nRemember Tutorial 3's random matcher? That probably scored around 5%. Now we'll build agents that actually understand context:\n\n- **Contextual Understanding**: Agents grasp meaning, not just keywords\n- **Dynamic Conversations**: They can ask follow-up questions and adapt to responses\n- **Collaborative Intelligence**: Multiple agents can work together with specialized roles\n- **Learning and Adaptation**: They improve their recommendations based on interactions\n\nIn our green careers challenge, we'll see how these capabilities create a powerful system for connecting Brazilian youth with sustainable career opportunities.\n\nLet's build something intelligent!"
  },
  {
   "cell_type": "markdown",
   "id": "e99d8690",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. [Environment Setup](#environment-setup)\n",
    "   - Installing the Strands Agents framework\n",
    "   - Quick system verification\n",
    "\n",
    "2. [Understanding AI Agents](#understanding-ai-agents)\n",
    "   - What makes AI agents different from traditional AI\n",
    "   - Key components: Models, Tools, and Structured Output\n",
    "   - Introduction to the Strands framework\n",
    "\n",
    "3. [Core Components and Utilities](#core-utilities)\n",
    "   - Essential functions for agent interaction\n",
    "   - Data processing utilities for job and training information\n",
    "   - Understanding the codebase architecture\n",
    "\n",
    "4. [Data Structures and Models](#data-structures)\n",
    "   - PersonaInfo, JobInfo, and TrainingInfo models\n",
    "   - Structured data extraction with Pydantic\n",
    "   - Why structured output is crucial for AI agents\n",
    "\n",
    "5. [Building Your First AI Agent](#first-agent)\n",
    "   - Creating conversation agents that can interview personas\n",
    "   - Extracting information from natural language conversations\n",
    "   - Managing conversation state and limits\n",
    "\n",
    "6. [Multi-Agent Collaboration](#multi-agent-system)\n",
    "   - Specialized information extraction agents\n",
    "   - Intelligent matching and recommendation agents\n",
    "   - Orchestrating multiple agents for complex workflows\n",
    "\n",
    "7. [Real-World Application](#real-world-application)\n",
    "   - Processing job descriptions and training programs at scale\n",
    "   - Implementing sophisticated matching algorithms\n",
    "   - Generating personalized career recommendations\n",
    "\n",
    "8. [Testing and Optimization](#testing-optimization)\n",
    "   - Validating your matching algorithm with real examples\n",
    "   - Token usage optimization and cost management\n",
    "   - Debugging AI agent interactions\n",
    "\n",
    "9. [Conclusion and Next Steps](#conclusion)\n",
    "   - Key learnings and best practices\n",
    "   - Preparing for challenge submission\n",
    "   - Advanced techniques for competitive advantage\n",
    "\n",
    "---\n",
    "\n",
    "# Environment Setup <a id='environment-setup'></a>\n",
    "\n",
    "Since you've already set up your basic environment in previous tutorials, we only need to install the AI agents framework and verify our system is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29186a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for AI agent development\n",
    "# This may take a few minutes - be patient!\n",
    "!pip install python-dotenv strands-agents[mistral] strands-agents-tools tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9af9bd",
   "metadata": {},
   "source": [
    "The [Strands Agents](https://strandsagents.com/latest/) framework provides powerful tools for creating and managing AI agents. We'll also need supporting libraries for progress tracking and data handling.\n",
    "\n",
    "**Note**: If you completed Tutorial 2, most dependencies are already installed. This cell ensures we have the latest agent framework:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f773a",
   "metadata": {},
   "source": [
    "# Understanding AI Agents <a id='understanding-ai-agents'></a>\n",
    "\n",
    "With our environment ready, let's dive into building AI agents with the [Strands Agents](https://strandsagents.com/latest/) framework and [Mistral](https://mistral.ai/) models.\n",
    "\n",
    "**Important**: You can modify any code to optimize your solution, as long as you provide results in the required format (covered in the final sections)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1bc86",
   "metadata": {},
   "source": [
    "## What Makes AI Agents Special?\n",
    "\n",
    "AI agents are intelligent systems that can perceive, reason, and act autonomously. Unlike traditional rule-based systems, they adapt their behavior based on context and can work collaboratively to solve complex problems.\n",
    "\n",
    "### Key Capabilities of Our AI Agents:\n",
    "\n",
    "1. **Intelligent Conversations**: Conduct natural interviews with job seekers, asking follow-up questions based on responses\n",
    "2. **Structured Extraction**: Convert unstructured text into precise, actionable data using Pydantic models\n",
    "3. **Contextual Matching**: Understand semantic relationships between skills, not just keyword matches\n",
    "4. **Collaborative Problem-Solving**: Multiple specialized agents work together on different aspects of the matching process\n",
    "\n",
    "### The Strands Agents Framework\n",
    "\n",
    "Strands provides enterprise-grade tools for building production AI agents:\n",
    "\n",
    "- **Model Abstraction**: Works with multiple LLM providers (we use Mistral)\n",
    "- **Structured Output**: Built-in support for Pydantic models ensures consistent data formats\n",
    "- **Conversation Management**: Handles multi-turn dialogues with state preservation\n",
    "- **Error Handling**: Robust retry mechanisms and graceful failure handling\n",
    "\n",
    "### Our Multi-Agent Architecture\n",
    "\n",
    "In this tutorial, we'll build a system with specialized agents:\n",
    "\n",
    "- **Conversation Agent**: Interviews personas to gather career information\n",
    "- **Extraction Agent**: Converts conversations into structured PersonaInfo objects\n",
    "- **Job Matching Agent**: Finds suitable opportunities based on skills and preferences\n",
    "- **Training Matching Agent**: Recommends learning paths to bridge skill gaps\n",
    "- **Orchestration Logic**: Coordinates all agents to produce final recommendations\n",
    "\n",
    "This division of labor makes each agent more focused and efficient, while the system as a whole handles complex workflows.\n",
    "\n",
    "Let's start building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbdbb6",
   "metadata": {},
   "outputs": [],
   "source": "# Core libraries for AI agent development\nimport json\nimport os\nimport sys\nimport boto3\nimport dotenv\nimport requests\n\nfrom pathlib import Path\nfrom typing import Dict, List, Optional, Tuple, Type, TypeVar, Any\nfrom tqdm import tqdm\n\n# Add parent directory to import our utilities\nsys.path.append('..')\nfrom src.utils import (\n    save_json, \n    read_json, \n    load_file_content,\n    get_job_paths,\n    get_training_paths,\n    sanity_check\n)\n\n# Structured data models\nfrom pydantic import BaseModel, Field\n\n# Strands Agents framework - our main AI agent library\nfrom strands.agent import Agent\nfrom strands.models.mistral import MistralModel\n\n# AWS integration for API calls\nfrom botocore.auth import SigV4Auth\nfrom botocore.awsrequest import AWSRequest\n\n# Type hints for better code quality\nT = TypeVar('T')\nM = TypeVar('M', bound=BaseModel)\n\n# Load environment variables from our env file\ndotenv.load_dotenv(\".env\")\n\nprint(\"✅ Imported shared utilities from src/\")\nprint(\"💡 Notice: We're reusing code from Tutorial 3's infrastructure\")"
  },
  {
   "cell_type": "markdown",
   "id": "44256fd3",
   "metadata": {},
   "source": [
    "## System Health Check\n",
    "\n",
    "Before we start building our AI agents, let's verify that our connection to the challenge infrastructure is working correctly. This sanity check ensures we can communicate with the persona API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86967b0f",
   "metadata": {},
   "outputs": [],
   "source": "# Run the sanity check to verify our setup (reusing from src/utils.py)\nsanity_check()"
  },
  {
   "cell_type": "markdown",
   "id": "58471e1e",
   "metadata": {},
   "source": [
    "# Core Components and Utilities <a id='core-utilities'></a>\n",
    "\n",
    "This section defines the essential building blocks for our AI agent system. These functions demonstrate key patterns in agent development: delegation of specialized tasks, structured data handling, and efficient batch processing.\n",
    "\n",
    "## AI Agent Patterns in Our System:\n",
    "\n",
    "### Agent Creation and Configuration\n",
    "- **`get_agent()`**: Factory function that creates agents with specific roles and capabilities\n",
    "- **System Prompts**: Define agent behavior, expertise, and response patterns\n",
    "\n",
    "### Conversation Management\n",
    "- **`send_message_to_chat()`**: Handles secure communication with persona agents via AWS API\n",
    "- **`get_conversation()`**: Orchestrates multi-turn dialogues with goal-oriented questioning\n",
    "\n",
    "### Intelligent Information Processing\n",
    "- **`extract_info()`**: Uses specialized agents to convert unstructured text into structured data\n",
    "- **`extract_info_to_json()`**: Batch processing with caching, retry logic, and progress tracking\n",
    "\n",
    "### Data Discovery and Management\n",
    "- **`load_file_content()`**, **`read_json()`**, **`save_json()`**: Standard I/O operations\n",
    "- **`get_job_paths()`**, **`get_training_paths()`**: Discover available data files\n",
    "\n",
    "## Why These Patterns Matter:\n",
    "\n",
    "1. **Specialization**: Each agent has a clear, focused role\n",
    "2. **Reusability**: Common patterns are abstracted into utility functions  \n",
    "3. **Reliability**: Built-in error handling, retries, and caching\n",
    "4. **Scalability**: Batch processing patterns handle large datasets efficiently\n",
    "5. **Cost Control**: Caching prevents redundant API calls\n",
    "\n",
    "Let's examine the implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0e926",
   "metadata": {},
   "outputs": [],
   "source": "def get_agent(\n    system_prompt: str = \"\",\n    model_id: str = \"mistral-medium-latest\"\n) -> Agent:\n    \"\"\"\n    Create and configure an AI agent with specified capabilities.\n    \n    This is the core function for creating AI agents. The system prompt defines\n    the agent's role, expertise, and behavior patterns. Different model IDs\n    offer different capabilities and cost profiles.\n    \n    Args:\n        system_prompt: Instructions defining the agent's role and behavior\n        model_id: Mistral model to use (e.g., 'mistral-medium-latest', 'mistral-small-latest')\n    \n    Returns:\n        Configured Agent ready for interaction\n    \"\"\"\n    model = MistralModel(\n        api_key=os.environ[\"MISTRAL_API_KEY\"],\n        model_id=model_id,\n        stream=False  # Non-streaming for better control in batch operations\n    )\n    return Agent(model=model, system_prompt=system_prompt, callback_handler=None)\n\n# Note: File I/O functions are now imported from src.utils\n# This keeps our notebook focused on AI agent logic"
  },
  {
   "cell_type": "markdown",
   "id": "ef5f9d3a",
   "metadata": {},
   "source": [
    "# Data Structures and Models <a id='data-structures'></a>\n",
    "\n",
    "**Structured output** is what separates professional AI agent systems from simple chatbots. Instead of generating free-form text that requires post-processing, our agents produce data that follows exact schemas, enabling reliable programmatic handling.\n",
    "\n",
    "## The Pydantic Advantage\n",
    "\n",
    "We use **Pydantic models** to define our data structures because they provide:\n",
    "\n",
    "- **Type Safety**: Automatic validation ensures data integrity\n",
    "- **Clear Contracts**: Agents know exactly what fields to populate\n",
    "- **Error Prevention**: Invalid data is caught immediately, not in downstream processing\n",
    "- **Documentation**: Field descriptions guide agent behavior\n",
    "- **JSON Serialization**: Seamless conversion between Python objects and storage formats\n",
    "\n",
    "## Our Data Models for Career Matching\n",
    "\n",
    "### PersonaInfo: The Complete Candidate Profile\n",
    "Captures everything needed to understand a job seeker's background, skills, and preferences. Notice how skills include both the skill name and proficiency level - this nuanced approach enables better matching than simple keyword lists.\n",
    "\n",
    "### JobInfo: Structured Job Requirements  \n",
    "Extracts the essential criteria for job opportunities. This standardized format lets us compare any job against any candidate programmatically.\n",
    "\n",
    "### TrainingInfo: Learning Pathway Data\n",
    "Describes what skills training programs develop and at what level. This enables us to recommend learning paths that bridge the gap between a candidate's current skills and job requirements.\n",
    "\n",
    "### IDList: Agent Recommendations\n",
    "A simple but powerful structure for when agents need to return multiple recommendations (job IDs, training IDs, etc.).\n",
    "\n",
    "## The Power of Structured Thinking\n",
    "\n",
    "Consider this transformation:\n",
    "\n",
    "**Unstructured Agent Output:**\n",
    "> \"Maria seems like a good fit for environmental jobs in São Paulo since she has sustainability experience and project management skills, though she might need some training in data analysis.\"\n",
    "\n",
    "**Structured Agent Output:**\n",
    "```python\n",
    "PersonaInfo(\n",
    "    name=\"Maria Santos\",\n",
    "    skills=[(\"sustainability\", \"intermediate\"), (\"project_management\", \"beginner\")],\n",
    "    location=\"São Paulo\",\n",
    "    age=\"25\",\n",
    "    years_of_experience=\"3\"\n",
    ")\n",
    "```\n",
    "\n",
    "The structured approach enables:\n",
    "- **Precise Matching**: Compare skill levels against job requirements\n",
    "- **Automatic Processing**: No need to parse natural language descriptions\n",
    "- **Quality Assurance**: Ensure all required information is captured\n",
    "- **Scalable Operations**: Process thousands of candidates consistently\n",
    "\n",
    "Let's examine our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured representation of job requirements and characteristics.\n",
    "    \n",
    "    This model captures the essential information needed to match candidates\n",
    "    to job opportunities. The AI agent extracts this information from\n",
    "    unstructured job descriptions.\n",
    "    \"\"\"\n",
    "    required_skills: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of required skills for the job.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Job location.\"\n",
    "    )\n",
    "    years_of_experience_required: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Years of experience required to get this job.\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a human-readable description for AI agents to process.\"\"\"\n",
    "        skills = ', '.join(self.required_skills)\n",
    "        return (\n",
    "            f\"Required skills: {skills}\\nLocation: {self.location}\\n\"\n",
    "            f\"Years of experience required: {self.years_of_experience_required}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class TrainingInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents training programs and the skills they provide.\n",
    "    \n",
    "    Each training program teaches specific skills at defined proficiency levels.\n",
    "    This information is crucial for recommending learning paths to candidates.\n",
    "    \"\"\"\n",
    "    skill_acquired_and_level: Tuple[str, str] = Field(\n",
    "        default=(\"not specified\", \"not specified\"),\n",
    "        description=\"A pair of skill name and level. This tuple contains only 2 elements!\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a human-readable description for AI agents to process.\"\"\"\n",
    "        skill = f'{self.skill_acquired_and_level[0]}: level {self.skill_acquired_and_level[1]}'\n",
    "        return f\"Acquired skills: {skill}\"\n",
    "\n",
    "\n",
    "class PersonaInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Comprehensive profile of a job seeker extracted from conversations.\n",
    "    \n",
    "    This model captures all the essential information needed to match\n",
    "    candidates with appropriate opportunities and training programs.\n",
    "    \"\"\"\n",
    "    name: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Persona's name\"\n",
    "    )\n",
    "    skills: List[Tuple[str, str]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of pairs representing skills and its level.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Current location\"\n",
    "    )\n",
    "    age: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Age of the persona\"\n",
    "        )\n",
    "    years_of_experience: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Years of experience in a field.\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a comprehensive human-readable profile for AI agents.\"\"\"\n",
    "        skills = ', '.join([\n",
    "            f'{skill}: {level}'\n",
    "            for skill, level in self.skills\n",
    "        ])\n",
    "        return (\n",
    "            f\"Name: {self.name}\\n\"\n",
    "            f\"Skills: {skills}\\n\"\n",
    "            f\"Location: {self.location}\\n\"\n",
    "            f\"Age: {self.age}\\n\"\n",
    "            f\"Years of experience: {self.years_of_experience}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class IDList(BaseModel):\n",
    "    \"\"\"\n",
    "    Simple container for lists of identifiers.\n",
    "    \n",
    "    Used when AI agents need to return multiple recommendations,\n",
    "    such as a list of suitable job IDs or training program IDs.\n",
    "    \"\"\"\n",
    "    values: List[str] = Field(default_factory=list, description=\"A list of string IDs (job IDs, training IDs, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb50184",
   "metadata": {},
   "source": [
    "# Building Your First AI Agent <a id='first-agent'></a>\n",
    "\n",
    "Now we'll create AI agents that can conduct intelligent conversations with job seekers and extract structured information. This demonstrates the core capability that makes AI agents powerful: **adaptive interaction**.\n",
    "\n",
    "## The Persona System\n",
    "\n",
    "In our challenge, \"personas\" are AI agents representing job seekers with unique backgrounds, skills, and career goals. Our job is to build agents that can:\n",
    "\n",
    "1. **Conduct Adaptive Interviews**: Ask relevant follow-up questions based on responses\n",
    "2. **Extract Complete Profiles**: Gather all necessary information efficiently  \n",
    "3. **Manage Conversation Limits**: Work within resource constraints effectively\n",
    "\n",
    "## Critical Resource Constraints\n",
    "\n",
    "⚠️ **Important**: There are strict limits on persona interactions:\n",
    "- **5 conversations per day** per persona per team\n",
    "- **20 messages maximum** per conversation\n",
    "- **Conversation IDs** must be tracked to maintain context\n",
    "\n",
    "These constraints are essential for:\n",
    "- Fair competition between teams\n",
    "- Preventing brute-force solutions  \n",
    "- Managing API costs and system load\n",
    "- Encouraging efficient conversation design\n",
    "\n",
    "## Conversation Strategy\n",
    "\n",
    "Effective conversation agents follow these principles:\n",
    "\n",
    "### Goal-Oriented Questioning\n",
    "- Have a clear information-gathering objective\n",
    "- Ask open-ended questions to encourage detailed responses\n",
    "- Follow up on vague or incomplete answers\n",
    "\n",
    "### Efficiency Under Constraints\n",
    "- Gather maximum information in minimum turns\n",
    "- Prioritize essential data over nice-to-have details\n",
    "- Use conversational flow to collect multiple data points per exchange\n",
    "\n",
    "### Context Preservation\n",
    "- Maintain conversation history across turns\n",
    "- Use conversation IDs to resume interrupted sessions\n",
    "- Build on previous responses rather than repeating questions\n",
    "\n",
    "Let's see how this works in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0651b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_chat(message: str, persona_id: str, conversation_id: str = None) -> Optional[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Send a message to a persona agent and receive their response.\n",
    "    \n",
    "    This function handles the low-level communication with the challenge API,\n",
    "    managing AWS authentication and conversation state. Each persona maintains\n",
    "    their own conversation context across multiple turns.\n",
    "    \n",
    "    Args:\n",
    "        message: The message to send to the persona\n",
    "        persona_id: Unique identifier for the persona (e.g., 'persona_001')\n",
    "        conversation_id: Optional conversation ID for maintaining context\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (persona_response, conversation_id) or None if failed\n",
    "    \"\"\"\n",
    "    url = \"https://cygeoykm2i.execute-api.us-east-1.amazonaws.com/main/chat\"\n",
    "    \n",
    "    # Set up AWS authentication\n",
    "    session = boto3.Session(region_name='us-east-1')\n",
    "    credentials = session.get_credentials()\n",
    "    region = 'us-east-1'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Prepare the message payload\n",
    "    payload = {\n",
    "        \"persona_id\": persona_id,\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    # Create and sign the AWS request\n",
    "    request = AWSRequest(\n",
    "        method='POST',\n",
    "        url=url,\n",
    "        data=json.dumps(payload),\n",
    "        headers=headers\n",
    "    )\n",
    "    SigV4Auth(credentials, 'execute-api', region).add_auth(request)\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.request(\n",
    "        method=request.method,\n",
    "        url=request.url,\n",
    "        headers=dict(request.headers),\n",
    "        data=request.body\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json['response'], response_json['conversation_id']\n",
    "\n",
    "\n",
    "def get_conversation(persona_id: str, max_turns: int = 5, print_conversation: bool = False, print_token_no: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Conduct a structured conversation with a persona to gather career information.\n",
    "    \n",
    "    This function demonstrates key AI agent capabilities:\n",
    "    - Goal-oriented dialogue management\n",
    "    - Adaptive questioning based on responses  \n",
    "    - Context maintenance across conversation turns\n",
    "    - Efficient information extraction within token limits\n",
    "    \n",
    "    Args:\n",
    "        persona_id: Unique identifier for the persona to interview\n",
    "        max_turns: Maximum conversation turns to prevent infinite loops\n",
    "        print_conversation: Whether to display the full conversation\n",
    "        print_token_no: Whether to show token usage statistics\n",
    "        \n",
    "    Returns:\n",
    "        List of conversation messages for further processing\n",
    "    \"\"\"\n",
    "    # Define the agent's role and objectives\n",
    "    system_prompt = \"\"\"\n",
    "    Continue to ask questions about this person - do not provide the jobs, trainings or anything yet.\n",
    "    You are a helpful and empathetic assistant. Your goal is to engage in a natural conversation with a persona to gather the following information:\n",
    "    - Their name\n",
    "    - Their skills and **level of this skill**\n",
    "    - Their current location\n",
    "    - Their age\n",
    "    - Their preferences\n",
    "    - Years of experience\n",
    "\n",
    "    Remember to always gather all of those information!\n",
    "    Ask open-ended questions to encourage detailed responses. Be polite, patient, and adapt your questions based on their answers.\n",
    "    If the persona is unsure or vague, gently probe for more details. Do not ask all questions at once; let the conversation flow naturally.\n",
    "    **Do not comment on whatever the response is. Just ask questions to retrieve the information.**\n",
    "    \"\"\"\n",
    "    conversation = []\n",
    "    current_turn = 0\n",
    "    total_tokens = 0\n",
    "    conversation_agent = get_agent(system_prompt)\n",
    "    conversation_id = None\n",
    "\n",
    "    # greeting\n",
    "    agent_message = \"Hello! I'm here to help you find the best job or training opportunities. Can you tell me your name?\"\n",
    "    conversation_agent.messages = [{\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\n",
    "            \"text\": agent_message\n",
    "        }]\n",
    "    }]\n",
    "    conversation.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    # Conduct the conversation\n",
    "    while current_turn < max_turns:\n",
    "        # Send message to persona and get response\n",
    "        resp = send_message_to_chat(\n",
    "            agent_message,\n",
    "            persona_id,\n",
    "            conversation_id\n",
    "        )\n",
    "        \n",
    "        if resp is None:\n",
    "            print(f\"⚠️ Persona {persona_id} did not respond - ending conversation\")\n",
    "            break\n",
    "            \n",
    "        user_response, conversation_id = resp\n",
    "        conversation.append(f\"User: {user_response}\")\n",
    "        \n",
    "        # Generate agent's next question/response\n",
    "        agent_response = conversation_agent(user_response)\n",
    "        total_tokens = agent_response.metrics.accumulated_usage['totalTokens']\n",
    "        agent_message = str(agent_response)\n",
    "        conversation.append(f\"Assistant: {agent_message}\")\n",
    "        \n",
    "        current_turn += 1\n",
    "    \n",
    "    # Optional debugging output\n",
    "    if print_conversation:\n",
    "        print('\\n=== CONVERSATION ===')\n",
    "        print('\\n'.join(conversation))\n",
    "        print('===================\\n')\n",
    "        \n",
    "    if print_token_no:\n",
    "        print(f'💡 Total tokens used: {total_tokens}')\n",
    "        \n",
    "    return conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1cb55",
   "metadata": {},
   "source": [
    "# Multi-Agent Collaboration <a id='multi-agent-system'></a>\n",
    "\n",
    "The real power of AI agents emerges when they work together. Our career matching system uses **specialized agents** that collaborate to solve different aspects of the challenge, each optimized for specific tasks.\n",
    "\n",
    "## Agent Specialization Strategy\n",
    "\n",
    "### Information Extraction Agents\n",
    "**Role**: Convert unstructured text into structured data\n",
    "**Why Specialized**: These agents are tuned for precise data extraction, with prompts optimized for identifying specific field types (skills, locations, experience levels)\n",
    "**Input**: Raw conversations, job descriptions, training materials  \n",
    "**Output**: Structured Pydantic objects\n",
    "\n",
    "### Matching Intelligence Agents  \n",
    "**Role**: Understand relationships between candidates and opportunities\n",
    "**Why Specialized**: These agents focus on semantic understanding - they know that \"environmental sustainability\" relates to \"green energy\" and \"climate action\"\n",
    "**Input**: Structured candidate and opportunity data\n",
    "**Output**: Ranked recommendation lists\n",
    "\n",
    "### Career Path Agents\n",
    "**Role**: Bridge skill gaps with training recommendations\n",
    "**Why Specialized**: These agents understand learning progressions and skill prerequisites\n",
    "**Input**: Current skills vs. target job requirements  \n",
    "**Output**: Personalized learning pathways\n",
    "\n",
    "## Collaborative Intelligence Patterns\n",
    "\n",
    "### 1. Pipeline Processing\n",
    "Each agent performs one step in a sequential process:\n",
    "```\n",
    "Raw Conversation → Extraction Agent → PersonaInfo → Matching Agent → Job Recommendations\n",
    "```\n",
    "\n",
    "### 2. Cross-Validation  \n",
    "Multiple agents can process the same input to improve accuracy:\n",
    "```\n",
    "Job Description → [Agent A, Agent B, Agent C] → Consensus JobInfo\n",
    "```\n",
    "\n",
    "### 3. Hierarchical Decision Making\n",
    "High-level agents delegate to specialists:\n",
    "```\n",
    "Career Advisor Agent → [Job Matcher, Training Recommender, Location Analyzer] → Integrated Plan\n",
    "```\n",
    "\n",
    "## Enterprise-Grade Batch Processing\n",
    "\n",
    "The `extract_info_to_json()` function demonstrates production AI patterns:\n",
    "\n",
    "- **Intelligent Caching**: Avoids redundant API calls by storing results\n",
    "- **Graceful Error Handling**: Retries failed extractions with exponential backoff  \n",
    "- **Progress Monitoring**: Shows processing status for large datasets\n",
    "- **Incremental Processing**: Resumes from interruption points\n",
    "- **Cost Optimization**: Batches operations to minimize API overhead\n",
    "\n",
    "This approach is crucial when processing hundreds of documents efficiently and reliably while managing costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2570174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(model: Type[M], text: str) -> M:\n",
    "    extraction_agent = get_agent()\n",
    "    return extraction_agent.structured_output(output_model=model, prompt=text)\n",
    "\n",
    "\n",
    "def extract_info_from_conversation(conversation: List[str]) -> PersonaInfo:\n",
    "    text = '\\n'.join(conversation)\n",
    "    return extract_info(PersonaInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_job_path(path: str | Path) -> JobInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(JobInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_training_path(path: str | Path) -> TrainingInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(TrainingInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_to_json(\n",
    "    model: BaseModel,\n",
    "    description_paths: List[str | Path],\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    save_path = Path(save_path)\n",
    "\n",
    "    if not save_path.exists():\n",
    "        save_path.touch()\n",
    "        save_json(save_path, {})\n",
    "\n",
    "    extracted_data = read_json(save_path)\n",
    "    description_paths = [Path(path) for path in description_paths]\n",
    "    print(f'Total descriptions for {model.__name__}: {len(description_paths)}')\n",
    "    print(f'Extracted infos: {len(extracted_data)}')\n",
    "\n",
    "    counter = 0\n",
    "    for path in description_paths:\n",
    "        id_ = path.stem\n",
    "        retries = 0\n",
    "        err = None\n",
    "        if id_ not in extracted_data:\n",
    "            text = load_file_content(path)\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    info = extract_info(model, text)\n",
    "                    extracted_data[id_] = info.model_dump_json()\n",
    "                    counter += 1\n",
    "                    break\n",
    "                except ValueError as e:\n",
    "                    retries += 1\n",
    "                    err = e\n",
    "            else:\n",
    "                print(f'Error for id: {id_}', err)\n",
    "        if counter % cache_period == 1:\n",
    "            save_json(save_path, extracted_data)\n",
    "            print(len(extracted_data))\n",
    "    save_json(save_path, extracted_data)\n",
    "\n",
    "\n",
    "def extract_jobs_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    job_paths = get_job_paths()\n",
    "    extract_info_to_json(\n",
    "        model=JobInfo,\n",
    "        description_paths=job_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_trainings_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    training_paths = get_training_paths()\n",
    "    extract_info_to_json(\n",
    "        model=TrainingInfo,\n",
    "        description_paths=training_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a5272",
   "metadata": {},
   "source": [
    "# Real-World Application: Intelligent Career Matching <a id='real-world-application'></a>\n",
    "\n",
    "This is where our AI agents solve the core challenge: **intelligent matching that goes beyond keywords**. Our system understands context, relationships, and nuances that traditional matching systems miss.\n",
    "\n",
    "## The Intelligence Advantage\n",
    "\n",
    "### Traditional Keyword Matching:\n",
    "- Person has \"sustainability\" → Job requires \"environmental\" → ❌ **No Match**\n",
    "- Rigid, literal interpretation leads to missed opportunities\n",
    "\n",
    "### AI Agent Matching:\n",
    "- Agent understands semantic relationships: sustainability ↔ environmental ↔ green energy\n",
    "- Considers skill transferability, location flexibility, experience scalability  \n",
    "- ✅ **Intelligent Match** with confidence reasoning\n",
    "\n",
    "## Multi-Layer Matching Intelligence\n",
    "\n",
    "### 1. Semantic Understanding Layer\n",
    "Our agents don't just match words - they understand meaning:\n",
    "- \"Organic farming\" connects to \"sustainable agriculture\" and \"food systems\"\n",
    "- \"Community outreach\" relates to \"stakeholder engagement\" and \"social impact\"\n",
    "- \"Data analysis\" applies across environmental monitoring, impact measurement, and policy research\n",
    "\n",
    "### 2. Context-Aware Evaluation Layer  \n",
    "Agents consider multiple factors simultaneously:\n",
    "- **Skill Level Alignment**: Does the candidate's proficiency match job requirements?\n",
    "- **Growth Potential**: Can this person develop into the role with training?\n",
    "- **Geographic Feasibility**: Are location constraints realistic?\n",
    "- **Career Trajectory**: Does this opportunity align with their goals?\n",
    "\n",
    "### 3. Learning Path Intelligence Layer\n",
    "For skill gaps, agents recommend strategic development:\n",
    "- **Prerequisite Analysis**: What foundational skills are needed first?\n",
    "- **Progressive Learning**: How to build from current skills to job requirements?\n",
    "- **Time-to-Competency**: Realistic timelines for skill development\n",
    "\n",
    "## Why This Approach Works at Scale\n",
    "\n",
    "1. **Contextual Intelligence**: Understands meaning behind requirements and capabilities\n",
    "2. **Holistic Evaluation**: Balances multiple factors for better recommendations  \n",
    "3. **Personalized Pathways**: Each recommendation is tailored to individual circumstances\n",
    "4. **Scalable Processing**: Same intelligent matching works for thousands of candidates\n",
    "5. **Continuous Learning**: Agent performance improves with more interactions\n",
    "\n",
    "The result is a career guidance system that thinks like an experienced career counselor, but operates at the scale and speed of modern AI.\n",
    "\n",
    "Let's see this intelligence in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ee846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    jobs_data: Dict[str, JobInfo],\n",
    ") -> List[str]:\n",
    "    jobs_text = \"\\n\".join([\n",
    "        f'{job_id}: {job_info.describe()}'\n",
    "        for job_id, job_info in jobs_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available jobs. Given a candidate info provide\n",
    "    a list of up to 4 job IDs that would match that candidate.\n",
    "    The list might be empty if no match is found:\n",
    "    {jobs_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values\n",
    "\n",
    "\n",
    "def find_training_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo]\n",
    ") -> List[str]:\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available trainings. Given a candidate info provide\n",
    "    a list of up to 4 training IDs that would match that candidate.\n",
    "    The list might be empty if no match is found:\\n\n",
    "    {trainings_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values\n",
    "\n",
    "\n",
    "def find_training_matches_for_job(\n",
    "    job_info: JobInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo],\n",
    "):\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available trainings. Given a job info provide\n",
    "    a list of up to 4 training IDs that would be nice to have before\n",
    "    taking that job. The list may be empty if no training fit:\\n\n",
    "    {trainings_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = None\n",
    "    err = None\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            res = agent.structured_output(IDList, job_info.describe())\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            retries += 1\n",
    "            err = e\n",
    "    if res is None:\n",
    "        raise ValueError(f'Agent could not get matches for job {job_info}. Err: {err}')\n",
    "    return res.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1a741",
   "metadata": {},
   "source": [
    "# Extracting job infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4734856",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_save_path = './extracted_jobs_info.json'\n",
    "extract_jobs_info_to_json(jobs_save_path)\n",
    "jobs_info = read_json(jobs_save_path)\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(job_data)\n",
    "    for job_id, job_data in jobs_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb3ec7",
   "metadata": {},
   "source": [
    "# Extracting trainings info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5574bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainings_save_path = './extracted_trainings_info.json'\n",
    "extract_trainings_info_to_json(trainings_save_path)\n",
    "trainings_info = read_json(trainings_save_path)\n",
    "trainings_info = {\n",
    "    training_id: TrainingInfo.model_validate_json(training_data)\n",
    "    for training_id, training_data in trainings_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916e03b",
   "metadata": {},
   "source": [
    "# Match trainings to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_training_matches_path = Path('./job_training_matches.json')\n",
    "job_training_matches = {}\n",
    "for job_id, job_info in tqdm(jobs_info.items()):\n",
    "    training_ids = find_training_matches_for_job(job_info, trainings_info)\n",
    "    job_training_matches[job_id] = training_ids\n",
    "save_json(job_training_matches_path, job_training_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96942bd3",
   "metadata": {},
   "source": [
    "# Testing and Optimization <a id='testing-optimization'></a>\n",
    "\n",
    "Testing AI agent systems requires evaluating both **technical correctness** and **intelligent behavior**. We need to verify that agents make sensible decisions, not just that code executes without errors.\n",
    "\n",
    "## Testing AI Agent Intelligence\n",
    "\n",
    "### Quality Metrics to Evaluate:\n",
    "- ✅ **Relevance**: Do job recommendations align with candidate skills and interests?\n",
    "- ✅ **Feasibility**: Are experience requirements and locations realistic?  \n",
    "- ✅ **Growth Potential**: Do training recommendations create logical skill progression?\n",
    "- ✅ **Semantic Understanding**: Does the system recognize skill relationships and transferability?\n",
    "\n",
    "### Edge Cases to Test:\n",
    "- **Minimal Information**: How does the system handle incomplete profiles?\n",
    "- **Conflicting Preferences**: What happens with unrealistic expectations?\n",
    "- **Unusual Skill Combinations**: Can agents find opportunities for unique backgrounds?\n",
    "- **Geographic Constraints**: How does location filtering affect recommendations?\n",
    "\n",
    "## Performance and Cost Optimization\n",
    "\n",
    "### Token Efficiency Strategies:\n",
    "1. **Prompt Optimization**: Concise, focused prompts reduce token usage\n",
    "2. **Batch Processing**: Group similar operations to minimize API overhead\n",
    "3. **Intelligent Caching**: Store results to avoid redundant processing\n",
    "4. **Model Selection**: Use smaller models for simple tasks, larger for complex reasoning\n",
    "\n",
    "### Debugging AI Agent Behaviors:\n",
    "- **Conversation Logging**: Track agent decisions and reasoning\n",
    "- **Intermediate Results**: Examine extracted data quality at each stage\n",
    "- **A/B Testing**: Compare different prompt strategies\n",
    "- **Error Analysis**: Understand when and why agents make poor decisions\n",
    "\n",
    "## Competitive Intelligence\n",
    "\n",
    "For the challenge, consider these optimization areas:\n",
    "- **Conversation Efficiency**: Gather maximum information in minimum turns\n",
    "- **Matching Sophistication**: Find connections that other teams miss\n",
    "- **Recommendation Quality**: Provide actionable, personalized guidance\n",
    "- **System Reliability**: Handle edge cases gracefully\n",
    "\n",
    "Let's test our system with a realistic example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test persona with environmental/sustainability focus\n",
    "persona = PersonaInfo(\n",
    "    name='Pedro Araújo',\n",
    "    skills=[('Food Safety', 'Intermediate'), ('Food Sustainability', 'Intermediate')],\n",
    "    location='Brasília',\n",
    "    age='16',  # Note: Young age may affect job eligibility\n",
    "    years_of_experience='1'\n",
    ")\n",
    "\n",
    "print(\"🧪 Testing with Sample Persona:\")\n",
    "print(\"=\" * 40)\n",
    "print(persona.describe())\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test job matching\n",
    "print(\"\\n🎯 Finding Job Matches...\")\n",
    "persona_jobs = find_job_matches_for_persona(persona, jobs_info)\n",
    "print(f\"Recommended Jobs: {persona_jobs}\")\n",
    "\n",
    "# Test training matching  \n",
    "print(\"\\n📚 Finding Training Matches...\")\n",
    "persona_trainings = find_training_matches_for_persona(persona, trainings_info)\n",
    "print(f\"Recommended Trainings: {persona_trainings}\")\n",
    "\n",
    "print(\"\\n💡 Analysis:\")\n",
    "print(\"- Are the job recommendations appropriate for someone with intermediate food safety/sustainability skills?\")\n",
    "print(\"- Do the training suggestions help develop complementary skills?\") \n",
    "print(\"- How does the young age (16) affect job eligibility?\")\n",
    "print(\"- Are there regional opportunities available in Brasília?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f2390",
   "metadata": {},
   "source": [
    "# Collecting conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dade2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_ids = [f'persona_{i:03}' for i in range(1, 101)]\n",
    "cache_period = 4\n",
    "\n",
    "personas_save_path = Path('./extracted_personas_info.json')\n",
    "if not personas_save_path.exists():\n",
    "    personas_save_path.touch()\n",
    "    save_json(personas_save_path, {})\n",
    "\n",
    "persona_infos = read_json(personas_save_path)\n",
    "print(f'Total conversations for personas: {len(persona_infos)}')\n",
    "print(f'Collected conversations: {len(persona_infos)}')\n",
    "\n",
    "counter = 0\n",
    "for persona_id in persona_ids:\n",
    "    if persona_id not in persona_infos:\n",
    "        conversation = get_conversation(persona_id, max_turns=2)\n",
    "        persona_info = extract_info_from_conversation(conversation)\n",
    "        persona_infos[persona_id] = persona_info.model_dump_json()\n",
    "        counter += 1\n",
    "    if counter % cache_period == 1:\n",
    "        save_json(personas_save_path, persona_infos)\n",
    "        print(len(persona_infos))\n",
    "save_json(personas_save_path, persona_infos)\n",
    "\n",
    "persona_infos = {\n",
    "    persona_id: PersonaInfo.model_validate_json(persona_info)\n",
    "    for persona_id, persona_info in persona_infos.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1f958",
   "metadata": {},
   "source": [
    "# Generating final data\n",
    "\n",
    "Each line in the sample represents a single prediction result for a persona, formatted as a JSON object (JSON Lines format). The fields include:\n",
    "\n",
    "- `persona_id`: The unique identifier for the persona.\n",
    "- `predicted_type`: The type of recommendation made. It can be `\"jobs+trainings\"`, `\"trainings_only\"`, or `\"awareness\"`.\n",
    "- Depending on the `predicted_type`, additional fields are included:\n",
    "    - For `\"jobs+trainings\"`: a `jobs` list, where each item contains a `job_id` and a list of `suggested_trainings` for that job.\n",
    "    - For `\"trainings_only\"`: a `trainings` list with recommended training IDs.\n",
    "    - For `\"awareness\"`: a `predicted_items` field, e.g., `\"too_young\"`.\n",
    "\n",
    "**Why this format?**\n",
    "\n",
    "- **Consistent structure** ensures our endpoint can reliably parse and validate each prediction.\n",
    "- **Flexible fields** support different recommendation types while keeping the schema simple and machine-readable.\n",
    "- **Automation-ready**: This format enables direct ingestion into evaluation or deployment systems without manual intervention.\n",
    "\n",
    "Participants must use this format to ensure compatibility with the challenge's automated result validation and scoring systems.\n",
    "\n",
    "Example result:\n",
    "```json\n",
    "{\"persona_id\": \"persona_001\", \"predicted_type\": \"trainings_only\", \"trainings\": [\"t1\", \"t2\"]}\n",
    "{\"persona_id\": \"persona_002\", \"predicted_type\": \"jobs+trainings\", \"jobs\": [{\"job_id\": \"j1\", \"suggested_trainings\": [\"t3\"]},{\"job_id\": \"j2\", \"suggested_trainings\": [\"t34\"]},{\"job_id\": \"j7\", \"suggested_trainings\": [\"t1\", \"t33\"]}]}\n",
    "{\"persona_id\": \"persona_127\", \"predicted_type\": \"awareness\", \"predicted_items\": \"too_young\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for persona_id, persona_info in tqdm(persona_infos.items()):\n",
    "    jobs = find_job_matches_for_persona(persona_info, jobs_info)\n",
    "    data = {'persona_id': persona_id}\n",
    "    if jobs and any(job_training_matches.get(job_id) for job_id in jobs):\n",
    "        data['predicted_type'] = 'jobs+trainings'\n",
    "        data['jobs'] = [\n",
    "            {\n",
    "                'job_id': job_id,\n",
    "                'suggested_trainings': job_training_matches[job_id]\n",
    "            }\n",
    "            for job_id in jobs\n",
    "        ]\n",
    "    elif not jobs:\n",
    "        trainings = find_training_matches_for_persona(persona_info, jobs_info)\n",
    "        data['predicted_type'] = 'trainings_only'\n",
    "        data['trainings'] = trainings\n",
    "    else:\n",
    "        data['predicted_type'] = 'awareness'\n",
    "        data['predicted_items'] = ''\n",
    "    results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e523466",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('./results.json')\n",
    "save_json(results_path, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004724ec",
   "metadata": {},
   "source": [
    "# Sending the results\n",
    "After your results are ready you have to send them for evaluation. The function that does that is defined below. If the submission is correct the response status code will be 200. After a while you should see how your solution socre on the main GDSC page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e5f07d",
   "metadata": {},
   "outputs": [],
   "source": "# Use the send_results function from our utilities\nfrom src.utils import send_results\n\n# This is cleaner than having submission logic in notebooks\n# See src/utils.py for the implementation"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c478db9d",
   "metadata": {},
   "outputs": [],
   "source": "results = read_json(results_path)\n\n# Submit using our shared utility function\nresponse = send_results(results)\n\nif response and response.status_code == 200:\n    try:\n        print(response.json()['message'])\n    except:\n        print(\"Submission successful!\")"
  },
  {
   "cell_type": "markdown",
   "id": "92196b09",
   "metadata": {},
   "source": [
    "# Conclusion and Next Steps <a id='conclusion'></a>\n",
    "\n",
    "Congratulations! You've built a sophisticated AI agent system that can conduct intelligent conversations, extract structured information, and make contextual recommendations for career matching.\n",
    "\n",
    "## Key Concepts You've Mastered\n",
    "\n",
    "### AI Agent Architecture\n",
    "- **Specialized Agents**: Each agent focuses on specific tasks (conversation, extraction, matching)\n",
    "- **Collaborative Intelligence**: Multiple agents work together to solve complex problems\n",
    "- **Structured Output**: Pydantic models ensure consistent, processable data\n",
    "\n",
    "### Production-Ready Patterns\n",
    "- **Resource Management**: Working within API limits and conversation constraints\n",
    "- **Error Handling**: Robust retry mechanisms and graceful failure handling  \n",
    "- **Batch Processing**: Efficient handling of large datasets with caching and progress tracking\n",
    "- **Cost Optimization**: Strategic model selection and token usage management\n",
    "\n",
    "### Intelligent Matching Beyond Keywords\n",
    "- **Semantic Understanding**: Agents grasp meaning and relationships between concepts\n",
    "- **Context-Aware Decisions**: Multiple factors considered simultaneously for better recommendations\n",
    "- **Personalized Pathways**: Each recommendation tailored to individual circumstances\n",
    "\n",
    "## Best Practices for Competitive Success\n",
    "\n",
    "1. **Optimize Conversation Efficiency**: Design agents that gather maximum information in minimum turns\n",
    "2. **Enhance Matching Intelligence**: Find connections and opportunities that simpler systems miss\n",
    "3. **Implement Robust Error Handling**: Ensure your system works reliably under all conditions\n",
    "4. **Monitor Performance Metrics**: Track token usage, response times, and recommendation quality\n",
    "5. **Test Edge Cases**: Validate behavior with unusual inputs and constraint scenarios\n",
    "\n",
    "## Preparing for Challenge Submission\n",
    "\n",
    "Your AI agent system is now ready to process the full challenge dataset. Remember:\n",
    "- **Results Format**: Ensure your output matches the required JSON Lines structure\n",
    "- **Quality over Quantity**: Focus on making intelligent recommendations rather than maximizing matches\n",
    "- **Resource Management**: Monitor API usage and optimize for cost-effectiveness\n",
    "- **Testing Validation**: Verify your system with diverse persona profiles before final submission\n",
    "\n",
    "## Advanced Techniques to Explore\n",
    "\n",
    "- **Ensemble Methods**: Combining multiple agent recommendations for improved accuracy\n",
    "- **Dynamic Prompt Engineering**: Adapting agent behavior based on persona responses\n",
    "- **Hierarchical Agent Systems**: Using supervisor agents to coordinate specialist agents\n",
    "- **Feedback Loops**: Learning from persona interactions to improve future conversations\n",
    "\n",
    "You now have the foundation to build intelligent, scalable AI agent systems. The techniques you've learned extend far beyond job matching - they're applicable to any domain requiring intelligent automation and human-AI collaboration.\n",
    "\n",
    "Good luck with the challenge!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}