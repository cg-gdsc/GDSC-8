{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 4: Multi-Agent System for Smart Matching\n",
    "\n",
    "Alright, your 5-10% score from Tutorial 3 was... expected. You literally gave everyone the same 5 jobs. Time to build something that actually works.\n",
    "\n",
    "---\n",
    "\n",
    "# Matching Rules\n",
    "\n",
    "To add extra clarity before you jump to work we wanted to share the basic matching rules that are used to define best matches. These rules are the baseline for decisions why certain persona is fit for a job. Although we all know that sometimes applying for a job you have no experience with could positively surprise you, **these hard filters exist for good reason**.\n",
    "\n",
    "Think of them as the \"minimum viable candidate\" criteria. Ignore them at your own risk - your accuracy will tank.\n",
    "\n",
    "## Hard Filters\n",
    "\n",
    "- **Domain matches the persona's target domain**.\n",
    "- **Location**:\n",
    "  - If the persona has a defined city â†’ the job must be in the same city or remote.\n",
    "  - If the persona is \"open to relocate\" â†’ there is no location constraint.\n",
    "- **Languages include at least one in common**.\n",
    "- **Education level** of the persona is equal to or greater than the job's requirement.\n",
    "- **Experience**: persona's years of experience are equal to or greater than the job's requirement.\n",
    "\n",
    "**Brazilian education levels** (in ascending order):\n",
    "\n",
    "Ensino Fundamental < Ensino MÃ©dio < TÃ©cnico < TecnÃ³logo < GraduaÃ§Ã£o < Bacharelado < Licenciatura < PÃ³s-graduaÃ§Ã£o < EspecializaÃ§Ã£o < Mestrado < MBA < Doutorado\n",
    "\n",
    "**If any of these filters fail, the job must not be recommended.**\n",
    "\n",
    "### Skills\n",
    "\n",
    "If a persona lacks required skills for a job:\n",
    "- The job must still be recommended (as long as it passes the hard filters).\n",
    "- Trainings must be suggested to cover all missing skills.\n",
    "\n",
    "Training recommendations must follow a strict level-by-level progression:\n",
    "- If the persona has no knowledge of a skill and the job requires IntermediÃ¡rio, suggest both BÃ¡sico and IntermediÃ¡rio (if available in the catalog).\n",
    "- If the persona has BÃ¡sico and the job requires AvanÃ§ado, suggest IntermediÃ¡rio and AvanÃ§ado (if available).\n",
    "- More generally: if the persona is at level $p$ and the job requires $r$, you must propose all trainings available from $p+1$ to $r$.\n",
    "- Missing levels in the catalog are acceptable. If no training exists for a given skill, the training list for that skill can remain empty (this is not a non-conformity).\n",
    "Skills should never be a blocker: if someone wants a job that requires a certain skill, this should not prevent those jobs from being suggested (although for a better user experience, it makes sense to prioritize them first).\n",
    "\n",
    "### Trainings\n",
    "\n",
    "Trainings are available at three levels:\n",
    "\n",
    "BÃ¡sico â†’ IntermediÃ¡rio â†’ AvanÃ§ado\n",
    "\n",
    "Rules for training recommendations:\n",
    "- A persona can only benefit from trainings above their current level.\n",
    "- If the persona already knows a skill at BÃ¡sico, recommend IntermediÃ¡rio or AvanÃ§ado, but not BÃ¡sico.\n",
    "- In standalone training mode (when no jobs are being recommended):\n",
    "  - Recommend only the next level above the current one.\n",
    "  - If the persona has no prior level, recommend only BÃ¡sico.\n",
    "  - Do not suggest multiple levels at once in this mode.\n",
    "- Personas may seek trainings either as a standalone goal or as preparation for a job.\n",
    "- If no relevant training exists, the list may remain empty.\n",
    "\n",
    "### Awareness\n",
    "\n",
    "Some personas are not yet ready for jobs or trainings. In these cases, your assistant should provide awareness content to help them explore and learn.\n",
    "Two possible cases:\n",
    "- **Too young:** If the persona is under 16, return awareness content with the reason \"too_young\".\n",
    "- **Seeking information:** If the persona is simply exploring (e.g., asking â€œWhat does an engineer do?â€), return awareness content with the reason \"info\".\n",
    "\n",
    "## Why These Rules Matter\n",
    "\n",
    "**Example failure**: Recommending a Doutorado-level research position to someone with Ensino MÃ©dio education.\n",
    "- **Human logic**: \"Maybe they'll accept it anyway!\"\n",
    "- **Reality**: Automatic rejection, wastes everyone's time\n",
    "- **Your score**: Takes a hit because it's an obviously bad match\n",
    "\n",
    "**Example success**: Finding a remote sustainability job for someone in a small city with environmental interests.\n",
    "- **Filters pass**: Location (remote), domain (environmental), experience level matches\n",
    "- **Result**: Realistic recommendation that could actually work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## What we're building\n",
    "\n",
    "A multi-agent system that:\n",
    "- **Interviews personas** to understand their background (and costs money doing it)\n",
    "- **Extracts structured data** from messy conversations into clean JSON\n",
    "- **Matches intelligently** using semantic understanding, not just keywords\n",
    "- **Handles all three types correctly** (jobs+trainings, trainings_only, awareness)\n",
    "- **Achieves 40-50% accuracy** (vs that embarrassing 5-10% from Tutorial 3)\n",
    "\n",
    "**Reality check**: This tutorial will cost you $5-10 in API credits. But you'll learn patterns worth way more than that in real consulting work.\n",
    "\n",
    "## The Competitive Landscape\n",
    "\n",
    "Look, everyone can do keyword matching. The teams hitting 60%+ are doing something smarter:\n",
    "- They're having actual conversations with personas\n",
    "- They're understanding context (\"I want to help the environment\" â†’ green jobs)\n",
    "- They're catching edge cases (minors need awareness, not jobs!)\n",
    "- They're being efficient with their API calls (remember: 5 conversations/day limit per persona)\n",
    "\n",
    "We're going to build that. And then share tips in Teams because the best collaborator award is pretty cool too.\n",
    "\n",
    "## Key Improvements in This Tutorial\n",
    "\n",
    "1. **Age-aware routing**: Minors (< 16) automatically get awareness type\n",
    "2. **Structured data extraction**: No more regex nightmares with Pydantic\n",
    "3. **Semantic matching**: Understanding \"sustainability\" = \"environmental\"\n",
    "4. **Training suggestions**: Worth 25% of your score - we won't ignore them!\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                     MULTI-AGENT ARCHITECTURE                    â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "Phase 1: INTERVIEW & EXTRACTION\n",
    "================================\n",
    "  Persona API\n",
    "      â†“\n",
    "  [Interview Agent] â† Conducts conversations (Medium model, $0.02/persona)\n",
    "      â†“\n",
    "  Raw Transcript\n",
    "      â†“\n",
    "  [Persona Extraction Agent] â† Structures conversation data (Small model, $0.001/extraction)\n",
    "      â†“\n",
    "  PersonaInfo (structured)\n",
    "\n",
    "Phase 2: DATA PROCESSING\n",
    "========================\n",
    "  Job Files â†’ [Job Extraction Agent] â†’ JobInfo (200 jobs)\n",
    "  Training Files â†’ [Training Extraction Agent] â†’ TrainingInfo (467 trainings)\n",
    "\n",
    "Phase 3: INTELLIGENT MATCHING\n",
    "==============================\n",
    "  PersonaInfo + JobInfo + TrainingInfo\n",
    "                â†“\n",
    "          [Matching Agent] â† Semantic matching (Medium model, $0.05/persona)\n",
    "                â†“\n",
    "          Recommendations\n",
    "                â†“\n",
    "            Submission\n",
    "```\n",
    "\n",
    "Each agent has ONE job. Think of it like a consulting team where everyone has their specialty. Nobody does everything well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup complete\n",
      "âœ… API connection successful!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Core imports\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import dotenv\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, TypeVar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Add parent directory to import our utilities\n",
    "sys.path.append('..')\n",
    "from src.utils import (\n",
    "    save_json,\n",
    "    read_json,\n",
    "    load_file_content,\n",
    "    get_job_paths,\n",
    "    get_training_paths,\n",
    "    sanity_check,\n",
    "\tchat_with_persona,\n",
    "    track_api_call,  # Cost tracking from utils\n",
    "    print_cost_summary,  # Cost summary from utils\n",
    "    reset_cost_tracker  # Reset cost tracker from utils\n",
    ")\n",
    "\n",
    "# Pydantic for structured data\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands for AI agents\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "# Type hints\n",
    "M = TypeVar('M', bound=BaseModel)\n",
    "\n",
    "# Set up submission directory\n",
    "SUBMISSION_DIR = Path('../submissions')\n",
    "SUBMISSION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load environment\n",
    "dotenv.load_dotenv(\"../env\")\n",
    "\n",
    "print(\"âœ… Setup complete\")\n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models (Why Pydantic Will Save Your Life)\n",
    "\n",
    "Remember Tutorial 3 where we just threw strings around? Yeah, that doesn't scale.\n",
    "\n",
    "**The problem with free-form LLM output:**\n",
    "```\n",
    "\"Maria seems good for environmental jobs in SÃ£o Paulo, maybe needs data training\"\n",
    "```\n",
    "\n",
    "**What we actually need:**\n",
    "```python\n",
    "PersonaInfo(\n",
    "    name=\"Maria Santos\",\n",
    "    skills=[(\"sustainability\", \"intermediate\"), (\"project_management\", \"beginner\")],\n",
    "    location=\"SÃ£o Paulo\"\n",
    ")\n",
    "```\n",
    "\n",
    "Pydantic models force the LLM to give us structured data. No more regex parsing nightmares. This is the difference between hobby projects and production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonaInfo(BaseModel):\n",
    "    \"\"\"Structured profile of a job seeker\"\"\"\n",
    "    name: str = Field(default=\"\", description=\"Persona's name\")\n",
    "    skills: List[Tuple[str, str]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of (skill, level) pairs\"\n",
    "    )\n",
    "    location: str = Field(default=\"unknown\")\n",
    "    age: str = Field(default=\"unknown\")\n",
    "    years_of_experience: str = Field(default=\"unknown\")\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skills = ', '.join([f'{s}: {l}' for s, l in self.skills])\n",
    "        return f\"Name: {self.name}\\nSkills: {skills}\\nLocation: {self.location}\\nAge: {self.age}\\nExperience: {self.years_of_experience} years\"\n",
    "\n",
    "\n",
    "class JobInfo(BaseModel):\n",
    "    \"\"\"Structured job requirements\"\"\"\n",
    "    required_skills: List[str] = Field(default_factory=list)\n",
    "    location: str = Field(default=\"\")\n",
    "    years_of_experience_required: str = Field(default=\"\")\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skills = ', '.join(self.required_skills)\n",
    "        return f\"Skills: {skills}\\nLocation: {self.location}\\nExperience: {self.years_of_experience_required}\"\n",
    "\n",
    "\n",
    "class TrainingInfo(BaseModel):\n",
    "    \"\"\"Training program details\"\"\"\n",
    "    skill_acquired_and_level: Tuple[str, str] = Field(\n",
    "        default=(\"not specified\", \"not specified\")\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skill, level = self.skill_acquired_and_level\n",
    "        return f\"Teaches: {skill} (Level: {level})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Agent Factory\n",
    "\n",
    "Here's where we create agents with different personalities. Think of this as the HR department of our AI company - we're hiring specialists, not generalists.\n",
    "\n",
    "**Why multiple agents instead of one mega-prompt?**\n",
    "- Each agent can use different models (small for extraction = cheap, large for reasoning = smart)\n",
    "- Easier to debug when something inevitably goes wrong\n",
    "- Costs less (use the cheapest model that gets the job done)\n",
    "- **Context overload prevention** - LLMs get confused with too much at once!\n",
    "\n",
    "It's like asking someone to read 200 resumes while conducting an interview while making hiring decisions. Nobody does that well. Split the work, get better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(\n",
    "    system_prompt: str = \"\",\n",
    "    model_id: str = \"mistral-medium-latest\"\n",
    ") -> Agent:\n",
    "    \"\"\"Create an AI agent with specific role and model\"\"\"\n",
    "    model = MistralModel(\n",
    "        api_key=os.environ[\"MISTRAL_API_KEY\"],\n",
    "        model_id=model_id,\n",
    "        stream=False\n",
    "    )\n",
    "    return Agent(model=model, system_prompt=system_prompt, callback_handler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 1: Interview Agent\n",
    "\n",
    "- **Purpose**: Conduct structured interviews with personas\n",
    "- **Model**: Medium (needs good conversation skills)\n",
    "- **Cost**: ~$0.02 per persona\n",
    "\n",
    "Time to build agents that actually talk to personas. This is where your money starts disappearing.\n",
    "\n",
    "### The Persona System Reality Check\n",
    "\n",
    "**âš ï¸ CRITICAL LIMITS:**\n",
    "- **5 conversations per day** per persona\n",
    "- **20 messages max** per conversation (10 on each side)\n",
    "- **30k tokens per persona** per conversation\n",
    "  - when chatting with a persona, this persona calls Mistral and consumes token. The persona should not exceed 30k tokens during the conversation\n",
    "- **Conversation IDs** must be tracked (or you lose context)\n",
    "- **1 submission** per week\n",
    "\n",
    "**Translation**: You can't just spam personas with questions. Be smart or run out of attempts.\n",
    "\n",
    "### Conversation Strategy That Actually Works\n",
    "\n",
    "**Bad approach** (what everyone tries first):\n",
    "```\n",
    "\"Hi, tell me everything about yourself\"\n",
    "*persona gives vague answer*\n",
    "\"Uh... tell me more?\"\n",
    "*waste 20 messages getting nothing*\n",
    "```\n",
    "\n",
    "**Good approach** (what we're building):\n",
    "```\n",
    "\"Hi! What's your name?\"\n",
    "\"What are your top skills and how experienced are you with each?\"\n",
    "\"Where are you located and are you willing to relocate?\"\n",
    "*Get everything in 5 messages*\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤ Testing Interview Agent...\n",
      "Assistant: Hello! I'm here to help you find the best opportunities. Can you tell me your name?\n",
      "User: hi my name is rafael ribeiro. i am 21 and i like food things.\n",
      "Assistant: Great, Rafael! Letâ€™s keep this quick and focused:\n",
      "\n",
      "1. **Skills & Proficiency**: What technical or professional skills do you have (e.g., cooking, food science, customer service, inventory management)? Rate your proficiency for each (Beginner/Intermediate/Advanced).\n",
      "2. **Current Location**: Where are you based (city/country)? Are you open to relocating?\n",
      "3. **Experience**: How many years of formal work experience do you have (paid/unpaid, including internships or part-time roles)?\n",
      "4. **Food Focus**: Do you specialize in any area (e.g., culinary arts, food tech, nutrition, hospitality)?\n",
      "\n",
      "*(Example: \"I have 2 years of experience as a line cook (Intermediate) and 1 year in food delivery logistics (Beginner).\")*\n",
      "\n",
      "User: 1. i dont have skils yet. i just know food is important and i wanna lern how to make it safe.\n",
      "2. i live in sao paulo. no move.\n",
      "3. zero years. but i can lern fast if i see the food lines?\n",
      "4. i like how food is made clean. like in factorys. do they let studnts touh the mashines?\n",
      "Assistant: Got it, Rafael! Hereâ€™s what Iâ€™m notingâ€”correct me if Iâ€™m wrong:\n",
      "\n",
      "- **Name**: Rafael Ribeiro\n",
      "- **Age**: 21\n",
      "- **Location**: SÃ£o Paulo, Brazil (not open to relocating)\n",
      "- **Experience**: 0 years (but eager to learn, especially in food safety/manufacturing)\n",
      "- **Skills**: None yet, but interested in:\n",
      "  - Food safety protocols\n",
      "  - Factory/hygienic food production\n",
      "  - Hands-on machine operation (e.g., processing lines)\n",
      "\n",
      "**Quick follow-ups**:\n",
      "1. **Education**: Are you currently studying (e.g., high school, food tech courses) or would you need training from scratch?\n",
      "2. **Language**: Do you speak/read English (for safety manuals or certifications), or only Portuguese?\n",
      "3. **Physical Work**: Food factories often require standing, lifting, or repetitive tasksâ€”are you comfortable with that?\n",
      "4. **Certifications**: Would you be willing to get a basic food safety certificate (like *ANVISA*â€™s requirements in Brazil) if it helped you get a job?\n",
      "\n",
      "*(Example: \"Yes, I can lift 10kg, and Iâ€™ll study for ANVISA rules if needed.\")*\n",
      "\n",
      "---\n",
      "*Next, Iâ€™d ask about your ideal first step (e.g., apprenticeship, short course), but letâ€™s confirm the above first.*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interview Agent implementation\n",
    "INTERVIEW_PROMPT = \"\"\"\n",
    "You are conducting a career counseling interview. Gather:\n",
    "- Name\n",
    "- Skills and proficiency levels\n",
    "- Current location\n",
    "- Age\n",
    "- Years of experience\n",
    "\n",
    "Ask targeted questions to get specific information quickly.\n",
    "Do not provide job recommendations yet.\n",
    "\"\"\"\n",
    "\n",
    "def conduct_persona_interview(\n",
    "    persona_id: str,\n",
    "    max_turns: int = 5,\n",
    "    model: str = \"mistral-medium-latest\",\n",
    "    print_conversation: bool = False\n",
    ") -> List[str]:\n",
    "    \"\"\"Interview a persona and return conversation transcript\"\"\"\n",
    "\n",
    "    conversation = []\n",
    "    interview_agent = get_agent(INTERVIEW_PROMPT, model_id=model)\n",
    "    conversation_id = None\n",
    "\n",
    "    # Start with greeting\n",
    "    agent_message = \"Hello! I'm here to help you find the best opportunities. Can you tell me your name?\"\n",
    "    conversation.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    # Conduct interview\n",
    "    for _ in range(max_turns):\n",
    "        resp = chat_with_persona(persona_id, agent_message, conversation_id)\n",
    "\n",
    "        if resp is None:\n",
    "            break\n",
    "\n",
    "        user_response, conversation_id = resp\n",
    "        conversation.append(f\"User: {user_response}\")\n",
    "\n",
    "        # Generate next question\n",
    "        agent_response = interview_agent(user_response)\n",
    "\n",
    "        # Track cost (using utils.py function)\n",
    "        track_api_call(agent_response, model)\n",
    "\n",
    "        agent_message = str(agent_response)\n",
    "        conversation.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    if print_conversation:\n",
    "        print('\\n'.join(conversation))\n",
    "\n",
    "    return conversation\n",
    "\n",
    "# Test it\n",
    "print(\"ðŸŽ¤ Testing Interview Agent...\")\n",
    "test_interview = conduct_persona_interview(\n",
    "    \"persona_001\",\n",
    "    max_turns=2,\n",
    "    print_conversation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 2: Extraction Agents (Yes, Plural!)\n",
    "\n",
    "- **Purpose**: Convert unstructured text to structured data\n",
    "- **Model**: Small (simple structured extraction)\n",
    "- **Cost**: ~$0.001 per extraction\n",
    "\n",
    "We actually have THREE extraction agents - think of them as specialist junior analysts:\n",
    "1. **Persona Extraction Agent**: Pulls name, skills, location from conversations\n",
    "2. **Job Extraction Agent**: Extracts requirements from job descriptions\n",
    "3. **Training Extraction Agent**: Gets skill outcomes from training programs\n",
    "\n",
    "Why three agents instead of one? Each has a specific prompt optimized for its data type. It's like having specialists who know exactly what to look for.\n",
    "\n",
    "The beauty of extraction agents is we can use a cheap model - it's just pattern matching and structuring, not complex reasoning. Save the expensive models for when you actually need intelligence.\n",
    "\n",
    "### The Magic of .structured_output()\n",
    "\n",
    "Here's the game-changer. Instead of this nightmare:\n",
    "```python\n",
    "# Old way - pray the LLM formats correctly\n",
    "response = agent(\"Extract the skills...\")\n",
    "# Now parse the string and hope it's valid JSON...\n",
    "# Handle 17 different ways the LLM might format it...\n",
    "```\n",
    "\n",
    "We do this:\n",
    "```python\n",
    "# New way - guaranteed valid Pydantic model\n",
    "result = agent.structured_output(output_model=PersonaInfo, prompt=prompt)\n",
    "# result is ALWAYS a valid PersonaInfo object!\n",
    "```\n",
    "\n",
    "**Why .structured_output() is perfect for our problem:**\n",
    "- Forces the LLM to return data that matches our Pydantic schema exactly\n",
    "- No more regex parsing, no more \"hope it's valid JSON\"\n",
    "- If a field is missing, Pydantic uses the default value\n",
    "- Type validation built-in (can't put a string where we expect a list)\n",
    "- **100% consistent output structure** - crucial when processing 100 personas\n",
    "\n",
    "This is the difference between a hackathon project and production code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Testing Persona Extraction Agent...\n",
      "Name: Rafael Ribeiro\n",
      "Skills: Food safety protocols: Beginner, Factory/hygienic food production: Beginner, Hands-on machine operation: Beginner\n",
      "Location: SÃ£o Paulo, Brazil\n",
      "Age: 21\n",
      "Experience: 0 years\n"
     ]
    }
   ],
   "source": [
    "# Three specialized extraction prompts - each optimized for its data type\n",
    "PERSONA_EXTRACTION_PROMPT = \"\"\"Extract the following information from this conversation:\n",
    "- Name\n",
    "- Skills (as pairs of skill name and proficiency level)\n",
    "- Location\n",
    "- Age\n",
    "- Years of experience\n",
    "\n",
    "Conversation:\n",
    "\"\"\"\n",
    "\n",
    "JOB_EXTRACTION_PROMPT = \"\"\"Extract from this job description:\n",
    "- Required skills (list)\n",
    "- Location\n",
    "- Years of experience required\n",
    "\n",
    "Job description:\n",
    "\"\"\"\n",
    "\n",
    "TRAINING_EXTRACTION_PROMPT = \"\"\"Extract from this training description:\n",
    "- Skill taught and its level\n",
    "\n",
    "Training description:\n",
    "\"\"\"\n",
    "\n",
    "def extract_persona_info(\n",
    "    conversation: List[str],\n",
    "    model: str = \"mistral-small-latest\"\n",
    ") -> PersonaInfo:\n",
    "    \"\"\"Extract persona info from conversation using Persona Extraction Agent\"\"\"\n",
    "    text = '\\n'.join(conversation)\n",
    "    prompt = PERSONA_EXTRACTION_PROMPT + text\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model)\n",
    "    result = extraction_agent.structured_output(output_model=PersonaInfo, prompt=prompt)\n",
    "\n",
    "    # Track cost\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_job_info(\n",
    "    path: Path,\n",
    "    model: str = \"mistral-small-latest\"\n",
    ") -> JobInfo:\n",
    "    \"\"\"Extract job info from file using Job Extraction Agent\"\"\"\n",
    "    text = load_file_content(path)\n",
    "    prompt = JOB_EXTRACTION_PROMPT + text\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model)\n",
    "    result = extraction_agent.structured_output(output_model=JobInfo, prompt=prompt)\n",
    "\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_training_info(\n",
    "    path: Path,\n",
    "    model: str = \"mistral-small-latest\"\n",
    ") -> TrainingInfo:\n",
    "    \"\"\"Extract training info from file using Training Extraction Agent\"\"\"\n",
    "    text = load_file_content(path)\n",
    "    prompt = TRAINING_EXTRACTION_PROMPT + text\n",
    "\n",
    "    extraction_agent = get_agent(model_id=model)\n",
    "    result = extraction_agent.structured_output(output_model=TrainingInfo, prompt=prompt)\n",
    "\n",
    "    if hasattr(extraction_agent, 'last_response'):\n",
    "        track_api_call(extraction_agent.last_response, model)\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test extraction on conversation\n",
    "print(\"ðŸ” Testing Persona Extraction Agent...\")\n",
    "test_persona = extract_persona_info(test_interview)\n",
    "print(test_persona.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's See the Other Extraction Agents in Action\n",
    "\n",
    "Now let's test our Job and Training extraction agents on real files. This shows you exactly what structured data we're pulling out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¼ Testing Job Extraction Agent...\n",
      "Reading a sample job file...\n",
      "\n",
      "Job ID: job_acc_001\n",
      "Skills: Tax regulations and compliance processes at an intermediate level, Attention to detail, Organizational skills, Fluent in Portuguese (Brazilian), Fluent in English\n",
      "Location: BrasÃ­lia\n",
      "Experience: 2 years\n",
      "\n",
      "Raw Pydantic model:\n",
      "{'required_skills': ['Tax regulations and compliance processes at an intermediate level', 'Attention to detail', 'Organizational skills', 'Fluent in Portuguese (Brazilian)', 'Fluent in English'], 'location': 'BrasÃ­lia', 'years_of_experience_required': '2 years'}\n"
     ]
    }
   ],
   "source": [
    "# Test Job Extraction Agent\n",
    "print(\"ðŸ’¼ Testing Job Extraction Agent...\")\n",
    "print(\"Reading a sample job file...\\n\")\n",
    "\n",
    "# Get first job file\n",
    "job_paths = get_job_paths()\n",
    "if job_paths:\n",
    "    sample_job = extract_job_info(job_paths[0])\n",
    "    print(f\"Job ID: {job_paths[0].stem}\")\n",
    "    print(sample_job.describe())\n",
    "    print(\"\\nRaw Pydantic model:\")\n",
    "    print(sample_job.model_dump())\n",
    "else:\n",
    "    print(\"No job files found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“š Testing Training Extraction Agent...\n",
      "Reading a sample training file...\n",
      "\n",
      "Training ID: tr_adm_client_record_management_01\n",
      "Teaches: Basic Customer Data Management (Level: foundational level)\n",
      "\n",
      "Raw Pydantic model:\n",
      "{'skill_acquired_and_level': ('Basic Customer Data Management', 'foundational level')}\n",
      "\n",
      "==================================================\n",
      "âœ… All three extraction agents tested!\n"
     ]
    }
   ],
   "source": [
    "# Test Training Extraction Agent\n",
    "print(\"ðŸ“š Testing Training Extraction Agent...\")\n",
    "print(\"Reading a sample training file...\\n\")\n",
    "\n",
    "# Get first training file\n",
    "training_paths = get_training_paths()\n",
    "if training_paths:\n",
    "    sample_training = extract_training_info(training_paths[0])\n",
    "    print(f\"Training ID: {training_paths[0].stem}\")\n",
    "    print(sample_training.describe())\n",
    "    print(\"\\nRaw Pydantic model:\")\n",
    "    print(sample_training.model_dump())\n",
    "else:\n",
    "    print(\"No training files found!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"âœ… All three extraction agents tested!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent 3: Matching Agent\n",
    "\n",
    "- **Purpose**: Semantic matching between personas and opportunities\n",
    "- **Model**: Medium (needs reasoning capabilities)\n",
    "- **Cost**: ~$0.05 per persona\n",
    "\n",
    "This is where the magic happens. The \"Senior Consultant\" of our team that actually understands context.\n",
    "\n",
    "### Semantic Matching vs Keyword Matching\n",
    "\n",
    "**Keyword matching**:\n",
    "- Person has \"sustainability\" â†’ Job needs \"environmental\" â†’ âŒ No match\n",
    "- Person in \"Greater SÃ£o Paulo\" â†’ Job in \"SÃ£o Paulo\" â†’ âŒ No match  \n",
    "- \"Data analysis\" â†’ \"Analytics\" â†’ âŒ No match\n",
    "\n",
    "**Semantic matching** (what we're doing now):\n",
    "- Agent understands \"sustainability\" = \"environmental\" = \"green energy\" = \"climate action\"\n",
    "- Knows \"Greater SÃ£o Paulo\" includes \"SÃ£o Paulo\" \n",
    "- Recognizes \"data analysis\" skills transfer to \"analytics\" roles\n",
    "\n",
    "**Example**: Maria, sustainability consultant, 3 years experience, SÃ£o Paulo\n",
    "\n",
    "**Simple matcher**: Looks for jobs with \"sustainability\" and \"consultant\" in the title. Finds 2.\n",
    "\n",
    "**Our semantic matcher**: \n",
    "- Understands she could do environmental consulting, ESG reporting, green project management\n",
    "- Knows her consulting skills transfer to advisory, strategy, implementation roles\n",
    "- Recognizes SÃ£o Paulo includes opportunities in the greater metro area\n",
    "- Finds 15 relevant opportunities\n",
    "\n",
    "That's the difference between 10% and 50% accuracy on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_matches(\n",
    "    persona_info: PersonaInfo,\n",
    "    jobs_text: str,  # Pre-built context to avoid rebuilding\n",
    "    model: str = \"mistral-medium-latest\"\n",
    ") -> List[str]:\n",
    "    \"\"\"Find suitable jobs for a persona using semantic matching\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"Available jobs:\n",
    "{jobs_text}\n",
    "\n",
    "Candidate profile:\n",
    "{persona_info.describe()}\n",
    "\n",
    "Return a list of up to 4 job IDs that best match this candidate.\n",
    "Consider skill transferability and semantic similarities.\n",
    "Return as a JSON list like [\"job_001\", \"job_002\"]\n",
    "\"\"\"\n",
    "\n",
    "    agent = get_agent(model_id=model)\n",
    "    response = agent(prompt)\n",
    "\n",
    "    # Track cost\n",
    "    track_api_call(response, model)\n",
    "\n",
    "    # Parse response - handle markdown code blocks\n",
    "    try:\n",
    "        response_str = str(response)\n",
    "        # Remove markdown code block markers if present\n",
    "        if response_str.startswith('```'):\n",
    "            # Extract content between code blocks\n",
    "            lines = response_str.split('\\n')\n",
    "            # Find start and end of code block\n",
    "            start_idx = 0\n",
    "            end_idx = len(lines)\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.startswith('```') and start_idx == 0:\n",
    "                    start_idx = i + 1\n",
    "                elif line.startswith('```') and i > start_idx:\n",
    "                    end_idx = i\n",
    "                    break\n",
    "            response_str = '\\n'.join(lines[start_idx:end_idx])\n",
    "\n",
    "        result = json.loads(response_str)\n",
    "        return result if isinstance(result, list) else []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def find_training_matches(\n",
    "    persona_info: PersonaInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo],\n",
    "    model: str = \"mistral-medium-latest\"\n",
    ") -> List[str]:\n",
    "    \"\"\"Find suitable trainings for a persona\"\"\"\n",
    "\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "\n",
    "    prompt = f\"\"\"Available trainings:\n",
    "{trainings_text}\n",
    "\n",
    "Candidate profile:\n",
    "{persona_info.describe()}\n",
    "\n",
    "Return up to 4 training IDs that would benefit this candidate.\n",
    "Return as a JSON list like [\"tr_001\", \"tr_002\"]\n",
    "\"\"\"\n",
    "\n",
    "    agent = get_agent(model_id=model)\n",
    "    response = agent(prompt)\n",
    "\n",
    "    track_api_call(response, model)\n",
    "\n",
    "    # Parse response - handle markdown code blocks\n",
    "    try:\n",
    "        response_str = str(response)\n",
    "        # Remove markdown code block markers if present\n",
    "        if response_str.startswith('```'):\n",
    "            # Extract content between code blocks\n",
    "            lines = response_str.split('\\n')\n",
    "            # Find start and end of code block\n",
    "            start_idx = 0\n",
    "            end_idx = len(lines)\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.startswith('```') and start_idx == 0:\n",
    "                    start_idx = i + 1\n",
    "                elif line.startswith('```') and i > start_idx:\n",
    "                    end_idx = i\n",
    "                    break\n",
    "            response_str = '\\n'.join(lines[start_idx:end_idx])\n",
    "\n",
    "        result = json.loads(response_str)\n",
    "        return result if isinstance(result, list) else []\n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline\n",
    "\n",
    "Now let's process all jobs and trainings. First time running this? Grab coffee. We're processing 200 jobs and 467 trainings.\n",
    "\n",
    "**Cost alert**: ~$2-3 to process everything with medium model. But here's the beautiful part - we cache everything. Run it once, pay once. If it crashes halfway? Just run again, it picks up where it left off. We're not savages.\n",
    "\n",
    "### Production Patterns That Matter\n",
    "\n",
    "**Caching** (never pay twice for the same thing):\n",
    "- Process all jobs once, save to JSON\n",
    "- Process all trainings once, save to JSON\n",
    "- If your code crashes, you don't lose everything\n",
    "\n",
    "**Batch Processing** (with progress bars because we're not animals):\n",
    "- Shows you exactly where you are\n",
    "- Saves progress every N items\n",
    "- Can resume from interruptions\n",
    "- **Now with cost updates!** See your spending as you go\n",
    "\n",
    "**Error Handling** (because everything fails eventually):\n",
    "- Retry with exponential backoff\n",
    "- Log failures for debugging\n",
    "- Graceful degradation (partial results > no results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_extract(\n",
    "    paths: List[Path],\n",
    "    extract_func,\n",
    "    save_path: Path,\n",
    "    cache_period: int = 20,\n",
    "    show_cost_every: int = 20\n",
    "):\n",
    "    \"\"\"Batch extract information with caching and cost tracking\n",
    "\n",
    "    Args:\n",
    "        paths: List of files to process\n",
    "        extract_func: Function to extract info from each file\n",
    "        save_path: Path to save extracted data\n",
    "        cache_period: Save progress every N items\n",
    "        show_cost_every: Display cost summary every N items\n",
    "    \"\"\"\n",
    "\n",
    "    if not save_path.exists():\n",
    "        save_json(save_path, {})\n",
    "\n",
    "    extracted = read_json(save_path)\n",
    "\n",
    "    print(f\"Processing {len(paths)} files ({len(extracted)} already cached)\")\n",
    "\n",
    "    # Reset cost tracker for this batch operation\n",
    "    if len(extracted) == 0:  # Only reset if starting fresh\n",
    "        reset_cost_tracker()\n",
    "\n",
    "    counter = 0\n",
    "    new_items_processed = 0\n",
    "\n",
    "    for path in tqdm(paths):\n",
    "        id_ = path.stem\n",
    "        if id_ not in extracted:\n",
    "            try:\n",
    "                info = extract_func(path)\n",
    "                extracted[id_] = info.model_dump_json()\n",
    "                counter += 1\n",
    "                new_items_processed += 1\n",
    "\n",
    "                # Save progress periodically\n",
    "                if counter % cache_period == 0:\n",
    "                    save_json(save_path, extracted)\n",
    "\n",
    "                # Show cost update periodically\n",
    "                if new_items_processed > 0 and new_items_processed % show_cost_every == 0:\n",
    "                    print(f\"\\nðŸ’° Cost update after {new_items_processed} new items:\")\n",
    "                    print_cost_summary()\n",
    "                    print()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {id_}: {e}\")\n",
    "\n",
    "    save_json(save_path, extracted)\n",
    "\n",
    "    # Final cost summary if we processed any new items\n",
    "    if new_items_processed > 0:\n",
    "        print(f\"\\nâœ… Processed {new_items_processed} new items\")\n",
    "        print_cost_summary()\n",
    "\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing Jobs...\n",
      "Processing 200 files (200 already cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 178405.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 200 jobs\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all jobs\n",
    "print(\"ðŸ“‚ Processing Jobs...\")\n",
    "jobs_save_path = SUBMISSION_DIR / 'extracted_jobs.json'\n",
    "\n",
    "jobs_data = batch_extract(\n",
    "    get_job_paths(),\n",
    "    extract_job_info,\n",
    "    jobs_save_path,\n",
    "    show_cost_every=50  # Show cost update every 50 items\n",
    ")\n",
    "\n",
    "# Convert to JobInfo objects\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(data)\n",
    "    for job_id, data in jobs_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Extracted {len(jobs_info)} jobs\")\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Processing Trainings...\n",
      "Processing 467 files (467 already cached)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 467/467 [00:00<00:00, 416487.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Extracted 467 trainings\n",
      "\n",
      "==================================================\n",
      "ðŸ“Š Total extraction cost so far:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 3\n",
      "  Total tokens: 1,390\n",
      "  Estimated cost: $0.0019\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 3 calls, $0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all trainings\n",
    "print(\"ðŸ“‚ Processing Trainings...\")\n",
    "trainings_save_path = SUBMISSION_DIR / 'extracted_trainings.json'\n",
    "\n",
    "# Note: batch_extract now includes cost tracking!\n",
    "trainings_data = batch_extract(\n",
    "    get_training_paths(),\n",
    "    extract_training_info,\n",
    "    trainings_save_path,\n",
    "    show_cost_every=100  # Show cost update every 100 items\n",
    ")\n",
    "\n",
    "# Convert to TrainingInfo objects\n",
    "trainings_info = {\n",
    "    training_id: TrainingInfo.model_validate_json(data)\n",
    "    for training_id, data in trainings_data.items()\n",
    "}\n",
    "\n",
    "print(f\"âœ… Extracted {len(trainings_info)} trainings\")\n",
    "\n",
    "# Show cumulative cost for both job and training extraction\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸ“Š Total extraction cost so far:\")\n",
    "print_cost_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the System (Before You Blow $10 on Broken Code)\n",
    "\n",
    "Always test with fake data first. Seriously. I know you want to just run everything, but trust me on this one.\n",
    "\n",
    "**Quick math for talking to 100 personas:**\n",
    "- ~2000 tokens per conversation (input + output)\n",
    "- 100 personas = 200,000 tokens\n",
    "- Cost: ~$0.02 with small model, ~$0.40 with large model\n",
    "- **But wait**: You'll retry failed conversations, test your code, mess up... \n",
    "- **Real cost**: Probably $5-10 for this tutorial if you do the exercises\n",
    "\n",
    "Let's test with one persona before we burn through our budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Test Persona:\n",
      "Name: Maria Silva\n",
      "Skills: sustainability: intermediate, project_management: beginner\n",
      "Location: SÃ£o Paulo\n",
      "Age: 24\n",
      "Experience: 2 years\n",
      "\n",
      "==================================================\n",
      "\n",
      "ðŸŽ¯ Job Matches: ['job_soc_008', 'job_tou_003', 'job_fib_009', 'job_pro_007']\n",
      "ðŸ“š Training Matches: ['tr_fib_eco_regulations_02', 'tr_fib_waste_management_02', 'tr_pro_process_optimization_01', 'tr_pur_risk_management_supply_01']\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 5\n",
      "  Total tokens: 25,768\n",
      "  Estimated cost: $0.0118\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 5 calls, $0.0118\n"
     ]
    }
   ],
   "source": [
    "# Create test persona\n",
    "test_persona = PersonaInfo(\n",
    "    name='Maria Silva',\n",
    "    skills=[('sustainability', 'intermediate'), ('project_management', 'beginner')],\n",
    "    location='SÃ£o Paulo',\n",
    "    age='24',\n",
    "    years_of_experience='2'\n",
    ")\n",
    "\n",
    "print(\"ðŸ§ª Test Persona:\")\n",
    "print(test_persona.describe())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "# Pre-build jobs text for efficiency\n",
    "jobs_text = \"\\n\".join([\n",
    "    f'{job_id}: {job_info.describe()}'\n",
    "    for job_id, job_info in jobs_info.items()\n",
    "])\n",
    "\n",
    "# Find matches\n",
    "test_jobs = find_job_matches(test_persona, jobs_text)\n",
    "print(f\"\\nðŸŽ¯ Job Matches: {test_jobs}\")\n",
    "\n",
    "test_trainings = find_training_matches(test_persona, trainings_info)\n",
    "print(f\"ðŸ“š Training Matches: {test_trainings}\")\n",
    "\n",
    "# Check cost so far\n",
    "print_cost_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Practice Exercise: Manual Matching\n",
    "\n",
    "Before we run the automated matching, let's build some intuition. Look at the extracted persona info above and think:\n",
    "1. What kind of jobs would suit Maria?\n",
    "2. What trainings might help her qualify for better roles?\n",
    "\n",
    "**Your turn**: Based on Maria's profile (sustainability skills, project management beginner, SÃ£o Paulo, 2 years experience), which of these would you recommend?\n",
    "- job_env_001: Environmental Analyst (SÃ£o Paulo, requires: data analysis, sustainability)\n",
    "- job_mkt_005: Marketing Manager (Rio, requires: marketing, leadership)\n",
    "- job_sus_003: Sustainability Coordinator (SÃ£o Paulo, requires: sustainability, project management)\n",
    "- tr_pm_101: Project Management Fundamentals\n",
    "- tr_data_202: Data Analysis for Environmental Science\n",
    "\n",
    "Think about it, then run the cell below to see what our agents recommend!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process All 100 Personas\n",
    "\n",
    "**âš ï¸ THIS WILL COST REAL MONEY âš ï¸**\n",
    "\n",
    "Estimated cost: $3-5 for all 100 personas (assuming some failures and retries)\n",
    "\n",
    "**Before you run this:**\n",
    "1. âœ… Have you tested with 1-2 personas? \n",
    "2. âœ… Did the extraction work correctly?\n",
    "3. âœ… Are your matches reasonable?\n",
    "4. âœ… Do you have $10 to spare?\n",
    "\n",
    "If you answered no to any of these, go back and test more.\n",
    "\n",
    "**What's happening here:**\n",
    "- Our **Interview Agent** talks to each persona\n",
    "- Our **Extraction Agent** structures the conversation data\n",
    "- We save progress every 5 personas (in case something breaks)\n",
    "- Total time: ~10-15 minutes for all 100\n",
    "\n",
    "**Pro tip**: Comment out the loop and run with just `persona_ids[:20]` first to test with 20 personas. Your wallet will thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personas to process: 60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 60/100 [11:32<17:22, 26.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Cost update after 20 new personas:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 184\n",
      "  Total tokens: 317,843\n",
      "  Estimated cost: $0.3690\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 184 calls, $0.3690\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 80/100 [24:52<18:51, 56.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Cost update after 40 new personas:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 244\n",
      "  Total tokens: 444,189\n",
      "  Estimated cost: $0.5198\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 244 calls, $0.5198\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [34:15<00:00, 20.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Cost update after 60 new personas:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 286\n",
      "  Total tokens: 536,314\n",
      "  Estimated cost: $0.6293\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 286 calls, $0.6293\n",
      "\n",
      "\n",
      "âœ… Interviewed 100 personas total (60 new)\n",
      "\n",
      "ðŸ“Š Persona processing costs:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 286\n",
      "  Total tokens: 536,314\n",
      "  Estimated cost: $0.6293\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 286 calls, $0.6293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Interview all personas\n",
    "persona_ids = [f'persona_{i:03}' for i in range(1, 101)]\n",
    "personas_save_path = SUBMISSION_DIR / 'personas.json'\n",
    "\n",
    "if not personas_save_path.exists():\n",
    "    save_json(personas_save_path, {})\n",
    "\n",
    "persona_infos = read_json(personas_save_path)\n",
    "personas_to_process = len(persona_ids) - len(persona_infos)\n",
    "print(f'Personas to process: {personas_to_process}')\n",
    "\n",
    "# Reset cost tracker if starting fresh\n",
    "if len(persona_infos) == 0:\n",
    "    reset_cost_tracker()\n",
    "    print(\"ðŸ’° Starting fresh - cost tracker reset\")\n",
    "\n",
    "# Track how many new personas we process\n",
    "new_personas_processed = 0\n",
    "\n",
    "for persona_id in tqdm(persona_ids):\n",
    "    if persona_id not in persona_infos:\n",
    "        # Interview\n",
    "        conversation = conduct_persona_interview(persona_id, max_turns=3)\n",
    "\n",
    "        # Extract\n",
    "        persona_info = extract_persona_info(conversation)\n",
    "        persona_infos[persona_id] = persona_info.model_dump_json()\n",
    "        new_personas_processed += 1\n",
    "\n",
    "        # Save every 5 personas\n",
    "        if len(persona_infos) % 5 == 0:\n",
    "            save_json(personas_save_path, persona_infos)\n",
    "\n",
    "        # Show cost update every 20 personas\n",
    "        if new_personas_processed > 0 and new_personas_processed % 20 == 0:\n",
    "            print(f\"\\nðŸ’° Cost update after {new_personas_processed} new personas:\")\n",
    "            print_cost_summary()\n",
    "            print()\n",
    "\n",
    "save_json(personas_save_path, persona_infos)\n",
    "\n",
    "# Convert to PersonaInfo objects\n",
    "personas = {\n",
    "    pid: PersonaInfo.model_validate_json(data)\n",
    "    for pid, data in persona_infos.items()\n",
    "}\n",
    "\n",
    "print(f\"\\nâœ… Interviewed {len(personas)} personas total ({new_personas_processed} new)\")\n",
    "\n",
    "# Final cost summary for persona processing\n",
    "if new_personas_processed > 0:\n",
    "    print(\"\\nðŸ“Š Persona processing costs:\")\n",
    "    print_cost_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping trainings to jobs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 1545.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# Match trainings to jobs first\n",
    "# Pre-build jobs text ONCE for efficiency\n",
    "jobs_text = \"\\n\".join([\n",
    "    f'{job_id}: {job_info.describe()}'\n",
    "    for job_id, job_info in jobs_info.items()\n",
    "])\n",
    "\n",
    "job_training_map = {}\n",
    "for job_id, job_info in tqdm(jobs_info.items(), desc=\"Mapping trainings to jobs\"):\n",
    "    # Simple heuristic: find trainings that teach required skills\n",
    "    relevant_trainings = []\n",
    "    for tid, tinfo in trainings_info.items():\n",
    "        skill_name = tinfo.skill_acquired_and_level[0].lower()\n",
    "        if any(skill_name in req.lower() for req in job_info.required_skills):\n",
    "            relevant_trainings.append(tid)\n",
    "            if len(relevant_trainings) >= 3:\n",
    "                break\n",
    "    job_training_map[job_id] = relevant_trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Starting matching phase - resetting cost tracker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations:  27%|â–ˆâ–ˆâ–‹       | 27/100 [01:13<03:17,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Matching progress - 25 personas matched:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 25\n",
      "  Total tokens: 305,525\n",
      "  Estimated cost: $0.1241\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 25 calls, $0.1241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/100 [02:18<01:20,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Matching progress - 50 personas matched:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 51\n",
      "  Total tokens: 623,835\n",
      "  Estimated cost: $0.2543\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 51 calls, $0.2543\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 81/100 [03:02<00:29,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ’° Matching progress - 75 personas matched:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 76\n",
      "  Total tokens: 929,334\n",
      "  Estimated cost: $0.3784\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 76 calls, $0.3784\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating recommendations: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:27<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Generated recommendations for 100 personas\n",
      "ðŸ“ Results saved to: ../submissions/3/results.json\n",
      "\n",
      "ðŸ“Š Type distribution: {'jobs+trainings': 87, 'awareness': 6, 'trainings_only': 7}\n",
      "\n",
      "ðŸ“Š Final matching costs:\n",
      "ðŸ’° Cost Summary:\n",
      "  Total API calls: 101\n",
      "  Total tokens: 1,237,638\n",
      "  Estimated cost: $0.5090\n",
      "\n",
      "  By model:\n",
      "    mistral-medium-latest: 101 calls, $0.5090\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Reset cost tracker for matching phase\n",
    "print(\"\\nðŸ’° Starting matching phase - resetting cost tracker\")\n",
    "reset_cost_tracker()\n",
    "\n",
    "# Generate final results\n",
    "results = []\n",
    "personas_matched = 0\n",
    "\n",
    "for persona_id, persona_info in tqdm(personas.items(), desc=\"Generating recommendations\"):\n",
    "    data = {'persona_id': persona_id}\n",
    "\n",
    "    # CRITICAL: Check age first for awareness cases!\n",
    "    try:\n",
    "        age = int(persona_info.age) if persona_info.age and persona_info.age != 'unknown' else 25\n",
    "    except:\n",
    "        age = 25  # Default to adult if age parsing fails\n",
    "\n",
    "    if age < 16:\n",
    "        # Minor - needs awareness type\n",
    "        data['predicted_type'] = 'awareness'\n",
    "        data['predicted_items'] = 'too_young'\n",
    "    else:\n",
    "        # Adult - proceed with job/training matching\n",
    "        jobs = find_job_matches(persona_info, jobs_text)\n",
    "        personas_matched += 1\n",
    "\n",
    "        if jobs:\n",
    "            data['predicted_type'] = 'jobs+trainings'\n",
    "            data['jobs'] = [\n",
    "                {\n",
    "                    'job_id': job_id,\n",
    "                    'suggested_trainings': job_training_map.get(job_id, [])\n",
    "                }\n",
    "                for job_id in jobs\n",
    "            ]\n",
    "        else:\n",
    "            # No jobs found, suggest trainings only\n",
    "            trainings = find_training_matches(persona_info, trainings_info)\n",
    "            data['predicted_type'] = 'trainings_only'\n",
    "            data['trainings'] = trainings\n",
    "\n",
    "    results.append(data)\n",
    "\n",
    "    # Show cost update every 25 personas\n",
    "    if personas_matched % 25 == 0 and personas_matched > 0:\n",
    "        print(f\"\\nðŸ’° Matching progress - {personas_matched} personas matched:\")\n",
    "        print_cost_summary()\n",
    "        print()\n",
    "\n",
    "# Save results\n",
    "results_save_path = SUBMISSION_DIR / 'results.json'\n",
    "save_json(results_save_path, results)\n",
    "print(f\"\\nâœ… Generated recommendations for {len(results)} personas\")\n",
    "print(f\"ðŸ“ Results saved to: {results_save_path}\")\n",
    "\n",
    "# Count types for debugging\n",
    "type_counts = {}\n",
    "for r in results:\n",
    "    t = r.get('predicted_type', 'unknown')\n",
    "    type_counts[t] = type_counts.get(t, 0) + 1\n",
    "print(f\"\\nðŸ“Š Type distribution: {type_counts}\")\n",
    "\n",
    "# Final cost summary for matching\n",
    "print(\"\\nðŸ“Š Final matching costs:\")\n",
    "print_cost_summary()\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Leaderboard!\n",
    "\n",
    "This is it. The moment of truth. If everything worked, you should jump from ~10% to ~40-50%.\n",
    "\n",
    "**Before submitting:**\n",
    "- Check you have 100 results (one per persona)\n",
    "- Make sure you're not submitting your 10th attempt today (there's a limit!)\n",
    "\n",
    "**After submitting:**\n",
    "- Go check the leaderboard immediately\n",
    "- Screenshot your score for bragging rights\n",
    "- Share what worked in the Teams channel (help others, win the collaborator award!)\n",
    "- If your score is still terrible, check our debugging tips above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import make_submission\n",
    "\n",
    "# Submit\n",
    "response = make_submission(results)\n",
    "\n",
    "if response and response.status_code == 200:\n",
    "    print(\"ðŸŽ‰ Submission successful! Check the leaderboard!\")\n",
    "else:\n",
    "    print(f\"âŒ Submission failed: {response.text if response else 'No response'}\")\n",
    "\n",
    "# Final cost report\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print_cost_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What You Just Built\n",
    "\n",
    "Congrats! You went from random matching (5%) to intelligent AI agents (40-50%). That's real progress.\n",
    "\n",
    "âœ… **Multi-agent system** with specialized roles (like a real consulting team)\n",
    "\n",
    "âœ… **Semantic matching** that actually understands context\n",
    "\n",
    "âœ… **Cost optimization** using appropriate models (small for simple, large for complex)\n",
    "\n",
    "âœ… **40-50% accuracy** (vs that embarrassing 5-10% from Tutorial 3)\n",
    "\n",
    "### Your Score Analysis\n",
    "\n",
    "- **If you got 40-50%**: Great! The agents are working. Your semantic matching is solid.\n",
    "- **If you got 20-30%**: Check your conversation quality. Are personas actually answering your questions?\n",
    "- **If you got <20%**: Something's broken. Check extraction, check matching logic, check everything.\n",
    "- **If you got >60%**: Share your secret sauce in Teams! Seriously, help others and maybe win that collaborator award.\n",
    "\n",
    "## Final Tips\n",
    "\n",
    "1. **Track your costs** - Set a budget and stick to it\n",
    "2. **Share knowledge** - The Teams channel is there for a reason\n",
    "3. **Experiment boldly** - Try different approaches, compare scores\n",
    "4. **Help others** - Best collaborator award is as cool as winning\n",
    "5. **Have fun** - You're building AI agents that help people find green jobs. That's pretty awesome.\n",
    "\n",
    "See you in Tutorial 5, where we'll push for 70%+ with advanced techniques! ðŸš€\n",
    "\n",
    "**Remember**: Bad code that ships > Perfect code that doesn't. You shipped. You improved. You're already ahead of most.\n",
    "\n",
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Model Optimization\n",
    "Try using small models for everything. How much do you save? How much does accuracy drop? The answer might surprise you.\n",
    "\n",
    "### Exercise 2: Better Interviews\n",
    "Design interview questions that get all info in 2 turns instead of 5. Compound questions are your friend.\n",
    "\n",
    "### Exercise 3: Semantic Caching\n",
    "If two personas have similar profiles, can you reuse recommendations? This could cut costs by 60-70%!\n",
    "\n",
    "### Exercise 4: Training Paths\n",
    "Instead of individual trainings, recommend learning paths (sequences of trainings). Much more useful for career progression.\n",
    "\n",
    "Share your improvements in Teams! The best optimization wins eternal glory (and maybe some swag). ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GDSC-8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
