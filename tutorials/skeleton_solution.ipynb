{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea221c-c253-4cec-bd42-a1d140783334",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install python-dotenv strands-agents[mistral] strands-agents-tools tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b923cf9-4016-4ab4-85d3-fdf8756caf4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!aws s3 cp s3://gdsc25test/ . --recursive --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bac1fc8c-22b5-4684-a097-58f349a467e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Type, TypeVar, Any\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel, Field\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "\n",
    "T = TypeVar('T')\n",
    "M = TypeVar('M', bound=BaseModel)\n",
    "\n",
    "dotenv.load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab7d91-2e1f-43ab-9235-3e591ac70c3b",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b9e4f29-84cb-4ad3-b657-4f9a4202f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(\n",
    "    system_prompt: str = \"\",\n",
    "    model_id: str = \"mistral-large-latest\"\n",
    ") -> Agent:\n",
    "    model = MistralModel(\n",
    "        api_key=os.environ[\"MISTRAL_API_KEY\"],\n",
    "        model_id=model_id,\n",
    "        stream=False\n",
    "    )\n",
    "    return Agent(model=model, system_prompt=system_prompt, callback_handler=None)\n",
    "\n",
    "\n",
    "def load_file_content(path: str | Path) -> str:\n",
    "    path = Path(path)\n",
    "    with path.open('r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def read_json(path: str | Path):\n",
    "    path = Path(path)\n",
    "    with path.open('r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_json(path: str | Path, data: Dict | List):\n",
    "    path = Path(path)\n",
    "    with path.open('w', encoding='utf-8') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "\n",
    "def get_job_paths() -> List[Path]:\n",
    "    data_dir = Path('./data/jobs')\n",
    "    paths = []\n",
    "    for file in data_dir.iterdir():\n",
    "        if file.suffix == '.md':\n",
    "            paths.append(file)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_training_paths() -> List[Path]:\n",
    "    data_dir = Path('./data/trainings')\n",
    "    paths = []\n",
    "    for file in data_dir.iterdir():\n",
    "        if file.suffix == '.md':\n",
    "            paths.append(file)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30d5ab-955a-4369-98ad-21212596e831",
   "metadata": {},
   "source": [
    "# Data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6d8ec3-a275-4f1d-8d0d-a086c2e8780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobInfo(BaseModel):\n",
    "    # domain: str = Field(default=\"\", description=\"Field or industry of the job\")\n",
    "    required_skills: List[str] = Field(default_factory=list, description=\"List of required skills for the job.\")\n",
    "    location: str = Field(default=\"\", description=\"Job location.\")\n",
    "    years_of_experience_required: str = Field(default=\"\", description=\"Years of experience required to get this job.\")\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skills = ', '.join(self.required_skills)\n",
    "        return f\"Required skills: {skills}\\nLocation: {self.location}\\nYears of experience required: {self.years_of_experience_required}\"\n",
    "\n",
    "\n",
    "class TrainingInfo(BaseModel):\n",
    "    skill_acquired_and_level: Tuple[str, str] = Field(\n",
    "        default_factory=tuple,\n",
    "        description=\"A pair of skill name and level\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skill = f'{self.skill_acquired_and_level[0]}: level {self.skill_acquired_and_level[1]}'\n",
    "        return f\"Acquired skills: {skill}\"\n",
    "\n",
    "\n",
    "class PersonaInfo(BaseModel):\n",
    "    name: str = Field(default=\"\", description=\"Persona's name\")\n",
    "    skills: List[Tuple[str, str]] = Field(default_factory=list, description=\"List of pairs representing skills and its level.\")\n",
    "    location: str = Field(default=\"unknown\", description=\"Current location\")\n",
    "    age: str = Field(default=\"unknown\", description=\"Age of the persona\")\n",
    "    years_of_experience: str = Field(default=\"unknown\", description=\"Years of experience in a field.\")\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        skills = ', '.join([\n",
    "            f'{skill}: {level}'\n",
    "            for skill, level in self.skills\n",
    "        ])\n",
    "        return (\n",
    "            f\"Name: {self.name}\\n\"\n",
    "            f\"Skills: {skills}\\n\"\n",
    "            f\"Location: {self.location}\\n\"\n",
    "            f\"Age: {self.age}\\n\"\n",
    "            f\"Years of experience: {self.years_of_experience}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class BoolOut(BaseModel):\n",
    "    result: bool = Field(default=False, description=\"whether the condition is fulfilled or not\")\n",
    "\n",
    "\n",
    "class IDList(BaseModel):\n",
    "    values: List[str] = Field(default=False, description=\"a list of string IDs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5b96dd-be86-421e-93a8-73b0aafdf9a5",
   "metadata": {},
   "source": [
    "# Accessing agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fb9c0d-fe1a-4634-8ec8-6e3dc057fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_chat(message: str, persona_id: str, conversation_id: str = None) -> Optional[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Send a single message to the chat endpoint and return the response.\n",
    "\n",
    "    Args:\n",
    "        persona_id: ID of the persona\n",
    "        message: Message to send\n",
    "\n",
    "    Returns:\n",
    "        The response from the chat endpoint\n",
    "    \"\"\"\n",
    "    url = 'https://5xxe59fsr7.execute-api.eu-central-1.amazonaws.com/main/chat'\n",
    "    headers = {\n",
    "        \"x-api-key\": os.environ[\"AWS_API_KEY\"]\n",
    "    }\n",
    "    payload = {\n",
    "        \"message\": message,\n",
    "        \"persona_id\": persona_id,\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"team_id\": \"WitekTeam\",\n",
    "    }\n",
    "\n",
    "    response = requests.post(\n",
    "        url=url,\n",
    "        json=payload,\n",
    "        headers=headers\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Err: {response}, {persona_id}, {response.text}\")\n",
    "        return None\n",
    "\n",
    "    response_data = response.json()\n",
    "    return response_data['response'], response_data['conversation_id']\n",
    "\n",
    "\n",
    "def get_conversation(persona_id: str, max_turns: int = 5, verbose: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Perform a conversation with a single persona for a maximum number of turns.\n",
    "\n",
    "    Args:\n",
    "        persona_id: ID of the persona\n",
    "        max_turns: Maximum number of conversation turns (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        List of conversation messages\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    **Speak only in english.**\n",
    "    **Do not give info from the internet.** \n",
    "    Continue to ask questions about this person - do not provide the jobs, trainings or anything yet.\n",
    "    You are a helpful and empathetic assistant. Your goal is to engage in a natural conversation with a persona to gather the following information:\n",
    "    - Their name\n",
    "    - Their skills and **level of this skill**\n",
    "    - Their current location\n",
    "    - Their age\n",
    "    - Their preferences\n",
    "    - Years of experience\n",
    "    \n",
    "    Remember to always gather all of those information!\n",
    "    Ask open-ended questions to encourage detailed responses. Be polite, patient, and adapt your questions based on their answers.\n",
    "    If the persona is unsure or vague, gently probe for more details. Do not ask all questions at once; let the conversation flow naturally.\n",
    "    **Do not comment on whatever the response is. Just ask questions to retrieve the information.**\n",
    "    **Focus only on asking question about persona. Do not provide any additional info from the internet.**\n",
    "    \"\"\"\n",
    "    conversation = []\n",
    "    current_turn = 0\n",
    "    converation_agent = get_agent(system_prompt)\n",
    "    conversation_id = None\n",
    "\n",
    "    # greeting\n",
    "    agent_message = \"Hello! I'm here to help you find the best job or training opportunities. Can you tell me your name?\"\n",
    "    converation_agent.messages = [{\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\n",
    "            \"text\": agent_message\n",
    "        }]\n",
    "    }]\n",
    "    conversation.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    while current_turn < max_turns:\n",
    "        resp = send_message_to_chat(\n",
    "            agent_message,\n",
    "            persona_id,\n",
    "            conversation_id\n",
    "        )\n",
    "        if resp is None:\n",
    "            print(f\"User: {persona_id} did not respond\")\n",
    "            break\n",
    "        user_response, conversation_id = resp\n",
    "        if verbose:\n",
    "            print(f\"Response: {user_response}\\n\\n\")\n",
    "        conversation.append(f\"User: {user_response}\")\n",
    "        agent_message = str(converation_agent(user_response))\n",
    "        conversation.append(f\"Assistant: {agent_message}\")\n",
    "        current_turn += 1\n",
    "    return conversation\n",
    "\n",
    "#maybe pararel_conversations() ?\n",
    "def get_conversations(persona_ids: List[str], max_workers: int = 10, verbose: bool = False, max_turns: int = 5) -> Dict[str, List[str]]:\n",
    "    all_conversations = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {\n",
    "            executor.submit(get_conversation, persona_id, verbose=verbose, max_turns=max_turns): persona_id\n",
    "            for persona_id in persona_ids\n",
    "        }\n",
    "        for future in futures:\n",
    "            persona_id = futures[future]\n",
    "            try:\n",
    "                all_conversations[persona_id] = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred for {persona_id}: {e}\")\n",
    "    return all_conversations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a161f43-dfc3-497b-bf3b-fa94599c1356",
   "metadata": {},
   "source": [
    "# Extracting information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d910534-9f94-4dcd-8716-6bb49fd39bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(model: Type[M], text: str) -> M:\n",
    "    extraction_agent = get_agent()\n",
    "    return extraction_agent.structured_output(output_model=model, prompt=text)\n",
    "\n",
    "\n",
    "def extract_info_from_conversation(conversation: List[str]) -> PersonaInfo:\n",
    "    text = '\\n'.join(conversation)\n",
    "    return extract_info(PersonaInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_job_path(path: str | Path) -> JobInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(JobInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_training_path(path: str | Path) -> TrainingInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(TrainingInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_to_json(\n",
    "    model: BaseModel,\n",
    "    description_paths: List[str | Path],\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    save_path = Path(save_path)\n",
    "\n",
    "    if not save_path.exists():\n",
    "        save_path.touch()\n",
    "        save_json(save_path, {})\n",
    "\n",
    "    extracted_data = read_json(save_path)\n",
    "    description_paths = [Path(path) for path in description_paths]\n",
    "    print(f'Total descriptions for {model.__name__}: {len(description_paths)}')\n",
    "    print(f'Extracted infos: {len(extracted_data)}')\n",
    "\n",
    "    counter = 0\n",
    "    for path in description_paths:\n",
    "        id_ = path.stem\n",
    "        retries = 0\n",
    "        err = None\n",
    "        if id_ not in extracted_data:\n",
    "            text = load_file_content(path)\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    info = extract_info(model, text)\n",
    "                    break\n",
    "                except ValueError as e:\n",
    "                    retries += 1\n",
    "                    err = e\n",
    "            else:\n",
    "                print(f'Error for id: {id_}', err)\n",
    "            extracted_data[id_] = info.model_dump_json()\n",
    "            counter += 1\n",
    "        if counter % cache_period == 1:\n",
    "            save_json(save_path, extracted_data)\n",
    "            print(len(extracted_data))\n",
    "    save_json(save_path, extracted_data)\n",
    "\n",
    "\n",
    "def extract_jobs_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    job_paths = get_job_paths()\n",
    "    extract_info_to_json(\n",
    "        model=JobInfo,\n",
    "        description_paths=job_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_trainings_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    training_paths = get_training_paths()\n",
    "    extract_info_to_json(\n",
    "        model=TrainingInfo,\n",
    "        description_paths=training_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e283a-6dbc-4d62-b0cf-18de6326dfc3",
   "metadata": {},
   "source": [
    "# Matching personas to jobs and trainings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eec51bb9-91ad-4016-bc73-1a89f05a7954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    jobs_data: Dict[str, JobInfo],\n",
    ") -> List[str]:\n",
    "    jobs_text = \"\\n\".join([\n",
    "        f'{job_id}: {job_info.describe()}'\n",
    "        for job_id, job_info in jobs_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available jobs. Given a candidate info provide\n",
    "    a list od 3 to 5 job IDs that would match that candidate:\n",
    "    {jobs_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values\n",
    "\n",
    "\n",
    "def find_training_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo]\n",
    ") -> List[str]:\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available trainings. Given a candidate info provide\n",
    "    a list od 3 to 5 training IDs that would match that candidate:\n",
    "    {trainings_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f42bd00-af95-46cb-a300-b5ab5b18f81e",
   "metadata": {},
   "source": [
    "# Extracting job infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd6dc06-35cc-498b-93e2-9f8d9a8f822e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total descriptions for JobInfo: 200\n",
      "Extracted infos: 200\n"
     ]
    }
   ],
   "source": [
    "jobs_save_path = './extracted_jobs_info.json'\n",
    "extract_jobs_info_to_json(jobs_save_path)\n",
    "jobs_info = read_json(jobs_save_path)\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(job_data)\n",
    "    for job_id, job_data in jobs_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18b6ce9-6923-426e-af57-6973e7c61c9f",
   "metadata": {},
   "source": [
    "# Extracting trainings info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84bec543-9687-43c4-9955-a3834aaea060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total descriptions for TrainingInfo: 497\n",
      "Extracted infos: 497\n"
     ]
    }
   ],
   "source": [
    "trainings_save_path = './extracted_trainings_info.json'\n",
    "extract_trainings_info_to_json(trainings_save_path)\n",
    "trainings_info = read_json(trainings_save_path)\n",
    "trainings_info = {\n",
    "    training_id: TrainingInfo.model_validate_json(training_data)\n",
    "    for training_id, training_data in trainings_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6963705-f209-40c3-89f9-f77ef6899f2e",
   "metadata": {},
   "source": [
    "# Test matching algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a25240c5-d237-4b0a-9632-1529b24600c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Pedro Araújo\n",
      "Skills: Food Safety: Intermediate, Food Sustainability: Intermediate\n",
      "Location: Brasília\n",
      "Age: 16\n",
      "Years of experience: 1\n",
      "Jobs: values=['job_foo_003', 'job_foo_006', 'job_foo_009', 'job_foo_001']\n",
      "Trainings: values=['tr_foo_food_safety_standards_haccp_gmp__02', 'tr_foo_waste_reduction_02', 'tr_foo_quality_inspection_02', 'tr_foo_hygiene_protocols_02', 'tr_foo_food_safety_standards_haccp_gmp__03']\n"
     ]
    }
   ],
   "source": [
    "persona = PersonaInfo(\n",
    "    name='Pedro Araújo',\n",
    "    skills=[('Food Safety', 'Intermediate'), ('Food Sustainability', 'Intermediate')],\n",
    "    location='Brasília',\n",
    "    age='16',\n",
    "    years_of_experience='1'\n",
    ")\n",
    "print(persona.describe())\n",
    "\n",
    "persona_jobs = find_job_matches_for_persona(persona, jobs_info)\n",
    "persona_trainings = find_training_matches_for_persona(persona, trainings_info)\n",
    "print(f\"Jobs: {persona_jobs}\")\n",
    "print(f\"Trainings: {persona_trainings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c873f15-6f1d-4d56-90d2-d7f326c7e431",
   "metadata": {},
   "source": [
    "# Collecting conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec4a518-583b-4601-a5c5-a235750480f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations for personas: 100\n",
      "Collected conversations: 100\n"
     ]
    }
   ],
   "source": [
    "persona_ids = [f'persona_{i:03}' for i in range(1, 101)]\n",
    "cache_period = 4\n",
    "\n",
    "personas_save_path = Path('./extracted_personas_info.json')\n",
    "if not personas_save_path.exists():\n",
    "    personas_save_path.touch()\n",
    "    save_json(personas_save_path, {})\n",
    "\n",
    "persona_infos = read_json(personas_save_path)\n",
    "print(f'Total conversations for personas: {len(persona_infos)}')\n",
    "print(f'Collected conversations: {len(persona_infos)}')\n",
    "\n",
    "counter = 0\n",
    "for persona_id in persona_ids:\n",
    "    if persona_id not in persona_infos:\n",
    "        conversation = get_conversation(persona_id, max_turns=2, verbose=False)\n",
    "        persona_info = extract_info_from_conversation(conversation)\n",
    "        persona_infos[persona_id] = persona_info.model_dump_json()\n",
    "        counter += 1\n",
    "    if counter % cache_period == 1:\n",
    "        save_json(personas_save_path, persona_infos)\n",
    "        print(len(persona_infos))\n",
    "save_json(personas_save_path, persona_infos)\n",
    "\n",
    "persona_infos = {\n",
    "    persona_id: PersonaInfo.model_validate_json(persona_info)\n",
    "    for persona_id, persona_info in persona_infos.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32148ac2-1ec6-40f4-8be5-da6af8d3440f",
   "metadata": {},
   "source": [
    "# Generating the final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd3878c3-51d7-4e05-9fe8-a679716ceabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:36<00:00,  3.36s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for persona_id, persona_info in tqdm(persona_infos.items()):\n",
    "    jobs = find_job_matches_for_persona(persona_info, jobs_info)\n",
    "    trainings = find_training_matches_for_persona(persona_info, trainings_info)\n",
    "    data = {'persona_id': persona_id}\n",
    "    if jobs and trainings:\n",
    "        data['gold_type'] = 'jobs+trainings'\n",
    "        data['jobs'] = [\n",
    "            {'job_id': job_id, 'suggested_trainings': trainings}\n",
    "            for job_id in jobs\n",
    "        ]\n",
    "    elif trainings:\n",
    "        data['gold_type'] = 'trainings_only'\n",
    "        data['trainings'] = trainings\n",
    "    else:\n",
    "        data['gold_type'] = 'awareness'\n",
    "        data['gold_items'] = ''\n",
    "    results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50262e5f-c449-4c1f-ac2f-3d644d19825a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persona_id': 'persona_001',\n",
       " 'gold_type': 'jobs+trainings',\n",
       " 'jobs': [{'job_id': 'job_foo_003',\n",
       "   'suggested_trainings': ['tr_foo_food_safety_standards_haccp_gmp__01',\n",
       "    'tr_foo_food_safety_standards_haccp_gmp__02',\n",
       "    'tr_foo_hygiene_protocols_01',\n",
       "    'tr_foo_hygiene_protocols_02',\n",
       "    'tr_foo_hygiene_protocols_03']},\n",
       "  {'job_id': 'job_foo_004',\n",
       "   'suggested_trainings': ['tr_foo_food_safety_standards_haccp_gmp__01',\n",
       "    'tr_foo_food_safety_standards_haccp_gmp__02',\n",
       "    'tr_foo_hygiene_protocols_01',\n",
       "    'tr_foo_hygiene_protocols_02',\n",
       "    'tr_foo_hygiene_protocols_03']},\n",
       "  {'job_id': 'job_foo_005',\n",
       "   'suggested_trainings': ['tr_foo_food_safety_standards_haccp_gmp__01',\n",
       "    'tr_foo_food_safety_standards_haccp_gmp__02',\n",
       "    'tr_foo_hygiene_protocols_01',\n",
       "    'tr_foo_hygiene_protocols_02',\n",
       "    'tr_foo_hygiene_protocols_03']},\n",
       "  {'job_id': 'job_foo_008',\n",
       "   'suggested_trainings': ['tr_foo_food_safety_standards_haccp_gmp__01',\n",
       "    'tr_foo_food_safety_standards_haccp_gmp__02',\n",
       "    'tr_foo_hygiene_protocols_01',\n",
       "    'tr_foo_hygiene_protocols_02',\n",
       "    'tr_foo_hygiene_protocols_03']},\n",
       "  {'job_id': 'job_foo_009',\n",
       "   'suggested_trainings': ['tr_foo_food_safety_standards_haccp_gmp__01',\n",
       "    'tr_foo_food_safety_standards_haccp_gmp__02',\n",
       "    'tr_foo_hygiene_protocols_01',\n",
       "    'tr_foo_hygiene_protocols_02',\n",
       "    'tr_foo_hygiene_protocols_03']}]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "735d87c5-afe5-4dcb-8740-72631a5e60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('./results.jsonl')\n",
    "with results_path.open('w', encoding='utf-8') as file:\n",
    "    for res in results:\n",
    "        line = json.dumps(res) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c58f564-412e-42c7-8815-de2314f99627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
