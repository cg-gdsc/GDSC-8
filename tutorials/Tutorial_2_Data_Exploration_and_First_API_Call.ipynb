{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: Data Exploration and Your First API Call\n",
    "\n",
    "Alright, let's get our hands dirty with some actual data and API calls. \n",
    "\n",
    "## What we're doing today\n",
    "\n",
    "- Download the GDSC 8 dataset (jobs + trainings from Brazil)\n",
    "- Make our first Mistral API call (and not go broke doing it)\n",
    "- Understand why tokens matter (spoiler: they cost money)\n",
    "- Use LLMs to filter data instead of writing regex hell\n",
    "\n",
    "**Reality check**: This is about building AI agents that help people find green jobs in Brazil. Cool mission, but also we're in a competition, so let's be smart about costs and performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Challenge Data\n",
    "\n",
    "### The Mission (kinda cool actually)\n",
    "We're helping young people in Brazil find green jobs. UNICEF partnership, climate action, meaningful careers - the whole deal. \n",
    "And because it's 2025 we will build AI agents that can sift through job descriptions and training programs, match them to people's profiles, and do it efficiently and ethically!\n",
    "\n",
    "**The Brazilian green jobs landscape we're working with:**\n",
    "- **Major cities**: SÃ£o Paulo (finance & tech hub), Rio de Janeiro (energy & environment), BrasÃ­lia (policy & government), Salvador (renewable energy), Recife (innovation centers)\n",
    "- **Key sectors**: Renewable energy (solar, wind, hydro), sustainable agriculture, environmental consulting, green construction, waste management\n",
    "- **Companies leading the charge**: Petrobras (transitioning to renewables), Vale (sustainable mining), Suzano (sustainable forestry), plus hundreds of green startups\n",
    "\n",
    "### Let's grab the data\n",
    "Time to download some files from S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'aws' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Download the GDSC 8 dataset\n",
    "!aws s3 cp s3://gdsc-25-data-bucket/ . --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this runs, you'll have a `data` directory with:\n",
    "- **`jobs/`** - 200 job postings\n",
    "- **`trainings/`** - 497 training programs\n",
    "\n",
    "### Quick math reality check\n",
    "697 items Ã— however many personas we need to match = potentially expensive if we're not careful with API calls.\n",
    "\n",
    "This is where being smart about it pays off. Literally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "Jobs: 200\n",
      "Trainings: 467\n",
      "Total items: 667\n"
     ]
    }
   ],
   "source": [
    "# Let's see what we're working with\n",
    "from pathlib import Path\n",
    "\n",
    "# Count files and get basic statistics\n",
    "jobs_dir = Path('../data/jobs')\n",
    "trainings_dir = Path('../data/trainings')\n",
    "\n",
    "job_files = list(jobs_dir.glob('*.md')) if jobs_dir.exists() else []\n",
    "training_files = list(trainings_dir.glob('*.md')) if trainings_dir.exists() else []\n",
    "\n",
    "print(f\"Dataset Overview:\")\n",
    "print(f\"Jobs: {len(job_files)}\")\n",
    "print(f\"Trainings: {len(training_files)}\")\n",
    "print(f\"Total items: {len(job_files) + len(training_files)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at a job posting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to peek at files\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "def display_markdown_file(path: str) -> None:\n",
    "    \"\"\"Display a markdown file in Jupyter - nothing fancy\"\"\"\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\"File not found: {p}\")\n",
    "        return\n",
    "    content = p.read_text(encoding='utf-8', errors='ignore')\n",
    "    display(Markdown(content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Design Research Analyst\n",
       "\n",
       "**Location:** Belo Horizonte\n",
       "**Type:** Full-Time\n",
       "\n",
       "**About the Role:**\n",
       "We are seeking a **Design Research Analyst** to join our team in Design Research Studies and Development. This is an excellent entry-level opportunity for someone looking to start their career in design research and user experience analysis.\n",
       "\n",
       "**Key Responsibilities:**\n",
       "- Conduct user research studies to understand customer needs and behaviors\n",
       "- Analyze research data and translate findings into actionable design insights\n",
       "- Support the development of user personas and journey maps\n",
       "- Collaborate with design teams to inform product development decisions\n",
       "- Document research methodologies and present findings to stakeholders\n",
       "- Assist in planning and executing usability testing sessions\n",
       "\n",
       "**Qualifications:**\n",
       "- TecnÃ³logo degree in a relevant field\n",
       "- Strong analytical and critical thinking skills\n",
       "- Interest in user experience and design research methodologies\n",
       "- Excellent communication skills in Portuguese (BR)\n",
       "- Ability to work collaboratively in a team environment\n",
       "\n",
       "**Preferred Qualifications:**\n",
       "- Familiarity with research tools and survey platforms\n",
       "- Basic understanding of design thinking principles\n",
       "- Experience with data analysis or statistics coursework\n",
       "\n",
       "This role is based in Belo Horizonte and offers the opportunity to grow your expertise in design research while contributing to meaningful product development initiatives.\n",
       "\n",
       "**How to Apply:**\n",
       "Please submit your resume and cover letter detailing your interest in design research."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample job\n",
    "display_markdown_file(job_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And a training program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Why take this course?**\n",
       "\n",
       "The **Intermediate Ship Operations Training** will help you:\n",
       "âœ… Master ship handling and operational procedures on intermediate level\n",
       "âœ… Apply best practices for transparency and compliance\n",
       "âœ… Strengthen your resume with a recognized credential\n",
       "\n",
       "**Course Details:**\n",
       "- **Duration:** 8 weeks\n",
       "- **Format:** online\n",
       "- **Language:** Portuguese (Brazil)\n",
       "- **Certification:** Yes\n",
       "\n",
       "**Prerequisites:**\n",
       "- Basic knowledge of ship operations and maritime procedures\n",
       "\n",
       "This comprehensive program focuses on advancing your maritime operational expertise through practical scenarios and industry standards. You'll develop the technical competencies needed to handle complex vessel operations while ensuring safety and regulatory compliance.\n",
       "\n",
       "The training covers essential aspects of ship management, from navigation procedures to cargo handling protocols. Each module builds systematically on foundational concepts, preparing you for real-world challenges in maritime transport operations.\n",
       "\n",
       "Upon completion, you'll receive official certification that validates your intermediate-level capabilities in maritime operations, making you a stronger candidate for advancement in the shipping industry.\n",
       "\n",
       "**Don't miss the chance to stand outâ€”register today!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display a sample training\n",
    "display_markdown_file(training_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you'll notice\n",
    "\n",
    "Both jobs and trainings have:\n",
    "- **Overview/Description** \n",
    "- **Location** (this matters for matching)\n",
    "- **Prerequisites** (skills, experience levels)\n",
    "- **Outcomes** (for trainings)\n",
    "\n",
    "But here's the kicker: they're not consistently formatted. Some use different headers, different structures, different language. \n",
    "Our solution needs to handle this chaos gracefully. \n",
    "\n",
    "This is why we can't just use regex or simple parsing - we need something smarter: GenAI!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your First Mistral API Call\n",
    "\n",
    "Time to get our hands dirty with the actual AI part.\n",
    "\n",
    "Firstly, create **`.env`** file. Right click on a project structure next to the **`data`** folder and select *New File*. Name the file: \".env\".\n",
    "Paste your Mistral API key which you generated in the first tutorial **`Tutorial_1_Account_setup.ipynb`** exactly like below:\n",
    "\n",
    "MISTRAL_API_KEY=\"your-api-key\"\n",
    "\n",
    "Only after that you will be able to continue with next sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install strands library for mistral\n",
    "!pip install strands-agents[mistral] python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API key found, we're ready to roll\n"
     ]
    }
   ],
   "source": [
    "# Setup time\n",
    "import os\n",
    "import dotenv\n",
    "\n",
    "# Load your API key from .env file\n",
    "dotenv.load_dotenv(\".env\")\n",
    "\n",
    "# Check if we're good to go\n",
    "if not os.getenv(\"MISTRAL_API_KEY\"):\n",
    "    print(\"âŒ No MISTRAL_API_KEY found!\")\n",
    "    print(\"Create a .env file with your API key\")\n",
    "else:\n",
    "    print(\"âœ… API key found, we're ready to roll\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add a helper function to actually connect to Mistral, using the [strands framework](https://strandsagents.com/latest/). \n",
    "\n",
    "**What's Strands?** It's basically a wrapper that makes Mistral (and other LLMs) actually useful for production. Handles retries, structured output, all that boring stuff. Check their [docs](https://strandsagents.com/latest/) if you're curious, but we'll show you what matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Mistral client ready!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from strands import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "def call_mistral(prompt: str, model: str = \"mistral-small-latest\") -> dict:\n",
    "    \"\"\"Call Mistral API and track what it costs us\"\"\"\n",
    "    mistral_model = MistralModel(\n",
    "        api_key=os.environ[\"MISTRAL_API_KEY\"],\n",
    "        model_id=model,\n",
    "        stream=False\n",
    "    )\n",
    "    agent = Agent(model=mistral_model, callback_handler=None)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        response = agent(prompt)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Extract useful info\n",
    "        result = {\n",
    "            \"content\": response.message['content'][0]['text'],\n",
    "            \"model\": model,\n",
    "            \"duration\": end_time - start_time,\n",
    "            \"input_tokens\": response.metrics.accumulated_usage['inputTokens'],\n",
    "            \"output_tokens\": response.metrics.accumulated_usage['outputTokens'],\n",
    "            \"total_tokens\": response.metrics.accumulated_usage['totalTokens']\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ API call failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"âœ… Mistral client ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ First API call...\n",
      "\n",
      "ðŸ“Š Stats:\n",
      "Model: mistral-small-latest\n",
      "Time: 1.25 seconds\n",
      "Input tokens: 17\n",
      "Output tokens: 87\n",
      "Total tokens: 104\n",
      "Estimated cost: $0.000031\n",
      "\n",
      "ðŸ’¬ Response:\n",
      "A **green job** is a role that helps protect the environment or reduce pollution. Examples include:\n",
      "\n",
      "- **Renewable energy** (solar/wind technician)\n",
      "- **Sustainability** (energy auditor, recycling coordinator)\n",
      "- **Conservation** (forest ranger, wildlife biologist)\n",
      "- **Green construction** (LEED-certified builder)\n",
      "\n",
      "These jobs focus on reducing carbon footprints and promoting eco-friendly practices.\n"
     ]
    }
   ],
   "source": [
    "# Simple test to make sure everything works\n",
    "test_prompt = \"\"\"What's a 'green job'? Keep it short and practical.\"\"\"\n",
    "\n",
    "print(\"ðŸš€ First API call...\")\n",
    "result = call_mistral(test_prompt, \"mistral-small-latest\")\n",
    "\n",
    "if result:\n",
    "    print(f\"\\nðŸ“Š Stats:\")\n",
    "    print(f\"Model: {result['model']}\")\n",
    "    print(f\"Time: {result['duration']:.2f} seconds\")\n",
    "    print(f\"Input tokens: {result['input_tokens']}\")\n",
    "    print(f\"Output tokens: {result['output_tokens']}\")\n",
    "    print(f\"Total tokens: {result['total_tokens']}\")\n",
    "    \n",
    "    estimated_cost = (result['total_tokens'] / 1_000_000) * 0.30\n",
    "    print(f\"Estimated cost: ${estimated_cost:.6f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’¬ Response:\")\n",
    "    print(result['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding Tokens - Your Cost Unit\n",
    "\n",
    "LLMs are usually priced via tokens. Usually X$ \"per 1 million tokens\" - but what exactly is a token?\n",
    "\n",
    "**Tokens are how LLMs process text**. Think of them as the \"billing units\" for AI:\n",
    "- \"OlÃ¡ mundo!\" â‰ˆ 4 tokens (Portuguese uses slightly more tokens than English)\n",
    "- \"Green jobs in SÃ£o Paulo\" â‰ˆ 6 tokens  \n",
    "- Roughly 1 token â‰ˆ 0.75 English words (varies by language)\n",
    "\n",
    "**Why tokens matter for our challenge:**\n",
    "- **Cost control**: 697 job postings Ã— 100 tokens each = 69,700 tokens to process\n",
    "- **Speed**: More tokens = slower responses (matters when processing hundreds of items)  \n",
    "- **Planning**: Models have token limits (128k for all Mistral models)\n",
    "\n",
    "**Quick cost reality check:**\n",
    "- Small model: 69,700 tokens â‰ˆ $0.007 to classify all jobs\n",
    "- Large model: Same task â‰ˆ $0.14 (20x more expensive)\n",
    "- For 697 items, choosing the right model matters!\n",
    "\n",
    "**Pro tip**: Always start with the smallest model that can handle your task. You can always upgrade to larger models for complex reasoning later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison - The Money Talk\n",
    "\n",
    "| Model Name           | Size / Version     | Input Cost (per 1M tokens)  | Output Cost (per 1M tokens)  | Context Window |\n",
    "|----------------------|--------------------|-----------------------------|--------------------------|----------------|\n",
    "| Mistral Large 24-11  | Large              | \\$2.00                       | \\$6.00                        | 128k tokens      |\n",
    "| Mistral Medium 3     | Medium             | \\$0.40                       | \\$2.00                        | 128k tokens      |\n",
    "| Mistral Small 3.1    | Small              | \\$0.10                       | \\$0.30                        | 128k tokens      |\n",
    "\n",
    "**Real talk**: For most filtering/classification tasks, the small model is plenty good and 15x cheaper. Only use the big guns when you really need them.\n",
    "We'll see an example in a minute. But first we need to talk about prompting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering Essentials\n",
    "\n",
    "Before we compare models, let's talk about **prompts** - your instructions to the AI. Think of prompts as the difference between asking a colleague \"Can you help?\" vs \"Can you analyze this SÃ£o Paulo job posting and extract the required skills in bullet format?\"\n",
    "\n",
    "### What makes a good prompt?\n",
    "\n",
    "**âŒ Vague prompt:**\n",
    "```\n",
    "\"Analyze this job\"\n",
    "```\n",
    "\n",
    "**âœ… Specific prompt:**\n",
    "```\n",
    "\"Analyze this Brazilian green job posting and extract:\n",
    "1. Required skills (list format)\n",
    "2. Experience level (entry/mid/senior)  \n",
    "3. Location requirements\n",
    "4. Sustainability focus areas\n",
    "\n",
    "Format as structured JSON.\"\n",
    "```\n",
    "\n",
    "### Key principles for GDSC challenge:\n",
    "\n",
    "1. **Be specific about the task** - \"classify\" vs \"analyze deeply\"\n",
    "2. **Specify output format** - JSON, bullet points, yes/no answers\n",
    "3. **Provide context** - mention it's Brazilian data, green jobs focus\n",
    "4. **Set constraints** - \"keep it under 50 words\" for cost control\n",
    "\n",
    "### Why this matters:\n",
    "- **Small models** need very clear, specific instructions\n",
    "- **Large models** can handle more ambiguous, complex requests\n",
    "- **Good prompts** = consistent results across your 697 job postings\n",
    "\n",
    "Let's see this in action with model comparisons..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¬ Running model comparison experiment...\n",
      "\n",
      "Testing mistral-small-latest:\n",
      "Duration: 1.49s | Tokens: 298 | Cost: $0.000056\n",
      "Full Response:\n",
      "```json\n",
      "{\n",
      "  \"required_skills\": [\n",
      "    \"Engineering degree (Electrical, Mechanical, or Environmental)\",\n",
      "    \"2-3 years experience in renewable energy projects\",\n",
      "    \"Proficiency in MATLAB/Simulink\",\n",
      "    \"Proficiency in AutoCAD\",\n",
      "    \"Portuguese fluency\"\n",
      "  ],\n",
      "  \"seniority_level\": \"intermediate\",\n",
      "  \"location_requirements\": {\n",
      "    \"primary_location\": \"SÃ£o Paulo and Minas Gerais regions, Brazil\",\n",
      "    \"travel_requirements\": \"Willingness to travel within Southeast Brazil\"\n",
      "  },\n",
      "  \"sustainability_green_job\": true\n",
      "}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "\n",
      "Testing mistral-large-latest:\n",
      "Duration: 3.06s | Tokens: 503 | Cost: $0.002354\n",
      "Full Response:\n",
      "```json\n",
      "{\n",
      "  \"job_analysis\": {\n",
      "    \"required_skills\": [\n",
      "      {\n",
      "        \"skill\": \"Engineering degree (Electrical, Mechanical, or Environmental)\",\n",
      "        \"type\": \"education\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"2-3 years experience in renewable energy projects\",\n",
      "        \"type\": \"experience\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"Proficient in MATLAB/Simulink\",\n",
      "        \"type\": \"technical\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"Proficient in AutoCAD\",\n",
      "        \"type\": \"technical\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"Fluency in Portuguese\",\n",
      "        \"type\": \"language\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"Willingness to travel within Southeast Brazil\",\n",
      "        \"type\": \"logistical\"\n",
      "      },\n",
      "      {\n",
      "        \"skill\": \"Design and optimization of solar/wind energy installations\",\n",
      "        \"type\": \"domain-specific\"\n",
      "      }\n",
      "    ],\n",
      "    \"seniority_level\": \"intermediate\",\n",
      "    \"location_requirements\": {\n",
      "      \"primary_regions\": [\"SÃ£o Paulo\", \"Minas Gerais\"],\n",
      "      \"country\": \"Brazil\",\n",
      "      \"travel_required\": true,\n",
      "      \"travel_scope\": \"Southeast Brazil\"\n",
      "    },\n",
      "    \"sustainability_related\": {\n",
      "      \"is_green_job\": true,\n",
      "      \"key_aspects\": [\n",
      "        \"Renewable energy (solar/wind)\",\n",
      "        \"Clean energy transition\",\n",
      "        \"Part of Petrobras Renewables Division\",\n",
      "        \"Focus on sustainability in Brazil's energy sector\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "ðŸ’° Cost Analysis:\n",
      "Small model cost: $0.000056\n",
      "Large model cost: $0.002354\n",
      "Large model is 41.9x more expensive\n",
      "\n",
      "For 697 job postings:\n",
      "Small model total: $0.04\n",
      "Large model total: $1.64\n",
      "Difference: $1.60\n"
     ]
    }
   ],
   "source": [
    "# Complex analysis prompt for comparison - let's use a Brazilian green energy company!\n",
    "analysis_prompt = \"\"\"Analyze this job description and extract:\n",
    "1. Required skills (list)\n",
    "2. Seniority level (basic/intermediate/advanced)\n",
    "3. Location requirements\n",
    "4. Whether it's related to sustainability/green jobs\n",
    "\n",
    "Job Description:\n",
    "# Renewable Energy Systems Engineer - Petrobras Renewables Division\n",
    "## Overview\n",
    "Join Petrobras's mission to accelerate Brazil's transition to clean energy! We're seeking a systems engineer to design and optimize solar and wind energy installations across SÃ£o Paulo and Minas Gerais regions.\n",
    "\n",
    "## Requirements\n",
    "- Engineering degree (Electrical, Mechanical, or Environmental)\n",
    "- 2-3 years experience in renewable energy projects\n",
    "- Proficiency in MATLAB/Simulink and AutoCAD\n",
    "- Portuguese fluency required\n",
    "- Willingness to travel within Southeast Brazil\n",
    "\n",
    "Format your response as structured JSON.\"\"\"\n",
    "\n",
    "print(\"ðŸ”¬ Running model comparison experiment...\\n\")\n",
    "\n",
    "# Test with small model\n",
    "print(\"Testing mistral-small-latest:\")\n",
    "result_small = call_mistral(analysis_prompt, \"mistral-small-latest\")\n",
    "\n",
    "if result_small:\n",
    "    small_input_cost = (result_small['input_tokens'] / 1_000_000) * 0.10\n",
    "    small_output_cost = (result_small['output_tokens'] / 1_000_000) * 0.30\n",
    "    small_total_cost = small_input_cost + small_output_cost\n",
    "    \n",
    "    print(f\"Duration: {result_small['duration']:.2f}s | Tokens: {result_small['total_tokens']} | Cost: ${small_total_cost:.6f}\")\n",
    "    print(\"Full Response:\")\n",
    "    print(result_small['content'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# Test with large model\n",
    "print(\"Testing mistral-large-latest:\")\n",
    "result_large = call_mistral(analysis_prompt, \"mistral-large-latest\")\n",
    "\n",
    "if result_large:\n",
    "    large_input_cost = (result_large['input_tokens'] / 1_000_000) * 2.00\n",
    "    large_output_cost = (result_large['output_tokens'] / 1_000_000) * 6.00\n",
    "    large_total_cost = large_input_cost + large_output_cost\n",
    "    \n",
    "    print(f\"Duration: {result_large['duration']:.2f}s | Tokens: {result_large['total_tokens']} | Cost: ${large_total_cost:.6f}\")\n",
    "    print(\"Full Response:\")\n",
    "    print(result_large['content'])\n",
    "\n",
    "# Cost comparison summary\n",
    "if result_small and result_large:\n",
    "    cost_multiplier = large_total_cost / small_total_cost\n",
    "    print(f\"\\nðŸ’° Cost Analysis:\")\n",
    "    print(f\"Small model cost: ${small_total_cost:.6f}\")\n",
    "    print(f\"Large model cost: ${large_total_cost:.6f}\")\n",
    "    print(f\"Large model is {cost_multiplier:.1f}x more expensive\")\n",
    "    print(f\"\\nFor 697 job postings:\")\n",
    "    print(f\"Small model total: ${small_total_cost * 697:.2f}\")\n",
    "    print(f\"Large model total: ${large_total_cost * 697:.2f}\")\n",
    "    print(f\"Difference: ${(large_total_cost - small_total_cost) * 697:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to use large vs small models?\n",
    "\n",
    "Looking at both responses, they seem pretty similar, right? Both extracted the key information correctly. So why would you ever pay 15x more for the large model?\n",
    "\n",
    "**Small model wins when:**\n",
    "- Simple extraction tasks (skills, location, yes/no questions)\n",
    "- Consistent input format\n",
    "- High-volume processing (like our 697 jobs)\n",
    "- Budget constraints\n",
    "\n",
    "**Large model wins when:**\n",
    "- Complex reasoning required (\"Would this person from Recife be successful in this SÃ£o Paulo role given the cultural differences?\")\n",
    "- Ambiguous or poorly formatted input\n",
    "- Nuanced analysis (understanding implicit requirements)\n",
    "- Multi-step logical chains\n",
    "\n",
    "**Exercise for you:**\n",
    "Try these prompts and compare small vs large model responses:\n",
    "\n",
    "1. **Complex cultural reasoning:**\n",
    "```\n",
    "\"This job is in SÃ£o Paulo but requires frequent travel to Amazon region. \n",
    "The candidate is from Rio and has never been to Northern Brazil. \n",
    "Analyze the cultural and practical challenges they might face.\"\n",
    "```\n",
    "\n",
    "2. **Implicit skill detection:**\n",
    "```\n",
    "\"This job mentions 'coordinating with stakeholders across different time zones' \n",
    "and 'managing distributed teams.' What soft skills are implicitly required?\"\n",
    "```\n",
    "\n",
    "3. **Brazilian regulatory knowledge:**\n",
    "```\n",
    "\"This environmental consulting role mentions 'compliance with CONAMA regulations.' \n",
    "What does this tell us about the job requirements?\"\n",
    "```\n",
    "\n",
    "Share your results in the Teams channel - you'll probably find some interesting differences!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LLMs for Data Filtering\n",
    "\n",
    "### The problem\n",
    "We have 697 items in our dataset. How can we categorize them efficiently without manually reading everything?\n",
    "\n",
    "### Why traditional approaches fail\n",
    "**Regex and keyword matching** would be a nightmare here. Consider these challenges:\n",
    "- Job titles vary: \"Engenheiro de Energia Solar\" vs \"Solar Energy Engineer\" vs \"Renewable Systems Specialist\"  \n",
    "- Skills are described differently: \"2 years experience\" vs \"minimum 24 months\" vs \"experiÃªncia de 2 anos\"\n",
    "- Location formats differ: \"SÃ£o Paulo, SP\" vs \"Greater SÃ£o Paulo Area\" vs \"Estado de SÃ£o Paulo\"\n",
    "- Requirements buried in paragraphs vs structured lists\n",
    "\n",
    "**Rule-based classification** would need hundreds of if-then statements and constant maintenance.\n",
    "\n",
    "### The LLM solution\n",
    "LLMs understand **semantic meaning**, not just keywords:\n",
    "- They recognize \"energia renovÃ¡vel\" and \"renewable energy\" as the same concept\n",
    "- They infer experience levels from contextual clues\n",
    "- They handle inconsistent formatting gracefully  \n",
    "- They can extract implicit information (e.g., senior-level roles often mention \"leadership\")\n",
    "\n",
    "### The trade-offs\n",
    "- **Accuracy**: Much higher than regex, handles edge cases\n",
    "- **Cost**: API calls add up - need to optimize model choice\n",
    "- **Speed**: Slower than regex, but parallel processing helps\n",
    "- **Consistency**: Good with proper prompt design\n",
    "\n",
    "Let's see this in action..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Loaded training: tr_marc_vessel_operations_02.md\n",
      "Content length: 1258 characters\n"
     ]
    }
   ],
   "source": [
    "# Load a training example for filtering\n",
    "sample_training_path = None\n",
    "if training_files:\n",
    "    sample_training_path = training_files[0]\n",
    "    with open(sample_training_path, 'r', encoding='utf-8') as f:\n",
    "        sample_training = f.read()\n",
    "    \n",
    "    print(f\"ðŸ“ Loaded training: {sample_training_path.name}\")\n",
    "    print(f\"Content length: {len(sample_training)} characters\")\n",
    "else:\n",
    "    print(\"No training files available for analysis\")\n",
    "    sample_training = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple classifier\n",
    "def classify_seniority(content: str, model: str = \"mistral-large-latest\") -> str:\n",
    "    \"\"\"Figure out if this is entry-level, mid-level, or senior stuff\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"Look at this job/training content and tell me the seniority level. Analyze whole file before answering.\n",
    "Options:\n",
    "* Basic - Entry level, no experience needed\n",
    "* Intermediate - Some experience (1-3 years)\n",
    "* Advanced - Senior level (3+ years)\n",
    "\n",
    "Just respond with one word: Basic, Intermediate, or Advanced.\n",
    "\n",
    "Content:\n",
    "{content}\"\"\"\n",
    "    \n",
    "    result = call_mistral(prompt, model)\n",
    "    if result:\n",
    "        return result['content'].strip()\n",
    "    return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why this design works:\n",
    "\n",
    "- âœ… Constrained outputs: Only 3 possible answers reduces hallucination\n",
    "- âœ… Clear definitions: Explicit criteria for each level\n",
    "- âœ… Simple instruction: 'Just respond with one word' forces compliance\n",
    "- âœ… Context window: 'Analyze whole file' ensures complete understanding\n",
    "- âœ… Large model default: Classification needs reasoning, not just pattern matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Testing the classifier...\n",
      "Result: Intermediate\n",
      "---------------------------------------------------------------\n",
      "\n",
      "ðŸ“‹ Here's what it analyzed:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Why take this course?**\n",
       "\n",
       "The **Intermediate Ship Operations Training** will help you:\n",
       "âœ… Master ship handling and operational procedures on intermediate level\n",
       "âœ… Apply best practices for transparency and compliance\n",
       "âœ… Strengthen your resume with a recognized credential\n",
       "\n",
       "**Course Details:**\n",
       "- **Duration:** 8 weeks\n",
       "- **Format:** online\n",
       "- **Language:** Portuguese (Brazil)\n",
       "- **Certification:** Yes\n",
       "\n",
       "**Prerequisites:**\n",
       "- Basic knowledge of ship operations and maritime procedures\n",
       "\n",
       "This comprehensive program focuses on advancing your maritime operational expertise through practical scenarios and industry standards. You'll develop the technical competencies needed to handle complex vessel operations while ensuring safety and regulatory compliance.\n",
       "\n",
       "The training covers essential aspects of ship management, from navigation procedures to cargo handling protocols. Each module builds systematically on foundational concepts, preparing you for real-world challenges in maritime transport operations.\n",
       "\n",
       "Upon completion, you'll receive official certification that validates your intermediate-level capabilities in maritime operations, making you a stronger candidate for advancement in the shipping industry.\n",
       "\n",
       "**Don't miss the chance to stand outâ€”register today!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test it on our sample\n",
    "if sample_training:\n",
    "    print(\"ðŸŽ¯ Testing the classifier...\")\n",
    "    classification = classify_seniority(sample_training)\n",
    "    print(f\"Result: {classification}\")\n",
    "    print('---------------------------------------------------------------')\n",
    "    print(\"\\nðŸ“‹ Here's what it analyzed:\")\n",
    "    display_markdown_file(sample_training_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pro tips for production:\n",
    "\n",
    "- Start with large model for accuracy baseline\n",
    "- Test small model on sample - might be sufficient\n",
    "- Use temperature=0 for consistent classifications\n",
    "- Consider few-shot examples for edge cases\n",
    "- Always validate on known examples before scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Processing Strategy\n",
    "\n",
    "When you're processing hundreds of items, you need to think about **scale optimization**:\n",
    "\n",
    "**Why batch processing matters:**\n",
    "- **API rate limits**: Most APIs limit requests per minute/hour\n",
    "- **Progress tracking**: Users want to see something happening  \n",
    "- **Error handling**: Individual failures shouldn't kill the whole job\n",
    "- **Memory management**: Don't load all 697 files into memory at once\n",
    "- **Cost monitoring**: Track spending as you go, not at the end\n",
    "\n",
    "**Batch size considerations:**\n",
    "- **Too small** (1-2 items): Lots of overhead, slow overall progress\n",
    "- **Too large** (100+ items): Memory issues, harder to recover from errors\n",
    "- **Sweet spot** (10-25 items): Balance between efficiency and manageability\n",
    "\n",
    "**For our GDSC dataset:**\n",
    "- 697 total items to process\n",
    "- Average ~500 characters per item \n",
    "- At 10 items per batch = 70 batches total\n",
    "- Estimated time: 70 batches Ã— 2 seconds = ~2.5 minutes\n",
    "\n",
    "Let's implement a smart batch processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Processing 3 training files...\n",
      "Progress tracking and cost accumulation:\n",
      "\n",
      "Processing 1/3 (33%): tr_marc_vessel_operations_02.md\n",
      "  â†’ Based on the provided content, the training program should be classified as **Intermediate**.\n",
      "\n",
      "### Key Indicators:\n",
      "1. **Title:** \"Intermediate Ship Operations Training\" explicitly states the level.\n",
      "2. **Prerequisites:** Requires \"basic knowledge of ship operations and maritime procedures,\" implying prior foundational learning.\n",
      "3. **Content Focus:** Advances beyond basics (e.g., \"master ship handling,\" \"complex vessel operations,\" \"real-world challenges\") but does not suggest expert-level specialization (e.g., advanced simulations, leadership, or niche maritime technologies).\n",
      "4. **Certification:** Validates \"intermediate-level capabilities,\" not entry-level or advanced mastery.\n",
      "\n",
      "The program bridges foundational knowledge and advanced expertise, aligning with the **Intermediate** category. | 396 tokens | $0.001412\n",
      "Processing 2/3 (67%): tr_law_case_analysis_03.md\n",
      "  â†’ The training program **\"Advanced Legal Case Analysis Training\"** should be classified as **Advanced** based on the following criteria:\n",
      "\n",
      "1. **Title & Description**: The term \"Advanced\" is explicitly used in the title, and the content focuses on \"mastering complex legal reasoning\" and \"sophisticated analytical skills.\"\n",
      "2. **Prerequisites**: Requires \"Intermediate experience in analyzing legal cases and court decisions,\" indicating it builds on prior knowledge.\n",
      "3. **Content Depth**: Covers advanced techniques for dissecting judicial decisions, evaluating reasoning, and identifying legal principlesâ€”topics typically beyond basic or intermediate levels.\n",
      "\n",
      "Thus, the correct classification is:\n",
      "**Advanced** | 278 tokens | $0.001096\n",
      "Processing 3/3 (100%): tr_ele_electrical_wiring_02.md\n",
      "  â†’ Based on the provided content, the training program **\"Intermediate Wire Installation and Circuit Design\"** is clearly classified as an **Intermediate** level course.\n",
      "\n",
      "### Key Indicators:\n",
      "1. **Title & Description**: Explicitly labeled as \"Intermediate\" and builds on foundational knowledge.\n",
      "2. **Prerequisites**: Requires basic experience in wire installation and circuit fundamentals, implying prior foundational learning.\n",
      "3. **Content Depth**: Covers complex circuit layouts, advanced connection methods, and troubleshootingâ€”beyond basic skills but not yet expert-level.\n",
      "4. **Audience**: Targets professionals (electricians, technicians) and enthusiasts with some prior experience, not beginners.\n",
      "\n",
      "### Why Not Basic or Advanced?\n",
      "- **Not Basic**: It assumes prior knowledge and teaches intermediate techniques (e.g., multi-branch circuits).\n",
      "- **Not Advanced**: It lacks specialization in cutting-edge technologies or mastery-level problem-solving (e.g., high-voltage systems, industrial automation).\n",
      "\n",
      "**Final Classification: Intermediate** âœ… | 417 tokens | $0.001658\n",
      "\n",
      "ðŸ“Š Batch Processing Results:\n",
      "Items processed: 3\n",
      "Total tokens used: 1,091\n",
      "Total cost: $0.0042\n",
      "Average cost per item: $0.001389\n",
      "\n",
      "ðŸ’° Scaling to full dataset (697 items):\n",
      "Estimated cost with large model: $0.97\n",
      "Estimated cost with small model: $0.06\n",
      "Potential savings: $0.90\n",
      "\n",
      "âš¡ Performance insights:\n",
      "Average API call duration: 1.80 seconds\n",
      "Full dataset processing time: ~20.9 minutes\n",
      "Recommendation: Use parallel processing for production!\n"
     ]
    }
   ],
   "source": [
    "def batch_classify_trainings(training_files: list, batch_size: int = 5) -> dict:\n",
    "    \"\"\"Classify multiple trainings in batches to optimize API calls\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    total_cost = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    # Process first few files as example (in production, remove [:3])\n",
    "    sample_files = training_files[:3]  # Just process 3 for demo\n",
    "    \n",
    "    print(f\"ðŸ”„ Processing {len(sample_files)} training files...\")\n",
    "    print(f\"Progress tracking and cost accumulation:\")\n",
    "    print()\n",
    "    \n",
    "    for i, file_path in enumerate(sample_files):\n",
    "        # Progress indicator\n",
    "        progress = ((i + 1) / len(sample_files)) * 100\n",
    "        print(f\"Processing {i+1}/{len(sample_files)} ({progress:.0f}%): {file_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Classify and get actual token usage\n",
    "            result = call_mistral(f\"\"\"Classify this training program seniority level:\n",
    "Options: Basic, Intermediate, Advanced\n",
    "Content: {content}\"\"\", \"mistral-small-latest\")\n",
    "            \n",
    "            if result:\n",
    "                # Calculate actual costs based on token usage\n",
    "                input_cost = (result['input_tokens'] / 1_000_000) * 2.00  # Small model input\n",
    "                output_cost = (result['output_tokens'] / 1_000_000) * 6.00  # Small model output\n",
    "                item_cost = input_cost + output_cost\n",
    "                \n",
    "                total_cost += item_cost\n",
    "                total_tokens += result['total_tokens']\n",
    "                \n",
    "                results[file_path.name] = {\n",
    "                    'seniority': result['content'].strip(),\n",
    "                    'tokens': result['total_tokens'],\n",
    "                    'cost': item_cost,\n",
    "                    'duration': result['duration']\n",
    "                }\n",
    "                \n",
    "                print(f\"  â†’ {result['content'].strip()} | {result['total_tokens']} tokens | ${item_cost:.6f}\")\n",
    "            else:\n",
    "                print(f\"  â†’ Error processing {file_path.name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  â†’ Error processing {file_path.name}: {e}\")\n",
    "            results[file_path.name] = {'seniority': 'Error', 'tokens': 0, 'cost': 0, 'duration': 0}\n",
    "    \n",
    "    return results, total_cost, total_tokens\n",
    "\n",
    "# Run batch classification with cost tracking\n",
    "if training_files:\n",
    "    batch_results, batch_cost, batch_tokens = batch_classify_trainings(training_files)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Batch Processing Results:\")\n",
    "    print(f\"Items processed: {len(batch_results)}\")\n",
    "    print(f\"Total tokens used: {batch_tokens:,}\")\n",
    "    print(f\"Total cost: ${batch_cost:.4f}\")\n",
    "    print(f\"Average cost per item: ${batch_cost / len(batch_results):.6f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ’° Scaling to full dataset (697 items):\")\n",
    "    avg_cost_per_item = batch_cost / len(batch_results)\n",
    "    full_dataset_cost = avg_cost_per_item * 697\n",
    "    print(f\"Estimated cost with large model: ${full_dataset_cost:.2f}\")\n",
    "    \n",
    "    # Cost comparison with small model (roughly 15x cheaper)\n",
    "    small_model_cost = full_dataset_cost / 15\n",
    "    print(f\"Estimated cost with small model: ${small_model_cost:.2f}\")\n",
    "    print(f\"Potential savings: ${full_dataset_cost - small_model_cost:.2f}\")\n",
    "    \n",
    "    print(f\"\\nâš¡ Performance insights:\")\n",
    "    avg_duration = sum(r.get('duration', 0) for r in batch_results.values()) / len(batch_results)\n",
    "    print(f\"Average API call duration: {avg_duration:.2f} seconds\")\n",
    "    print(f\"Full dataset processing time: ~{(avg_duration * 697) / 60:.1f} minutes\")\n",
    "    print(f\"Recommendation: Use parallel processing for production!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises (aka homework)\n",
    "\n",
    "### Exercise 1: Data analysis\n",
    "Build some actual statistics about our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your mission: analyze the dataset properly\n",
    "# What we want to know about Brazilian green jobs:\n",
    "# - Geographic distribution (SÃ£o Paulo, Rio, BrasÃ­lia, Salvador, Recife, etc.)\n",
    "# - Average token counts per category\n",
    "# - Most common skills mentioned\n",
    "# - Portuguese vs English content ratio\n",
    "# - Green job concentration by region\n",
    "\n",
    "print(\"ðŸ“ Exercise 1: Data analysis\")\n",
    "print(\"Use LLMs to extract domains from job titles and training content\")\n",
    "print(\"Count location mentions across major Brazilian cities\")  \n",
    "print(\"Calculate processing costs for different classification approaches\")\n",
    "print(\"Bonus: Identify uniquely Brazilian requirements (e.g., Portuguese fluency, CONAMA compliance)\")\n",
    "\n",
    "# Your code goes here...\n",
    "# Hint: Use the classify function pattern we just built\n",
    "# Consider analyzing:\n",
    "# - Job titles: \"Engenheiro Ambiental\" vs \"Environmental Engineer\"\n",
    "# - Location patterns: \"SÃ£o Paulo, SP\" vs \"Greater SÃ£o Paulo\" vs \"Interior de SÃ£o Paulo\"\n",
    "# - Brazilian-specific skills: Portuguese fluency, local regulations, regional travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Cost optimization\n",
    "Figure out the cheapest way to process everything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost comparison challenge\n",
    "# Calculate costs for:\n",
    "# 1. All 697 items with small model\n",
    "# 2. All 697 items with large model\n",
    "# 3. Hybrid: small for classification, large for complex analysis\n",
    "\n",
    "print(\"ðŸ“ Exercise 2: Cost optimization\")\n",
    "print(\"Which approach gives best quality/cost ratio?\")\n",
    "print(\"What's the break-even point?\")\n",
    "\n",
    "# Your implementation here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Green jobs detector\n",
    "Build a classifier for sustainability-related jobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Green jobs classifier for Brazilian context\n",
    "def is_green_job(content: str) -> bool:\n",
    "    \"\"\"Detect sustainability/climate-related jobs and trainings in Brazilian context\"\"\"\n",
    "    # Your implementation here\n",
    "    # Look for keywords like: \n",
    "    # - English: renewable energy, sustainability, climate, environment, solar, wind\n",
    "    # - Portuguese: energia renovÃ¡vel, sustentabilidade, meio ambiente, solar, eÃ³lica\n",
    "    # - Brazilian specifics: CONAMA, AmazÃ´nia, Mata AtlÃ¢ntica, etanol, biodiesel\n",
    "    # - Companies: Petrobras renewables, Vale sustainability, Suzano forestry\n",
    "    pass\n",
    "\n",
    "print(\"ðŸ“ Exercise 3: Green jobs detector\")\n",
    "print(\"Build a classifier that recognizes sustainability jobs in both Portuguese and English\")\n",
    "print(\"Test it on the dataset - how many green opportunities can you find?\")\n",
    "print(\"Bonus questions:\")\n",
    "print(\"â€¢ What makes a job 'green' in the Brazilian context?\")\n",
    "print(\"â€¢ How do green job requirements differ between SÃ£o Paulo (urban) and Amazon region?\")\n",
    "print(\"â€¢ Which green sectors are growing fastest in Brazil?\")\n",
    "\n",
    "# Implement the function and test it...\n",
    "# Consider Brazilian green job examples:\n",
    "# - Solar panel installer in Northeast Brazil\n",
    "# - Environmental consultant for mining companies  \n",
    "# - Sustainable agriculture specialist in Cerrado region\n",
    "# - Carbon credit analyst for forestry companies\n",
    "# - Renewable energy engineer for hydroelectric plants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we learned\n",
    "\n",
    "âœ… **Data structure**: 697 items in messy formats  \n",
    "âœ… **API basics**: Tokens, models, costs  \n",
    "âœ… **Smart filtering**: LLMs > regex for unstructured data  \n",
    "âœ… **Cost optimization**: Start small, scale strategically  \n",
    "\n",
    "### The real lessons\n",
    "- Token counting matters when you're processing lots of data\n",
    "- Small models are surprisingly good for classification tasks\n",
    "- Always track costs as you go\n",
    "\n",
    "### Next up\n",
    "Tutorial 3: Building your first submission and getting on the leaderboard ASAP."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdsc-env (3.11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
