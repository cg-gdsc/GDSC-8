{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52bfd4bb",
   "metadata": {},
   "source": [
    "# **Tutorial 3** - Introduction to AI Agents: Green Agents of Change\n",
    "\n",
    "Welcome to the exciting world of AI agents! In this tutorial, we'll dive deep into building intelligent systems that can help solve real-world problems, specifically focusing on our challenge: connecting young people in Brazil with green and future-proof career opportunities.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "After completing this tutorial, you'll understand:\n",
    "- **How to build multi-agent systems** using the Strands Agents framework\n",
    "- **Real-world application** of AI agents for job matching and career guidance\n",
    "- **Best practices** for developing sustainable and efficient AI solutions\n",
    "\n",
    "## The Challenge Context\n",
    "\n",
    "This year's Global Data Science Challenge focuses on empowering youth across Brazil to explore, discover, and pursue green and future-proof jobs. We're collaborating with AI agents to:\n",
    "\n",
    "- Sift through thousands of job descriptions and training opportunities\n",
    "- Match people to roles that fit their preferences and potential\n",
    "- Recommend concrete learning paths to help them reach their goals\n",
    "\n",
    "This involves sophisticated retrieval over real data, thoughtful matching and ranking algorithms, and smart prompt engineering - all powered by AI agents working together.\n",
    "\n",
    "## Why AI Agents Matter\n",
    "\n",
    "AI agents represent the next evolution in artificial intelligence. Unlike simple chatbots or traditional AI systems that follow fixed rules, AI agents can:\n",
    "\n",
    "- **Adapt and Learn**: They can adjust their behavior based on new information and changing circumstances\n",
    "- **Work Collaboratively**: Multiple agents can work together, each with specialized roles and expertise\n",
    "- **Use Tools**: They can interact with external systems, databases, and APIs to accomplish complex tasks\n",
    "- **Make Decisions**: They can evaluate options and choose the best course of action autonomously\n",
    "\n",
    "In our green careers challenge, we'll see how these capabilities come together to create a powerful system for career guidance and opportunity matching.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99d8690",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. [Environment Setup](#environment-setup)\n",
    "   - Installing required libraries and dependencies\n",
    "   - Setting up API keys and environment variables\n",
    "   - Data download and sanity checks\n",
    "\n",
    "2. [Understanding AI Agents](#understanding-ai-agents)\n",
    "   - What are AI agents and how do they work?\n",
    "   - Key components: Models, Tools, and Structured Output\n",
    "   - The Strands Agents framework\n",
    "\n",
    "3. [Core Components and Utilities](#core-utilities)\n",
    "   - Essential functions for agent interaction\n",
    "   - Data loading and processing utilities\n",
    "   - Understanding the codebase structure\n",
    "\n",
    "4. [Data Structures and Models](#data-structures)\n",
    "   - PersonaInfo, JobInfo, and TrainingInfo models\n",
    "   - Structured data extraction with Pydantic\n",
    "   - Why structured output matters\n",
    "\n",
    "5. [Building Your First AI Agent](#first-agent)\n",
    "   - Creating conversation agents\n",
    "   - Extracting information from conversations\n",
    "   - Testing agent interactions\n",
    "\n",
    "6. [Multi-Agent Collaboration](#multi-agent-system)\n",
    "   - Information extraction agents\n",
    "   - Matching and recommendation agents\n",
    "   - Orchestrating multiple agents together\n",
    "\n",
    "7. [Real-World Application](#real-world-application)\n",
    "   - Processing job descriptions and training programs\n",
    "   - Matching personas to opportunities\n",
    "   - Generating final recommendations\n",
    "\n",
    "8. [Testing and Optimization](#testing-optimization)\n",
    "   - Testing your matching algorithm\n",
    "   - Token usage and efficiency considerations\n",
    "   - Debugging AI agent systems\n",
    "\n",
    "9. [Conclusion and Next Steps](#conclusion)\n",
    "   - Summary of key learnings\n",
    "   - Best practices for AI agent development\n",
    "   - Preparing for the challenge submission\n",
    "\n",
    "10. [Appendix](#appendix)\n",
    "    - Framework comparisons and alternatives\n",
    "    - Advanced techniques and resources\n",
    "    - Troubleshooting guide\n",
    "\n",
    "---\n",
    "\n",
    "# Environment Setup <a id='environment-setup'></a>\n",
    "\n",
    "Before we can start working with AI agents, we need to set up our development environment. This includes installing the necessary libraries, configuring API keys, and ensuring we have access to the challenge data.\n",
    "\n",
    "## Installing Required Libraries\n",
    "\n",
    "The most important library for this year's challenge is [Strands Agents](https://strandsagents.com/latest/), which provides a powerful framework for creating and managing AI agents. We'll also need several supporting libraries for data handling and API interactions.\n",
    "\n",
    "The cell below needs to be run just once on every JupyterLab restart. To run it, click on it and press \"Shift + Enter\" or press the \"‚ñ∑\" symbol on the top bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29186a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for AI agent development\n",
    "# This may take a few minutes - be patient!\n",
    "!pip install python-dotenv strands-agents[mistral] strands-agents-tools tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9af9bd",
   "metadata": {},
   "source": [
    "Let's understand what each library does:\n",
    "\n",
    "- **`python-dotenv`**: Manages environment variables securely, keeping sensitive information like API keys out of your code\n",
    "- **`strands-agents[mistral]`**: The core framework for building AI agents, with Mistral LLM integration\n",
    "- **`strands-agents-tools`**: Additional tools and utilities for agent development\n",
    "- **`tqdm`**: Provides progress bars for long-running operations - very helpful when processing large datasets\n",
    "\n",
    "The installation process may take a few minutes. You'll see various dependency installations, which is normal.\n",
    "\n",
    "## Downloading Challenge Data\n",
    "\n",
    "Next, we need to download the challenge dataset, which includes job descriptions, training programs, and persona profiles. You may have already done this in previous tutorials - if so, you can skip this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4384be",
   "metadata": {},
   "source": [
    "The dataset contains three main components:\n",
    "- **Jobs**: Structured job offers in JSON format stored in Markdown files\n",
    "- **Training Programs**: Relevant training opportunities with skills and levels\n",
    "\n",
    "If you haven't downloaded the data yet, run the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9517d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the challenge dataset from AWS S3\n",
    "# This command downloads all necessary data files quietly\n",
    "!aws s3 cp s3://gdsc-25-data-bucket/ . --recursive --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daec1e7",
   "metadata": {},
   "source": [
    "## Setting Up Environment Variables\n",
    "\n",
    "Security is crucial when working with AI agents and APIs. We use environment variables to store sensitive information like API keys, ensuring they never appear directly in our code.\n",
    "\n",
    "Create an `env` file in your working directory to store sensitive variables. This file should contain your API keys and other configuration settings.\n",
    "\n",
    "Method on how to get the Mistral API Key was covered in the previous tutorials.\n",
    "\n",
    "Your `env` file should look like this:\n",
    "\n",
    "```bash\n",
    "MISTRAL_API_KEY=your_actual_api_key_here\n",
    "```\n",
    "\n",
    "**Important Security Notes:**\n",
    "- Never commit the `env` file to version control\n",
    "- Keep your API keys secret and secure\n",
    "- If you suspect your key has been compromised, regenerate it immediately\n",
    "\n",
    "**Note**: After updating the env file, you may need to restart your notebook for changes to take effect. Click the \"‚ü≥\" symbol on the top bar to restart."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd78bb",
   "metadata": {},
   "source": [
    "## Understanding Token Usage and Costs\n",
    "\n",
    "When working with AI agents, it's important to understand that each interaction with the language model consumes \"tokens\" - the basic units of text processing. This has implications for both performance and cost:\n",
    "\n",
    "- **Tokens**: Words and parts of words that the model processes\n",
    "- **Cost**: Most AI models charge per token used\n",
    "- **Efficiency**: Better prompts and structured approaches can reduce token usage\n",
    "\n",
    "Throughout this tutorial, we'll show you how to build efficient AI agents that accomplish more with fewer tokens, making your solutions both faster and more cost-effective.\n",
    "\n",
    "---\n",
    "\n",
    "# Understanding AI Agents <a id='understanding-ai-agents'></a>\n",
    "\n",
    "Now that our environment is set up, let's dive into the core concepts behind AI agents and understand what makes them so powerful for solving complex problems like career matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f773a",
   "metadata": {},
   "source": [
    "# Basic solution\n",
    "After the environment setup is completed we can move forward and get to know the code. As mentioned before this year we are using [Strands Agents](https://strandsagents.com/latest/) as our main library used for interacting with LLMs and creating AI agents. The models that we are going to use come from [Mistral](https://mistral.ai/).\n",
    "\n",
    "You can modify anything in the code you'd like as long as you provide the final data in the required format (more about the required format in upcomng sections)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1bc86",
   "metadata": {},
   "source": [
    "## AI Agents\n",
    "\n",
    "AI agents are intelligent systems that can perceive their environment, make decisions, and take actions to achieve specific goals. Unlike traditional software that follows predefined rules, AI agents can adapt, learn, and work autonomously.\n",
    "\n",
    "### Key Characteristics of AI Agents:\n",
    "\n",
    "1. **Autonomy**: They can operate independently without constant human oversight\n",
    "2. **Reactivity**: They respond to changes in their environment\n",
    "3. **Pro-activeness**: They take initiative to achieve their goals\n",
    "4. **Social Ability**: They can interact with other agents and humans\n",
    "\n",
    "### How AI Agents Differ from Traditional AI:\n",
    "\n",
    "- **Traditional AI**: Processes input ‚Üí produces output (like a function)\n",
    "- **AI Agents**: Continuously interact with environment ‚Üí make decisions ‚Üí take actions ‚Üí learn from results\n",
    "\n",
    "### Components of Our AI Agent System:\n",
    "\n",
    "1. **Language Models**: The \"brain\" that provides reasoning and language understanding\n",
    "2. **Structured Output**: Ensures consistent, processable responses using Pydantic models\n",
    "3. **Tools and APIs**: Allow agents to interact with external systems\n",
    "4. **Conversation Management**: Handles multi-turn interactions with personas\n",
    "\n",
    "In our career matching challenge, we'll use these components to create agents that can:\n",
    "- Conduct natural conversations with job seekers\n",
    "- Extract structured information from unstructured text\n",
    "- Match people to appropriate opportunities\n",
    "- Generate personalized recommendations\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our foundation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fbdbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Core libraries for AI agent development\n",
    "import json\n",
    "import os\n",
    "import boto3\n",
    "import dotenv\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple, Type, TypeVar, Any\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Structured data models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Strands Agents framework - our main AI agent library\n",
    "from strands.agent import Agent\n",
    "from strands.models.mistral import MistralModel\n",
    "\n",
    "# AWS integration for API calls\n",
    "from botocore.auth import SigV4Auth\n",
    "from botocore.awsrequest import AWSRequest\n",
    "\n",
    "# Type hints for better code quality\n",
    "T = TypeVar('T')\n",
    "M = TypeVar('M', bound=BaseModel)\n",
    "\n",
    "# Load environment variables from our env file\n",
    "dotenv.load_dotenv(\"env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44256fd3",
   "metadata": {},
   "source": [
    "## System Health Check\n",
    "\n",
    "Before we start building our AI agents, let's verify that our connection to the challenge infrastructure is working correctly. This sanity check ensures we can communicate with the persona API endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77440b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check():\n",
    "    \"\"\"\n",
    "    Verify connection to the challenge API infrastructure.\n",
    "    \n",
    "    This function tests our AWS credentials and API access by making a health check\n",
    "    request to the challenge endpoints. This ensures we can interact with the persona\n",
    "    agents that represent our job seekers.\n",
    "    \"\"\"\n",
    "    base_url = \"https://cygeoykm2i.execute-api.us-east-1.amazonaws.com/main/health\"\n",
    "    \n",
    "    # Set up AWS session and credentials\n",
    "    session = boto3.Session(region_name='us-east-1')\n",
    "    credentials = session.get_credentials()\n",
    "    region = 'us-east-1'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Create and sign the AWS request\n",
    "    request = AWSRequest(method='GET', url=base_url, data=None, headers=headers)\n",
    "    SigV4Auth(credentials, 'execute-api', region).add_auth(request)\n",
    "    \n",
    "    # Make the request\n",
    "    response = requests.request(\n",
    "        method=request.method,\n",
    "        url=request.url,\n",
    "        headers=dict(request.headers),\n",
    "        data=request.body\n",
    "    )\n",
    "\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Sanity check passed! You're ready to interact with personas.\")\n",
    "    else:\n",
    "        print(\"‚ùå Sanity check failed!\")\n",
    "        print(f\"Response: {response.text}\")\n",
    "        print(\"Please check your AWS credentials and network connection.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86967b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: 200\n",
      "Sanity check passed!\n"
     ]
    }
   ],
   "source": [
    "# Run the sanity check to verify our setup\n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58471e1e",
   "metadata": {},
   "source": [
    "# Core Components and Utilities <a id='core-utilities'></a>\n",
    "\n",
    "This section defines the essential building blocks for our AI agent system. These utility functions handle everything from creating agents to managing data files. Understanding these components is crucial for building effective AI solutions.\n",
    "\n",
    "## Key Functions Overview:\n",
    "\n",
    "### Agent Management\n",
    "- **`get_agent()`**: Creates and configures AI agents with specific roles and capabilities\n",
    "- **`send_message_to_chat()`**: Handles communication with persona agents\n",
    "- **`get_conversation()`**: Manages multi-turn conversations with personas\n",
    "\n",
    "### Data Management\n",
    "- **`load_file_content()`**: Reads raw content from files (job descriptions, training programs)\n",
    "- **`read_json()` / `save_json()`**: Handle JSON data persistence for caching results\n",
    "- **`get_job_paths()` / `get_training_paths()`**: Discover available data files\n",
    "\n",
    "### Information Extraction\n",
    "- **`extract_info()`**: Uses AI agents to extract structured data from unstructured text\n",
    "- **`extract_info_from_conversation()`**: Processes conversation transcripts\n",
    "- **`extract_info_to_json()`**: Batch processes files with caching and error handling\n",
    "\n",
    "Let's examine the implementation details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent(\n",
    "    system_prompt: str = \"\",\n",
    "    model_id: str = \"mistral-medium-latest\"\n",
    ") -> Agent:\n",
    "    \"\"\"\n",
    "    Create and configure an AI agent with specified capabilities.\n",
    "    \n",
    "    This is the core function for creating AI agents. The system prompt defines\n",
    "    the agent's role, expertise, and behavior patterns. Different model IDs\n",
    "    offer different capabilities and cost profiles.\n",
    "    \n",
    "    Args:\n",
    "        system_prompt: Instructions defining the agent's role and behavior\n",
    "        model_id: Mistral model to use (e.g., 'mistral-medium-latest', 'mistral-small-latest')\n",
    "    \n",
    "    Returns:\n",
    "        Configured Agent ready for interaction\n",
    "    \"\"\"\n",
    "    model = MistralModel(\n",
    "        api_key=os.environ[\"MISTRAL_API_KEY\"],\n",
    "        model_id=model_id,\n",
    "        stream=False  # Non-streaming for better control in batch operations\n",
    "    )\n",
    "    return Agent(model=model, system_prompt=system_prompt, callback_handler=None)\n",
    "\n",
    "\n",
    "def load_file_content(path: str | Path) -> str:\n",
    "    \"\"\"\n",
    "    Load raw text content from a file.\n",
    "    \n",
    "    Used for reading job descriptions, training programs, and other text files\n",
    "    that need to be processed by our AI agents.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "\n",
    "def read_json(path: str | Path):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file.\n",
    "    \n",
    "    Essential for loading cached results, configuration files, and structured data.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_json(path: str | Path, data: Dict | List):\n",
    "    \"\"\"\n",
    "    Save data to a JSON file.\n",
    "    \n",
    "    Used for caching extracted information to avoid redundant API calls and\n",
    "    preserve results between sessions.\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    with path.open('w', encoding='utf-8') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "\n",
    "def get_job_paths() -> List[Path]:\n",
    "    \"\"\"\n",
    "    Discover all job description files in the dataset.\n",
    "    \n",
    "    Scans the jobs directory for Markdown files containing structured job information.\n",
    "    Each file represents one job opportunity in our challenge dataset.\n",
    "    \"\"\"\n",
    "    data_dir = Path('./data/jobs')\n",
    "    paths = []\n",
    "    for file in data_dir.iterdir():\n",
    "        if file.suffix == '.md':\n",
    "            paths.append(file)\n",
    "    return paths\n",
    "\n",
    "\n",
    "def get_training_paths() -> List[Path]:\n",
    "    \"\"\"\n",
    "    Discover all training program files in the dataset.\n",
    "    \n",
    "    Scans the trainings directory for Markdown files containing training opportunities.\n",
    "    Each file describes skills, levels, and learning outcomes.\n",
    "    \"\"\"\n",
    "    data_dir = Path('./data/trainings')\n",
    "    paths = []\n",
    "    for file in data_dir.iterdir():\n",
    "        if file.suffix == '.md':\n",
    "            paths.append(file)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5f9d3a",
   "metadata": {},
   "source": [
    "# Data Structures and Models <a id='data-structures'></a>\n",
    "\n",
    "One of the key advantages of modern AI agent systems is their ability to produce **structured output**. Instead of just generating free-form text, our agents can create data that follows specific schemas, making it easy to process programmatically.\n",
    "\n",
    "We use **Pydantic models** to define these data structures. Pydantic provides:\n",
    "\n",
    "- **Type validation**: Ensures data meets our requirements\n",
    "- **Automatic parsing**: Converts AI-generated text into Python objects\n",
    "- **Documentation**: Clear field descriptions help agents understand what to generate\n",
    "- **Error handling**: Graceful failures when data doesn't match expected format\n",
    "\n",
    "## Our Core Data Models\n",
    "\n",
    "### PersonaInfo\n",
    "Represents information about job seekers extracted from conversations. This structured approach ensures we capture all essential details consistently.\n",
    "\n",
    "### JobInfo  \n",
    "Contains the key requirements and characteristics of job opportunities, extracted from job descriptions.\n",
    "\n",
    "### TrainingInfo\n",
    "Describes training programs including skills acquired and proficiency levels.\n",
    "\n",
    "### IDList\n",
    "A simple container for lists of identifiers, used when agents need to return multiple recommendations.\n",
    "\n",
    "## Why Structured Output Matters\n",
    "\n",
    "In traditional AI systems, you might get responses like \"This person seems interested in environmental work and has some experience with sustainability.\" Although sentences like this hold the necessary information, it is tough to use it in a program with strict data structures. By using structured output calls, we get precise, actionable data:\n",
    "```python\n",
    "PersonaInfo(\n",
    "    name=\"Maria Silva\",\n",
    "    skills=[(\"sustainability\", \"intermediate\"), (\"project_management\", \"beginner\")],\n",
    "    location=\"S√£o Paulo\",\n",
    "    age=\"24\",\n",
    "    years_of_experience=\"2\"\n",
    ")\n",
    "```\n",
    "\n",
    "This structured approach enables:\n",
    "- **Consistent processing**: Every persona has the same data fields\n",
    "- **Easy matching**: We can compare skills, locations, and experience levels programmatically  \n",
    "- **Reliable integration**: Other systems can depend on the data format\n",
    "- **Quality assurance**: We can validate that all required information was captured\n",
    "\n",
    "Let's examine our data models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853ef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JobInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured representation of job requirements and characteristics.\n",
    "    \n",
    "    This model captures the essential information needed to match candidates\n",
    "    to job opportunities. The AI agent extracts this information from\n",
    "    unstructured job descriptions.\n",
    "    \"\"\"\n",
    "    required_skills: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of required skills for the job.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Job location.\"\n",
    "    )\n",
    "    years_of_experience_required: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Years of experience required to get this job.\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a human-readable description for AI agents to process.\"\"\"\n",
    "        skills = ', '.join(self.required_skills)\n",
    "        return (\n",
    "            f\"Required skills: {skills}\\nLocation: {self.location}\\n\"\n",
    "            f\"Years of experience required: {self.years_of_experience_required}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class TrainingInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents training programs and the skills they provide.\n",
    "    \n",
    "    Each training program teaches specific skills at defined proficiency levels.\n",
    "    This information is crucial for recommending learning paths to candidates.\n",
    "    \"\"\"\n",
    "    skill_acquired_and_level: Tuple[str, str] = Field(\n",
    "        default=(\"not specified\", \"not specified\"),\n",
    "        description=\"A pair of skill name and level. This tuple contains only 2 elements!\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a human-readable description for AI agents to process.\"\"\"\n",
    "        skill = f'{self.skill_acquired_and_level[0]}: level {self.skill_acquired_and_level[1]}'\n",
    "        return f\"Acquired skills: {skill}\"\n",
    "\n",
    "\n",
    "class PersonaInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    Comprehensive profile of a job seeker extracted from conversations.\n",
    "    \n",
    "    This model captures all the essential information needed to match\n",
    "    candidates with appropriate opportunities and training programs.\n",
    "    \"\"\"\n",
    "    name: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Persona's name\"\n",
    "    )\n",
    "    skills: List[Tuple[str, str]] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of pairs representing skills and its level.\"\n",
    "    )\n",
    "    location: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Current location\"\n",
    "    )\n",
    "    age: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Age of the persona\"\n",
    "        )\n",
    "    years_of_experience: str = Field(\n",
    "        default=\"unknown\",\n",
    "        description=\"Years of experience in a field.\"\n",
    "    )\n",
    "\n",
    "    def describe(self) -> str:\n",
    "        \"\"\"Create a comprehensive human-readable profile for AI agents.\"\"\"\n",
    "        skills = ', '.join([\n",
    "            f'{skill}: {level}'\n",
    "            for skill, level in self.skills\n",
    "        ])\n",
    "        return (\n",
    "            f\"Name: {self.name}\\n\"\n",
    "            f\"Skills: {skills}\\n\"\n",
    "            f\"Location: {self.location}\\n\"\n",
    "            f\"Age: {self.age}\\n\"\n",
    "            f\"Years of experience: {self.years_of_experience}\"\n",
    "        )\n",
    "\n",
    "\n",
    "class IDList(BaseModel):\n",
    "    \"\"\"\n",
    "    Simple container for lists of identifiers.\n",
    "    \n",
    "    Used when AI agents need to return multiple recommendations,\n",
    "    such as a list of suitable job IDs or training program IDs.\n",
    "    \"\"\"\n",
    "    values: List[str] = Field(default_factory=list, description=\"A list of string IDs (job IDs, training IDs, etc.)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb50184",
   "metadata": {},
   "source": [
    "# Building Your First AI Agent <a id='first-agent'></a>\n",
    "\n",
    "Now we'll create our first AI agents that can have conversations with job seekers (personas) and extract structured information from those conversations. This is where the magic happens - we're moving from static data processing to dynamic, intelligent interactions.\n",
    "\n",
    "## The Persona System\n",
    "\n",
    "In our challenge, \"personas\" are AI agents that represent fictional job seekers. Each persona has:\n",
    "- A unique background and career interests\n",
    "- Specific skills and experience levels  \n",
    "- Location preferences and constraints\n",
    "- Personal goals and motivations\n",
    "\n",
    "Our job is to build agents that can:\n",
    "1. **Conduct natural conversations** with these personas\n",
    "2. **Extract key information** about their profiles and preferences\n",
    "3. **Match them** to appropriate jobs and training opportunities\n",
    "\n",
    "## Conversation Management\n",
    "\n",
    "The `get_conversation()` function orchestrates multi-turn dialogues with personas. It demonstrates several key AI agent principles:\n",
    "\n",
    "- **Goal-oriented behavior**: The agent has a clear objective (gather specific information)\n",
    "- **Adaptive questioning**: Questions evolve based on persona responses\n",
    "- **Context management**: The agent maintains conversation history\n",
    "- **Efficiency awareness**: Limited turns prevent infinite conversations\n",
    "\n",
    "### Conversation ID\n",
    "‚ö†Ô∏è Important Note: There is a strict limit on the number of conversations each team can conduct with a persona. Teams are allowed up to 5 conversations per day, per persona, with each conversation capped at 20 messages. This limitation ensures fair usage, prevents brute-forcing solutions, and helps manage token consumption effectively. While this may seem restrictive, it is essential for maintaining the integrity and efficiency of the system. **Conversation ID** was introduced for that reason. When calling the persona endpoint for the first time you will receive a conversation ID that need to be passed in the payload in order to get back to the right conversation.\n",
    "\n",
    "\n",
    "Let's examine how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0651b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message_to_chat(message: str, persona_id: str, conversation_id: str = None) -> Optional[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Send a message to a persona agent and receive their response.\n",
    "    \n",
    "    This function handles the low-level communication with the challenge API,\n",
    "    managing AWS authentication and conversation state. Each persona maintains\n",
    "    their own conversation context across multiple turns.\n",
    "    \n",
    "    Args:\n",
    "        message: The message to send to the persona\n",
    "        persona_id: Unique identifier for the persona (e.g., 'persona_001')\n",
    "        conversation_id: Optional conversation ID for maintaining context\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (persona_response, conversation_id) or None if failed\n",
    "    \"\"\"\n",
    "    url = \"https://cygeoykm2i.execute-api.us-east-1.amazonaws.com/main/chat\"\n",
    "    \n",
    "    # Set up AWS authentication\n",
    "    session = boto3.Session(region_name='us-east-1')\n",
    "    credentials = session.get_credentials()\n",
    "    region = 'us-east-1'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    \n",
    "    # Prepare the message payload\n",
    "    payload = {\n",
    "        \"persona_id\": persona_id,\n",
    "        \"conversation_id\": conversation_id,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "    # Create and sign the AWS request\n",
    "    request = AWSRequest(\n",
    "        method='POST',\n",
    "        url=url,\n",
    "        data=json.dumps(payload),\n",
    "        headers=headers\n",
    "    )\n",
    "    SigV4Auth(credentials, 'execute-api', region).add_auth(request)\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.request(\n",
    "        method=request.method,\n",
    "        url=request.url,\n",
    "        headers=dict(request.headers),\n",
    "        data=request.body\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        return None\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json['response'], response_json['conversation_id']\n",
    "\n",
    "\n",
    "def get_conversation(persona_id: str, max_turns: int = 5, print_conversation: bool = False, print_token_no: bool = False) -> List[str]:\n",
    "    \"\"\"\n",
    "    Conduct a structured conversation with a persona to gather career information.\n",
    "    \n",
    "    This function demonstrates key AI agent capabilities:\n",
    "    - Goal-oriented dialogue management\n",
    "    - Adaptive questioning based on responses  \n",
    "    - Context maintenance across conversation turns\n",
    "    - Efficient information extraction within token limits\n",
    "    \n",
    "    Args:\n",
    "        persona_id: Unique identifier for the persona to interview\n",
    "        max_turns: Maximum conversation turns to prevent infinite loops\n",
    "        print_conversation: Whether to display the full conversation\n",
    "        print_token_no: Whether to show token usage statistics\n",
    "        \n",
    "    Returns:\n",
    "        List of conversation messages for further processing\n",
    "    \"\"\"\n",
    "    # Define the agent's role and objectives\n",
    "    system_prompt = \"\"\"\n",
    "    Continue to ask questions about this person - do not provide the jobs, trainings or anything yet.\n",
    "    You are a helpful and empathetic assistant. Your goal is to engage in a natural conversation with a persona to gather the following information:\n",
    "    - Their name\n",
    "    - Their skills and **level of this skill**\n",
    "    - Their current location\n",
    "    - Their age\n",
    "    - Their preferences\n",
    "    - Years of experience\n",
    "\n",
    "    Remember to always gather all of those information!\n",
    "    Ask open-ended questions to encourage detailed responses. Be polite, patient, and adapt your questions based on their answers.\n",
    "    If the persona is unsure or vague, gently probe for more details. Do not ask all questions at once; let the conversation flow naturally.\n",
    "    **Do not comment on whatever the response is. Just ask questions to retrieve the information.**\n",
    "    \"\"\"\n",
    "    conversation = []\n",
    "    current_turn = 0\n",
    "    total_tokens = 0\n",
    "    conversation_agent = get_agent(system_prompt)\n",
    "    conversation_id = None\n",
    "\n",
    "    # greeting\n",
    "    agent_message = \"Hello! I'm here to help you find the best job or training opportunities. Can you tell me your name?\"\n",
    "    conversation_agent.messages = [{\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": [{\n",
    "            \"text\": agent_message\n",
    "        }]\n",
    "    }]\n",
    "    conversation.append(f\"Assistant: {agent_message}\")\n",
    "\n",
    "    # Conduct the conversation\n",
    "    while current_turn < max_turns:\n",
    "        # Send message to persona and get response\n",
    "        resp = send_message_to_chat(\n",
    "            agent_message,\n",
    "            persona_id,\n",
    "            conversation_id\n",
    "        )\n",
    "        \n",
    "        if resp is None:\n",
    "            print(f\"‚ö†Ô∏è Persona {persona_id} did not respond - ending conversation\")\n",
    "            break\n",
    "            \n",
    "        user_response, conversation_id = resp\n",
    "        conversation.append(f\"User: {user_response}\")\n",
    "        \n",
    "        # Generate agent's next question/response\n",
    "        agent_response = conversation_agent(user_response)\n",
    "        total_tokens = agent_response.metrics.accumulated_usage['totalTokens']\n",
    "        agent_message = str(agent_response)\n",
    "        conversation.append(f\"Assistant: {agent_message}\")\n",
    "        \n",
    "        current_turn += 1\n",
    "    \n",
    "    # Optional debugging output\n",
    "    if print_conversation:\n",
    "        print('\\n=== CONVERSATION ===')\n",
    "        print('\\n'.join(conversation))\n",
    "        print('===================\\n')\n",
    "        \n",
    "    if print_token_no:\n",
    "        print(f'üí° Total tokens used: {total_tokens}')\n",
    "        \n",
    "    return conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1cb55",
   "metadata": {},
   "source": [
    "# Multi-Agent Collaboration <a id='multi-agent-system'></a>\n",
    "\n",
    "One of the most powerful aspects of AI agent systems is their ability to work together. In our career matching system, different agents specialize in different tasks:\n",
    "\n",
    "## Information Extraction Agents\n",
    "\n",
    "These agents take unstructured text (conversations, job descriptions, training materials) and convert them into structured data using our Pydantic models.\n",
    "\n",
    "### Why Structured Extraction Matters\n",
    "\n",
    "Consider this raw conversation excerpt:\n",
    "> \"Hi, I'm Jo√£o from Rio. I've been working with sustainable farming for about 3 years now. I'm pretty good at organic cultivation and decent at project management...\"\n",
    "\n",
    "An extraction agent converts this into:\n",
    "```python\n",
    "PersonaInfo(\n",
    "    name=\"Jo√£o\",\n",
    "    location=\"Rio\", \n",
    "    skills=[(\"organic_cultivation\", \"advanced\"), (\"project_management\", \"intermediate\")],\n",
    "    years_of_experience=\"3\"\n",
    ")\n",
    "```\n",
    "\n",
    "This transformation enables:\n",
    "- **Consistent data formats** across all personas\n",
    "- **Programmatic matching** based on skills and requirements\n",
    "- **Quality validation** to ensure complete information capture\n",
    "- **Efficient processing** of large datasets\n",
    "\n",
    "## Batch Processing with Intelligence\n",
    "\n",
    "The `extract_info_to_json()` function demonstrates enterprise-grade AI agent design:\n",
    "\n",
    "- **Caching**: Avoids redundant API calls by storing results\n",
    "- **Error handling**: Retries failed extractions with exponential backoff\n",
    "- **Progress tracking**: Shows processing status for large datasets\n",
    "- **Incremental processing**: Resumes from where it left off\n",
    "\n",
    "This approach is crucial when processing hundreds or thousands of documents efficiently and reliably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2570174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(model: Type[M], text: str) -> M:\n",
    "    extraction_agent = get_agent()\n",
    "    return extraction_agent.structured_output(output_model=model, prompt=text)\n",
    "\n",
    "\n",
    "def extract_info_from_conversation(conversation: List[str]) -> PersonaInfo:\n",
    "    text = '\\n'.join(conversation)\n",
    "    return extract_info(PersonaInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_job_path(path: str | Path) -> JobInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(JobInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_from_training_path(path: str | Path) -> TrainingInfo:\n",
    "    text = load_file_content(path)\n",
    "    return extract_info(TrainingInfo, text)\n",
    "\n",
    "\n",
    "def extract_info_to_json(\n",
    "    model: BaseModel,\n",
    "    description_paths: List[str | Path],\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    save_path = Path(save_path)\n",
    "\n",
    "    if not save_path.exists():\n",
    "        save_path.touch()\n",
    "        save_json(save_path, {})\n",
    "\n",
    "    extracted_data = read_json(save_path)\n",
    "    description_paths = [Path(path) for path in description_paths]\n",
    "    print(f'Total descriptions for {model.__name__}: {len(description_paths)}')\n",
    "    print(f'Extracted infos: {len(extracted_data)}')\n",
    "\n",
    "    counter = 0\n",
    "    for path in description_paths:\n",
    "        id_ = path.stem\n",
    "        retries = 0\n",
    "        err = None\n",
    "        if id_ not in extracted_data:\n",
    "            text = load_file_content(path)\n",
    "            while retries < max_retries:\n",
    "                try:\n",
    "                    info = extract_info(model, text)\n",
    "                    extracted_data[id_] = info.model_dump_json()\n",
    "                    counter += 1\n",
    "                    break\n",
    "                except ValueError as e:\n",
    "                    retries += 1\n",
    "                    err = e\n",
    "            else:\n",
    "                print(f'Error for id: {id_}', err)\n",
    "        if counter % cache_period == 1:\n",
    "            save_json(save_path, extracted_data)\n",
    "            print(len(extracted_data))\n",
    "    save_json(save_path, extracted_data)\n",
    "\n",
    "\n",
    "def extract_jobs_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    job_paths = get_job_paths()\n",
    "    extract_info_to_json(\n",
    "        model=JobInfo,\n",
    "        description_paths=job_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_trainings_info_to_json(\n",
    "    save_path: str | Path,\n",
    "    cache_period: int = 20,\n",
    "    max_retries: int = 3\n",
    "):\n",
    "    training_paths = get_training_paths()\n",
    "    extract_info_to_json(\n",
    "        model=TrainingInfo,\n",
    "        description_paths=training_paths,\n",
    "        save_path=save_path,\n",
    "        cache_period=cache_period,\n",
    "        max_retries=max_retries\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947a5272",
   "metadata": {},
   "source": [
    "# Real-World Application: Intelligent Matching <a id='real-world-application'></a>\n",
    "\n",
    "This is where our AI agents solve the core challenge: matching people to opportunities. Our matching system uses specialized agents that understand both human preferences and job requirements.\n",
    "\n",
    "## The Matching Challenge\n",
    "\n",
    "Traditional job matching often relies on simple keyword matching. Our AI agent approach is far more sophisticated:\n",
    "\n",
    "### Traditional Approach:\n",
    "- Person has \"sustainability\" skill\n",
    "- Job requires \"environmental\" knowledge  \n",
    "- ‚ùå **No Match** (different keywords)\n",
    "\n",
    "### AI Agent Approach:\n",
    "- Agent understands semantic relationships\n",
    "- Recognizes that sustainability ‚Üî environmental knowledge\n",
    "- ‚úÖ **Match Found** with confidence score\n",
    "\n",
    "## Multi-Layer Matching Strategy\n",
    "\n",
    "Our system employs multiple specialized agents:\n",
    "\n",
    "### 1. Job Matching Agent\n",
    "- Analyzes persona skills vs. job requirements\n",
    "- Considers location preferences and constraints\n",
    "- Evaluates experience levels and career growth potential\n",
    "- Returns ranked list of suitable opportunities\n",
    "\n",
    "### 2. Training Matching Agent  \n",
    "- Identifies skill gaps between current abilities and career goals\n",
    "- Recommends learning paths to bridge those gaps\n",
    "- Considers prerequisite skills and learning progression\n",
    "- Suggests training programs that align with career objectives\n",
    "\n",
    "### 3. Career Path Agent\n",
    "- Combines job and training recommendations\n",
    "- Creates comprehensive development plans\n",
    "- Balances immediate opportunities with long-term growth\n",
    "\n",
    "## Why This Approach Works\n",
    "\n",
    "1. **Contextual Understanding**: Agents grasp the meaning behind requirements, not just keywords\n",
    "2. **Holistic Evaluation**: Multiple factors are considered simultaneously\n",
    "3. **Personalized Recommendations**: Each match is tailored to individual circumstances\n",
    "4. **Scalable Intelligence**: The same agents can handle thousands of personas efficiently\n",
    "\n",
    "Let's see how these matching agents work in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ee846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_job_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    jobs_data: Dict[str, JobInfo],\n",
    ") -> List[str]:\n",
    "    jobs_text = \"\\n\".join([\n",
    "        f'{job_id}: {job_info.describe()}'\n",
    "        for job_id, job_info in jobs_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available jobs. Given a candidate info provide\n",
    "    a list of up to 4 job IDs that would match that candidate.\n",
    "    The list might be empty if no match is found:\n",
    "    {jobs_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values\n",
    "\n",
    "\n",
    "def find_training_matches_for_persona(\n",
    "    persona_info: PersonaInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo]\n",
    ") -> List[str]:\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available trainings. Given a candidate info provide\n",
    "    a list of up to 4 training IDs that would match that candidate.\n",
    "    The list might be empty if no match is found:\\n\n",
    "    {trainings_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = agent.structured_output(IDList, persona_info.describe())\n",
    "    return res.values\n",
    "\n",
    "\n",
    "def find_training_matches_for_job(\n",
    "    job_info: JobInfo,\n",
    "    trainings_data: Dict[str, TrainingInfo],\n",
    "):\n",
    "    trainings_text = \"\\n\".join([\n",
    "        f'{training_id}: {training_info.describe()}'\n",
    "        for training_id, training_info in trainings_data.items()\n",
    "    ])\n",
    "    system_prompt = f\"\"\"\n",
    "    You have a list of all available trainings. Given a job info provide\n",
    "    a list of up to 4 training IDs that would be nice to have before\n",
    "    taking that job. The list may be empty if no training fit:\\n\n",
    "    {trainings_text}\n",
    "    \"\"\"\n",
    "    agent = get_agent(system_prompt=system_prompt)\n",
    "    res = None\n",
    "    err = None\n",
    "    max_retries = 3\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            res = agent.structured_output(IDList, job_info.describe())\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            retries += 1\n",
    "            err = e\n",
    "    if res is None:\n",
    "        raise ValueError(f'Agent could not get matches for job {job_info}. Err: {err}')\n",
    "    return res.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1a741",
   "metadata": {},
   "source": [
    "# Extracting job infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4734856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total descriptions for JobInfo: 200\n",
      "Extracted infos: 200\n"
     ]
    }
   ],
   "source": [
    "jobs_save_path = './extracted_jobs_info.json'\n",
    "extract_jobs_info_to_json(jobs_save_path)\n",
    "jobs_info = read_json(jobs_save_path)\n",
    "jobs_info = {\n",
    "    job_id: JobInfo.model_validate_json(job_data)\n",
    "    for job_id, job_data in jobs_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12eb3ec7",
   "metadata": {},
   "source": [
    "# Extracting trainings info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5574bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total descriptions for TrainingInfo: 497\n",
      "Extracted infos: 497\n"
     ]
    }
   ],
   "source": [
    "trainings_save_path = './extracted_trainings_info.json'\n",
    "extract_trainings_info_to_json(trainings_save_path)\n",
    "trainings_info = read_json(trainings_save_path)\n",
    "trainings_info = {\n",
    "    training_id: TrainingInfo.model_validate_json(training_data)\n",
    "    for training_id, training_data in trainings_info.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e916e03b",
   "metadata": {},
   "source": [
    "# Match trainings to jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14f2718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [04:50<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "job_training_matches_path = Path('./job_training_matches.json')\n",
    "job_training_matches = {}\n",
    "for job_id, job_info in tqdm(jobs_info.items()):\n",
    "    training_ids = find_training_matches_for_job(job_info, trainings_info)\n",
    "    job_training_matches[job_id] = training_ids\n",
    "save_json(job_training_matches_path, job_training_matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96942bd3",
   "metadata": {},
   "source": [
    "# Testing and Optimization <a id='testing-optimization'></a>\n",
    "\n",
    "Testing AI agent systems requires a different approach than traditional software testing. We need to verify not just that the code runs, but that the agents make intelligent decisions and provide valuable recommendations.\n",
    "\n",
    "## Testing Your Matching Algorithm\n",
    "\n",
    "Let's test our matching system with a sample persona to see how well it works:\n",
    "\n",
    "### Test Case: Environmental Sustainability Professional\n",
    "\n",
    "We'll create a persona representing someone interested in sustainable agriculture and environmental work, then see what opportunities our agents recommend.\n",
    "\n",
    "**Key Testing Principles:**\n",
    "1. **Diverse test cases**: Try personas with different backgrounds, skill levels, and locations\n",
    "2. **Edge cases**: Test with minimal information, conflicting preferences, or unusual skill combinations  \n",
    "3. **Quality validation**: Verify that recommendations make sense and are relevant\n",
    "4. **Efficiency monitoring**: Track token usage and response times\n",
    "\n",
    "### What to Look For:\n",
    "- ‚úÖ **Relevant matches**: Do recommended jobs align with the persona's skills and interests?\n",
    "- ‚úÖ **Appropriate difficulty**: Are experience requirements realistic for the candidate?\n",
    "- ‚úÖ **Geographic feasibility**: Do location constraints make sense?\n",
    "- ‚úÖ **Learning pathways**: Do training recommendations help bridge skill gaps?\n",
    "\n",
    "Let's run our test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a test persona with environmental/sustainability focus\n",
    "persona = PersonaInfo(\n",
    "    name='Pedro Ara√∫jo',\n",
    "    skills=[('Food Safety', 'Intermediate'), ('Food Sustainability', 'Intermediate')],\n",
    "    location='Bras√≠lia',\n",
    "    age='16',  # Note: Young age may affect job eligibility\n",
    "    years_of_experience='1'\n",
    ")\n",
    "\n",
    "print(\"üß™ Testing with Sample Persona:\")\n",
    "print(\"=\" * 40)\n",
    "print(persona.describe())\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test job matching\n",
    "print(\"\\nüéØ Finding Job Matches...\")\n",
    "persona_jobs = find_job_matches_for_persona(persona, jobs_info)\n",
    "print(f\"Recommended Jobs: {persona_jobs}\")\n",
    "\n",
    "# Test training matching  \n",
    "print(\"\\nüìö Finding Training Matches...\")\n",
    "persona_trainings = find_training_matches_for_persona(persona, trainings_info)\n",
    "print(f\"Recommended Trainings: {persona_trainings}\")\n",
    "\n",
    "print(\"\\nüí° Analysis:\")\n",
    "print(\"- Are the job recommendations appropriate for someone with intermediate food safety/sustainability skills?\")\n",
    "print(\"- Do the training suggestions help develop complementary skills?\") \n",
    "print(\"- How does the young age (16) affect job eligibility?\")\n",
    "print(\"- Are there regional opportunities available in Bras√≠lia?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689f2390",
   "metadata": {},
   "source": [
    "# Collecting conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dade2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total conversations for personas: 100\n",
      "Collected conversations: 100\n"
     ]
    }
   ],
   "source": [
    "persona_ids = [f'persona_{i:03}' for i in range(1, 101)]\n",
    "cache_period = 4\n",
    "\n",
    "personas_save_path = Path('./extracted_personas_info.json')\n",
    "if not personas_save_path.exists():\n",
    "    personas_save_path.touch()\n",
    "    save_json(personas_save_path, {})\n",
    "\n",
    "persona_infos = read_json(personas_save_path)\n",
    "print(f'Total conversations for personas: {len(persona_infos)}')\n",
    "print(f'Collected conversations: {len(persona_infos)}')\n",
    "\n",
    "counter = 0\n",
    "for persona_id in persona_ids:\n",
    "    if persona_id not in persona_infos:\n",
    "        conversation = get_conversation(persona_id, max_turns=2)\n",
    "        persona_info = extract_info_from_conversation(conversation)\n",
    "        persona_infos[persona_id] = persona_info.model_dump_json()\n",
    "        counter += 1\n",
    "    if counter % cache_period == 1:\n",
    "        save_json(personas_save_path, persona_infos)\n",
    "        print(len(persona_infos))\n",
    "save_json(personas_save_path, persona_infos)\n",
    "\n",
    "persona_infos = {\n",
    "    persona_id: PersonaInfo.model_validate_json(persona_info)\n",
    "    for persona_id, persona_info in persona_infos.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1f958",
   "metadata": {},
   "source": [
    "# Generating final data\n",
    "\n",
    "Each line in the sample represents a single prediction result for a persona, formatted as a JSON object (JSON Lines format). The fields include:\n",
    "\n",
    "- `persona_id`: The unique identifier for the persona.\n",
    "- `predicted_type`: The type of recommendation made. It can be `\"jobs+trainings\"`, `\"trainings_only\"`, or `\"awareness\"`.\n",
    "- Depending on the `predicted_type`, additional fields are included:\n",
    "    - For `\"jobs+trainings\"`: a `jobs` list, where each item contains a `job_id` and a list of `suggested_trainings` for that job.\n",
    "    - For `\"trainings_only\"`: a `trainings` list with recommended training IDs.\n",
    "    - For `\"awareness\"`: a `predicted_items` field, e.g., `\"too_young\"`.\n",
    "\n",
    "**Why this format?**\n",
    "\n",
    "- **Consistent structure** ensures our endpoint can reliably parse and validate each prediction.\n",
    "- **Flexible fields** support different recommendation types while keeping the schema simple and machine-readable.\n",
    "- **Automation-ready**: This format enables direct ingestion into evaluation or deployment systems without manual intervention.\n",
    "\n",
    "Participants must use this format to ensure compatibility with the challenge's automated result validation and scoring systems.\n",
    "\n",
    "Example result:\n",
    "```json\n",
    "{\"persona_id\": \"persona_001\", \"predicted_type\": \"trainings_only\", \"trainings\": [\"t1\", \"t2\"]}\n",
    "{\"persona_id\": \"persona_002\", \"predicted_type\": \"jobs+trainings\", \"jobs\": [{\"job_id\": \"j1\", \"suggested_trainings\": [\"t3\"]},{\"job_id\": \"j2\", \"suggested_trainings\": [\"t34\"]},{\"job_id\": \"j7\", \"suggested_trainings\": [\"t1\", \"t33\"]}]}\n",
    "{\"persona_id\": \"persona_127\", \"predicted_type\": \"awareness\", \"predicted_items\": \"too_young\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1545ddfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for persona_id, persona_info in tqdm(persona_infos.items()):\n",
    "    jobs = find_job_matches_for_persona(persona_info, jobs_info)\n",
    "    data = {'persona_id': persona_id}\n",
    "    if jobs and any(job_training_matches.get(job_id) for job_id in jobs):\n",
    "        data['predicted_type'] = 'jobs+trainings'\n",
    "        data['jobs'] = [\n",
    "            {\n",
    "                'job_id': job_id,\n",
    "                'suggested_trainings': job_training_matches[job_id]\n",
    "            }\n",
    "            for job_id in jobs\n",
    "        ]\n",
    "    elif not jobs:\n",
    "        trainings = find_training_matches_for_persona(persona_info, jobs_info)\n",
    "        data['predicted_type'] = 'trainings_only'\n",
    "        data['trainings'] = trainings\n",
    "    else:\n",
    "        data['predicted_type'] = 'awareness'\n",
    "        data['predicted_items'] = ''\n",
    "    results.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fec47",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc176966",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path('./results.jsonl')\n",
    "with results_path.open('w', encoding='utf-8') as file:\n",
    "    for res in results:\n",
    "        line = json.dumps(res) + '\\n'\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e523466",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
